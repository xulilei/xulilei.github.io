[{"title":"面试总结（持续更新）","date":"2020-09-14T11:37:14.000Z","path":"2020/09/14/面试总结（持续更新）/","text":"9.14 中移物联网 面试没答好的点： 1、不懂得扩展，说到底还是自己基础不扎实，比如JVM，五个分区每个分区是干嘛用的 2、Feign的原理？如何在各服务之间通信的 3、hashmap介绍一下，直说了数据结构，应该从存储key开始 4、索引的种类，我只从主键索引，唯一索引，普通索引和联合索引说了 5、怎么判断哪些查询没有走索引，我说了最左前缀原则，应该再说一下explain语句 6、锁的分类，应该详细介绍，我答得语无伦次 总结：最大的问题是心里太慌了，应该从每个点然后再深入再退出再深入","tags":[]},{"title":"八大排序算法","date":"2020-08-23T11:38:24.000Z","path":"2020/08/23/八大排序算法/","text":"八大排序算法1、冒泡排序package 冒泡排序;import java.util.Arrays;/** 从第一个数开始，将最大数不断向后移* */public class 冒泡排序 &#123; public static void maoPao(int[]arr)&#123; int temp; for(int i=0;i&lt;arr.length-1;i++)&#123; for(int j=0;j&lt;arr.length-i-1;j++)&#123; if(arr[j]&gt;arr[j+1])&#123; temp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=temp; &#125; &#125; &#125; &#125;&#125; 时间复杂度分析 2、选择排序/** 不断的把最小值往前扔* */public class 选择排序 &#123; public static void selectSort(int[]arr)&#123; for(int i=0;i&lt;arr.length-1;i++)&#123; int min=arr[i]; int minIndex=i; for(int j=i+1;j&lt;arr.length;j++)&#123; if(min&gt;arr[j])&#123; min=arr[j]; minIndex=j; &#125; &#125; if(minIndex!=i)&#123; arr[minIndex]=arr[i]; arr[i]=min; &#125; &#125; &#125;&#125; 3、直接插入排序package 插入排序;import java.util.Arrays;/** 简单插入排序很循规蹈矩，不管数组分布是怎么样的，依然一步一步的对元素进行比较，移动，插入* （1，4）3，5-&gt;(1,3,4) 5* 保证前i-1位有序排列，将本次第i个插入前i-1个中某个位置* 规则为，依次比较，大于i则将排好序的数索引向后移动一位，直到空出一个位置* */public class 插入排序 &#123; public static void insertSort(int[]arr)&#123; for(int i=1;i&lt;arr.length;i++)&#123; int value=arr[i]; int insertIndex=i; while (insertIndex&gt;0&amp;&amp;arr[insertIndex-1]&gt;value)&#123; //向后移动一个，腾出要插入的空地 arr[insertIndex]=arr[insertIndex-1]; insertIndex--; &#125; arr[insertIndex]=value; &#125; &#125;&#125; 4、希尔排序package 希尔排序;import java.util.Arrays;/** 希尔排序是对直接插入排序的一种优化* 是按照跳跃式分组的方式，按组进行插入排序，之后每次将增量减为1/2，直到增量为0* */public class 希尔排序 &#123; public static void shellSort(int[]arr)&#123; for(int step=arr.length/2;step&gt;0;step/=2)&#123; for(int i=step;i&lt;arr.length;i++)&#123; int value=arr[i]; int insertIndex=i; while (insertIndex-step&gt;=0&amp;&amp;arr[insertIndex-step]&gt;value)&#123; arr[insertIndex]=arr[insertIndex-step]; insertIndex-=step; &#125; arr[insertIndex]=value; &#125; &#125; &#125;&#125; 5、快速排序package 快排;import java.util.Arrays;/** 选取一个base，一般以left为准，不断将base放到左侧小于他右侧大于他的位置* 再递归从已确定位置的左右* */public class quickSort &#123; public static void quickSort(int[]arr,int left,int right)&#123; if(left&gt;right)return; int base=arr[left]; //索引 int l=left; int r=right; while (l&lt;r)&#123; while (arr[r]&gt;base&amp;&amp;l&lt;r)r--; while (arr[l]&lt;=base&amp;&amp;l&lt;r)l++; int temp=arr[r]; arr[r]=arr[l]; arr[l]=temp; &#125; arr[left]=arr[l]; arr[l]=base; quickSort(arr, left, l-1); quickSort(arr, l+1, right); &#125;&#125; 6、归并排序package 归并排序;/** 先分（mergeSort）再合（merge）* 先分以mid为中线* merge时写一个例子方便理解* left（l） mid mid+1（r） right* （1， ,5 4） （2， ,6 3）* 临时数组int[]temp=new int[right-left+1];* */public class mergeSort &#123; public static void mergeSort(int[]arr,int left,int right)&#123; if(left&gt;=right)return; int mid=(left+right)/2; mergeSort(arr, left, mid); mergeSort(arr,mid+1,right); merge(arr,left,mid,right); &#125; public static void merge(int[]arr,int left,int mid,int right)&#123; int l=left,r=mid+1; int[]temp=new int[right-left+1]; int index=0; while (l&lt;=mid&amp;&amp;r&lt;=right)&#123; if(arr[l]&lt;arr[r])&#123; temp[index++]=arr[l++]; &#125;else &#123; temp[index++]=arr[r++]; &#125; &#125; while (l&lt;=mid)&#123; temp[index++]=arr[l++]; &#125; while (r&lt;=right)&#123; temp[index++]=arr[r++]; &#125; for(int i=0;i&lt;temp.length;i++)&#123; arr[left+i]=temp[i]; &#125; &#125;&#125; 7、基数排序package 基数排序;import java.util.Arrays;/** 基数排序的基本思想是，通过从个位开始讲每个书按照该位所在的值依次放入所在的桶* 再重新覆盖原数组后，位数向高位进一位* 当最高位执行完毕，这个数组就是一个有序数组* */public class 基数排序 &#123; public static void jiShuSort(int[]arr)&#123; //找到数最大的位数 int max=arr[0]; for(int a:arr)&#123; if(a&gt;max)max=a; &#125; //代表位数 int weiShu=(max+\"\").length(); //从个位开始 int n=1; //每一行的位数值相等，0-9总共十个数，创建十行，每行长度最大为arr的长度 int[][] bucket=new int[10][arr.length]; //存放的是每个位数容纳的数的个数，比如order[1]，表示个位为1的数的个数，初始值都为0 int[]order=new int[10]; //将数组从bucket中拿出来覆盖原数组用到的索引 int index=0; //从各位开始一直到最高位 while (n&lt;=Math.pow(10,weiShu))&#123; //将数组中的每个数，按照本轮的位数，放入所在的行 for(int a:arr)&#123; int digit=(a/n)%10; bucket[digit][order[digit]]=a; order[digit]++; &#125; //将bucket中的数据取出覆盖原数组 for(int i=0;i&lt;10;i++)&#123; //当本位数存储的数不为空时 if(order[i]!=0)&#123; for(int j=0;j&lt;order[i];j++)&#123; arr[index++]=bucket[i][j]; &#125; &#125; //重置计数器 order[i]=0; &#125; //位数加1 n*=10; //覆盖索引归零 index=0; &#125; &#125;&#125; 8、堆排序package 堆排序;import java.util.Arrays;/** 基本思想是先从非叶子节点开始，通过数组对应关系调整叶子节点为大顶堆* 数组与完全二叉树堆的对应关系为：父节点为i，则左子节点为2i+1，右子节点为2i+2；* 接着让大顶堆的最大值与最后一个数对调，除掉最后一个最大值数重新调整大顶堆，最后变成有序数列* 这也是升序用大顶推，降序用小顶堆* */public class 堆排序 &#123; public static void heapSort(int[] array) &#123; // 按照完全二叉树的特点，从最后一个非叶子节点开始，对于整棵树进行大根堆的调整 // 也就是说，是按照自下而上，每一层都是自右向左来进行调整的 // 注意，这里元素的索引是从0开始的 // 另一件需要注意的事情，这里的建堆，是用堆调整的方式来做的 // 堆调整的逻辑在建堆和后续排序过程中复用的 for (int i = array.length/2-1; i &gt;= 0; i--) &#123; adjustHeap(array, i, array.length); &#125; // 上述逻辑，建堆结束 // 下面，开始排序逻辑 for (int j=array.length-1;j&gt;0;j--) &#123; // 元素交换 // 说是交换，其实质就是把大顶堆的根元素，放到数组的最后；换句话说，就是每一次的堆调整之后，都会有一个元素到达自己的最终位置 swap(array, 0, j); // 元素交换之后，毫无疑问，最后一个元素无需再考虑排序问题了。 // 接下来我们需要排序的，就是已经去掉了部分元素的堆了，这也是为什么此方法放在循环里的原因 // 而这里，实质上是自上而下，自左向右进行调整的 adjustHeap(array, 0, j); &#125; &#125; public static void adjustHeap(int[] array, int i, int length) &#123; // 先把当前元素取出来，因为当前元素可能要一直移动 int temp = array[i]; // 可以参照sort中的调用逻辑，在堆建成，且完成第一次交换之后，实质上i=0；也就是说，是从根所在的最小子树开始调整的 // 接下来的讲解，都是按照i的初始值为0来讲述的 // 这一段很好理解，如果i=0；则k=1；k+1=2 // 实质上，就是根节点和其左右子节点记性比较，让k指向这个不超过三个节点的子树中最大的值 // 这里，必须要说下为什么k值是跳跃性的。 // 首先，举个例子，如果a[0] &gt; a[1]&amp;&amp;a[0]&gt;a[2],说明0,1,2这棵树不需要调整，那么，下一步该到哪个节点了呢？肯定是a[1]所在的子树了， // 也就是说，是以本节点的左子节点为根的那棵小的子树 // 而如果a[0&#125;&lt;a[2]呢，那就调整a[0]和a[2]的位置，然后继续调整以a[2]为根节点的那棵子树，而且肯定是从左子树开始调整的 // 所以，这里面的用意就在于，自上而下，自左向右一点点调整整棵树的部分，直到每一颗小子树都满足大根堆的规律为止 for (int k=2*i+1; k&lt;length; k=2*k+1) &#123; // 让k先指向子节点中最大的节点 if (k + 1 &lt; length &amp;&amp; array[k] &lt; array[k + 1]) &#123; k++; &#125; // 如果发现子节点更大，则进行值的交换 if (array[k] &gt; temp) &#123; swap(array, i, k); // 下面就是非常关键的一步了 // 如果子节点更换了，那么，以子节点为根的子树会不会受到影响呢？ // 所以，循环对子节点所在的树继续进行判断 i = k; // 如果不用交换，那么，就直接终止循环了 &#125; else &#123; break; &#125; &#125; &#125; public static void swap(int[] arr, int a, int b) &#123; int temp = arr[a]; arr[a] = arr[b]; arr[b] = temp; &#125;&#125; 时间复杂度分析①、稳定性判断：从前往后或者从后往前，逐一（两两）进行比较的排序算法都具有稳定性的特征，如：冒泡排序，插入排序，基数排序，归并排序。 而较快比较出来的算法往往是不稳定的，如：快速排序，简单选择排序，堆排序，希尔排序。 ②、时间复杂度判断：涉及到两两递归或二叉树的排序时间复杂度为O(nlogn)，如堆排序，归并排序，快速排序 ③、时间复杂度表","tags":[{"name":"排序算法","slug":"排序算法","permalink":"https://xulilei.github.io/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"秋招复习之SpringMVC、Boot、Cloud","date":"2020-08-19T07:26:52.000Z","path":"2020/08/19/秋招复习之SpringMVC、Boot、Cloud/","text":"SpringMVCSpring MVC是spring的一个模块，是一个web框架，通过把Model，View，Controller分离，将web层进行职责解耦，把复杂的web开发分成逻辑清晰的几部分，简化开发 流程1、客户端发送请求到DispatcherServlet 2、DispatcherServlet根据请求信息调用HandlerMapping，解析请求对应的handler 3、解析到对应的Handler后，由HandlerAdapter适配器调用具体的处理器，并处理请求 4、处理请求完成后，会返回一个ModelAndView对象给DispatcherServlet 5、ViewResolver根据ModelAndView中的view查找实际的model 6、DispatcherServlet将返回的model传给view进行视图渲染 7、最终将View返回给请求者 SpringMVC怎么和Ajax互相调用的？通过jackson框架就可以直接把java对象直接转化成js可以识别的json对象，需要加上@ResponseBody注解 如果解决POST请求乱码的问题在web.xml中配置一个CharacterEncodingFilter过滤器，并将字符集设置为utf8 SpringMVC的异常处理？springMVC是spring框架中的一个模块，遇到异常处理可以将异常抛给spring，由spring异常处理器执行具体异常逻辑，返回异常视图页面 SpringMVC和Struts2的区别有哪些?springmvc的入口是一个servlet即前端控制器（DispatchServlet），而struts入口是一个filter过虑器 springmvc是基于方法开发(一个url对应一个方法)，请求参数传递到方法的形参，控制器是单例的，struts2是基于类开发，传递参数是通过类的属性，只能设计为多例。 SpringMVC的控制器是不是单例模式,如果是,有什么问题,怎么解决？是单例的，多线程访问下会有线程安全的问题 解决方法是尽量不要在controller里面去定义属性，如果在特殊情况需要定义属性的时候，那么就在类上面加上注解@Scope(“prototype”)改为多例的模式. 原因： 1、struts是基于类的属性进行发的，定义属性可以整个类通用，所以默认是多例，不然单例情况下多线程访问肯定是共用类里面的属性值的，肯定是不安全的，2、springmvc是基于方法的开发，请求参数传递到方法的形参，一个方法结束参数就销毁了，多线程访问会将参数存放在各自的threadlocal中，使得方法参数线程间不可见，所以springmvc默认使用了单例. 因此，只要controller里面不定义属性，那么单例模式下的控制器就是安全的。 如果在拦截请求中，我想拦截get方式提交的方法,怎么配置？答：可以在@RequestMapping注解里面加上method=RequestMethod.GET。 怎样在方法里面得到Request,或者Session？答：直接在方法的形参中声明request,SpringMvc就自动把request对象传入。 SpringMVC中函数的返回值是什么？答：返回值可以有很多类型,有String, ModelAndView。ModelAndView类把视图和数据都合并的一起的，但一般用String比较好。 SpringMVC用什么对象从后台向前台传递数据的？答：通过ModelMap对象,可以在这个对象里面调用put方法,把对象加到里面,前台就可以通过el表达式拿到。 怎么样把ModelMap里面的数据放入Session里面？答：可以在类上面加上@SessionAttributes注解,里面包含的字符串就是要放入session里面的key。 springMvc和springboot的区别Spring MVC：是spring的一个模块，是一个web框架，通过把Model，View，Controller分离，将web层进行职责解耦，把复杂的web开发分成逻辑清晰的几部分springboot：是spring组件一站式解决方案，主要简化了使用spring的难度，减省了繁重的配置，提供各种starter Springbootspringboot自动装配的原理主要基于一个注解@EnableAutoConfiguration，会通过这个注解找到META-INF文件中的配置类，并结合对应的xxxProperties.java读取配置文件进行自动配置 Spring Boot 有哪几种读取配置的方式？@PropertySource,@Value,@Environment, @ConfigurationProperties Spring Boot 的核心配置文件有哪几个？它们的区别是什么？核心配置文件是application和bootstrap application配置文件主要用于springboot项目自动化配置 bootstrap优先于application加载，从额外的资源加载配置信息，比如通过spring cloud config配置中心时，需要在bootstrap配置文件中配置连接信息 Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？@SpringBootApplication 主要包含了以下3个注解： @SpringBootConfiguration：是configuration注解，实现配置文件的功能 @EnableAutoConfiguration：打开自动配置功能 @ComponentScan：组件扫描 SpringCloud1. 什么是 spring cloud？ spring cloud 是一系列框架的有序集合。它利用 spring boot 的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用 spring boot 的开发风格做到一键启动和部署。 3. spring cloud 的核心组件有哪些？ Eureka：服务注册于发现。 Feign：基于动态代理机制，根据请求 url 地址，跟指定的服务建立连接、构造请求、发起靕求、获取响应、解析响应。 Ribbon：实现负载均衡，从一个服务的多台机器中选择一台。 Hystrix：提供线程池，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题。 Zuul：网关管理，由 Zuul 网关转发请求给对应的服务。 4. SpringCloud和Dubbo SpringCloud和Dubbo都是现在主流的微服务架构SpringCloud是Apache旗下的Spring体系下的微服务解决方案Dubbo是阿里系的分布式服务治理框架从技术维度上,其实SpringCloud远远的超过Dubbo,Dubbo本身只是实现了服务治理,而SpringCloud现在以及有21个子项目以后还会更多服务的调用方式Dubbo使用的是RPC远程调用,而SpringCloud使用的是 Rest API,其实更符合微服务官方的定义服务的注册中心来看,Dubbo使用了第三方的ZooKeeper作为其底层的注册中心,实现服务的注册和发现,SpringCloud使用Eureka实现注册中心服务网关,Dubbo并没有本身的实现,只能通过其他第三方技术的整合,而SpringCloud有Zuul路由网关,作为路由服务器,进行消费者的请求分发,SpringCloud还支持断路器,与git完美集成分布式配置文件支持版本控制,事务总线实现配置文件的更新与服务自动装配等等一系列的微服务架构要素 5、与boot的区别而SpringCloud专注于解决各个微服务之间的协调与配置,服务之间的通信,熔断,负载均衡等 总结: SpringBoot专注于快速方便的开发单个个体的微服务 SpringCloud是关注全局的微服务协调整理治理框架,整合并管理各个微服务,为各个微服务之间提供,配置管理,服务发现,断路器,路由,事件总线等集成服务 SpringBoot不依赖于SpringCloud,SpringCloud依赖于SpringBoot,属于依赖关系 7. 负载均衡的意义是什么? 在计算中，负载均衡可以改善跨计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器等多种计算资源的工作负载分布。负载均衡旨在优化资源使用，最大吞吐量，最小响应时间并避免任何单一资源的过载。使用多个组件进行负载均衡而不是单个组件可能会通过冗余来提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务进程。 有哪些负载均衡算法：1、轮询：将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。 2、源地址哈希法：对请求服务器的ip进行一个哈希算法，将其分配到一个服务器上去，也就是说之后每次该IP地址的访问都将分配给同一台服务器 3、加权轮询：在轮询的基础上，对服务器承受压力大的服务器权重设置高点。 4、最小连接数：动态的选取当前所有服务器，连接数最少的服务器 8. springcloud如何实现服务的注册? 1.服务发布时，指定对应的服务名,将服务注册到 注册中心(eureka zookeeper)2.注册中心加@EnableEurekaServer,服务用@EnableDiscoveryClient，然后用ribbon或feign进行服务直接的调用发现。 9. 什么是服务熔断?什么是服务降级 在复杂的分布式系统中,微服务之间的相互调用,有可能出现各种各样的原因导致服务的阻塞,在高并发场景下,服务的阻塞意味着线程的阻塞,导致当前线程不可用,服务器的线程全部阻塞,导致服务器崩溃,由于服务之间的调用关系是同步的,会对整个微服务系统造成服务雪崩 为了解决某个微服务的调用响应时间过长或者不可用进而占用越来越多的系统资源引起雪崩效应就需要进行服务熔断和服务降级处理。 所谓的服务熔断指的是某个服务故障或异常一起类似显示世界中的“保险丝”当某个异常条件被触发就直接熔断整个服务，而不是一直等到此服务超时。 服务熔断就是相当于我们电闸的保险丝,一旦发生服务雪崩的,就会熔断整个服务,通过维护一个自己的线程池,当线程达到阈值的时候就启动服务降级,如果其他请求继续访问就直接返回fallback的默认值 13. eureka自我保护机制是什么? 当Eureka Server 节点在短时间内丢失了过多实例的连接时（比如网络故障或频繁启动关闭客户端）节点会进入自我保护模式，保护注册信息，不再删除注册数据，故障恢复时，自动退出自我保护模式。 14. 什么是Ribbon？ ribbon是一个负载均衡客户端，可以很好的控制htt和tcp的一些行为。feign默认集成了ribbon。 15. 什么是feigin？它的优点是什么？ 1.feign采用的是基于接口的注解2.feign整合了ribbon，具有负载均衡的能力3.整合了Hystrix，具有熔断的能力 使用:1.添加pom依赖。2.启动类添加@EnableFeignClients3.定义一个接口@FeignClient(name=“xxx”)指定调用哪个服务 16. Ribbon和Feign的区别？ 1.Ribbon都是调用其他服务的，但方式不同。2.启动类注解不同，Ribbon是@RibbonClient feign的是@EnableFeignClients3.服务指定的位置不同，Ribbon是在@RibbonClient注解上声明，Feign则是在定义抽象方法的接口中使用@FeignClient声明。4.调用方式不同，Ribbon需要自己构建http请求，模拟http请求然后使用RestTemplate发送给其他服务，步骤相当繁琐。Feign需要将调用的方法定义成抽象方法即可。 17. 什么是Spring Cloud Bus? spring cloud bus 将分布式的节点用轻量的消息代理连接起来，它可以用于广播配置文件的更改或者服务直接的通讯，也可用于监控。如果修改了配置文件，发送一次请求，所有的客户端便会重新读取配置文件。使用:1.添加依赖2.配置rabbimq 20. 什么是SpringCloudConfig? 在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库中。在spring cloud config 组件中，分两个角色，一是config server，二是config client。 使用：1、添加pom依赖2、配置文件添加相关配置3、启动类添加注解@EnableConfigServer 21. 架构？ 在微服务架构中，需要几个基础的服务治理组件，包括服务注册与发现、服务消费、负载均衡、断路器、智能路由、配置管理等，由这几个基础组件相互协作，共同组建了一个简单的微服务系统 在Spring Cloud微服务系统中，一种常见的负载均衡方式是，客户端的请求首先经过负载均衡（zuul、Ngnix），再到达服务网关（zuul集群），然后再到具体的服。服务统一注册到高可用的服务注册中心集群，服务的所有的配置文件由配置服务管理，配置服务的配置文件放在git仓库，方便开发人员随时改配置。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://xulilei.github.io/tags/Spring/"}]},{"title":"秋招复习之Spring事务、分布式事务","date":"2020-08-19T07:26:07.000Z","path":"2020/08/19/秋招复习之Spring事务、分布式事务/","text":"spring事务spring隔离级别比mysql多了一个ISOLATION_DEFAULT ：使用后端数据库默认的隔离级别，mysql使用的是REPEATABLE_READ 支持当前事务：PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务，如果当前没有事务，则创建一个新的事务 PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务，如果当前没有事务，则以非事务的方式继续执行 PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务，如果当前没有事务，则抛出异常 不支持当前事务：PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务则把当前事务挂起 PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务则把当前事务挂起 PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常 其他情况：PROPAGATION_NESTED： 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务执行，否则就创建新的事务 事务的实现方式申明式事务@Transactional 编程式事务管理：beginTransaction、commit、rollback 事务的原理是基于SpringAOP的，通过transactionProxyFactoryBean对加了@Transactional注解的对象生成代理对象，再通过transactionintercept完成对方法的拦截，将事务功能编制在拦截方法中，从而完成rollback，commit等操作 事务中threadlocal的使用与数据库交互的事务是和线程绑定起来的,Spring框架在事务开始时会给当前线程绑定一个Jdbc Connection,在整个事务过程都是使用该线程绑定的connection来执行数据库操作，实现了事务的隔离性。Spring框架里面就是用的ThreadLocal来实现这种隔离 分布式事务java中的事务由于是jvm层级的，因此只要满足acid，那么这个事务是不会出现异常情况的 而在分布式事务中，由于不再是jvm层级了， 有这样一种情况：以我自己做的那个项目为例：一个下单系统，先通过redis预减库存，然后将请求发送给mq，在另一个模块中异步消费mq中的下单请求，操作数据库，接着生成打印订单，用@Transactional注解包裹，如果发生异常rollback将redis中减掉的库存加回去 分析如果在生成打印订单的途中，发生了异常，使得下单失败，那么redis会将减掉的库存加回去，看上去似乎没有问题。但是mq中的消息仍然被消费了，最终数据库中的库存是被剪掉了的，虽然不会导致超卖的现象，但是会出现少卖的情况 解决方案可靠性最终一致性方案","tags":[{"name":"事务","slug":"事务","permalink":"https://xulilei.github.io/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"项目实操","date":"2020-08-14T01:40:04.000Z","path":"2020/08/14/项目实操/","text":"一、Docker下redis集群搭建1、主从结构搭建配置文件confREPLICAOF命令REPLICAOF 可以在线修改当前服务器的复制设置 如果当前服务器已经是副本服务器，命令REPLIACAOF NO ONE 会关闭当前服务器的复制并转变为主服务器。 执行 REPLIACOF hostname port 会将当前服务器转变为某一服务器的副本服务器 如果当前服务器已经是某个主服务器(master server)的副本服务器，那么执行 REPLICAOF hostname port 将使当前服务器停止对原主服务器的同步，丢弃旧数据集，转而开始对新主服务器进行同步 对一个副本服务器执行命令 REPLICAOF NO ONE 将使得这个副本服务器关闭复制，并从副本服务器转变回主服务器，原来同步所得的数据集不会被丢弃。因此，当原主服务器停止服务，可以将该副本服务器切换为主服务器，应用可以使用新主服务器进行读写。原主服务器修复后，可将其设置为新主服务器的副本服务器。 #主服务器配置文件#bind 127.0.0.1 #如果bind选项为空的话，则允许所有来自于可用网络接口的连接protected-mode no #保护模式，若为yes，只允许本地客户端连接appendonly yes #开启后，Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里#主服务器配置文件#bind 127.0.0.1 #如果bind选项为空的话，则允许所有来自于可用网络接口的连接protected-mode no #保护模式，若为yes，只允许本地客户端连接appendonly yes #开启后，Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里replicaof masterHost port 3、sentinel模式搭建# 让sentinel服务后台运行daemonize yes # 修改日志文件的路径logfile \"/var/log/redis/sentinel.log\"# 修改监控的主redis服务器# 最后一个2表示，两台机器判定主被动下线后，就进行failover(故障转移)sentinel monitor mymaster 35.236.172.131 6379 2 创建sentinel容器 docker run -di --name redisSentinel -p 26379:26379 -v /usr/local/redisSentinel/sentinel.conf:/etc/redis/sentinel.conf redis /bin/bash 进入容器开启哨兵 redis exec -it redisSentinel bashredis-sentinel /etc/redis/sentinel.conf 二、分布式锁1、redis分布式锁的基本实现String key;//try是为了防止逻辑代码出现异常，导致无法删除keytry&#123; //如果有则返回false，如果没有则set并返回false Boolean result=redisTemplate.opsForValue().setIfAbsent(key,value,timeout); //result为false说明没有key，则获得该锁，此时其他进程返回true，无法获得该锁 if(!result)&#123; 逻辑代码段 &#125; &#125;finally&#123; redisTemplate.delete(\"key\");&#125; 2、redisson的分布式锁实现//配置文件@Configurationpublic class redissonConfig &#123; /*单体模式 public Redisson getRedisson()&#123; Config config=new Config(); config.useSingleServer().setAddress(\"118.25.105.4:6379\"); return (Redisson) Redisson.create(config); &#125;*/ /*主从模式 public Redisson getRedisson()&#123; Config config=new Config(); config.useMasterSlaveServers().setMasterAddress(\"118.25.105.4:6379\") .addSlaveAddress(\"118.25.105.4:6380\"); return (Redisson) Redisson.create(config); &#125;*/ //哨兵模式 @Bean public Redisson getRedisson()&#123; Config config=new Config(); config.useSentinelServers().setMasterName(\"mymaster\") .addSentinelAddress(\"118.25.105.4:26379\"); return (Redisson) Redisson.create(config); &#125; /*集群模式 public Redisson getRedisson()&#123; Config config=new Config(); config.useClusterServers().setScanInterval(2000) .addNodeAddress(); return (Redisson) Redisson.create(config); &#125;*/&#125;public void deleteById(String id) throws InterruptedException &#123; //验证权限 String token = (String) request.getAttribute(\"admin_claims\"); if(token==null||\"\".equals(token))&#123; throw new RuntimeException(\"权限不足\"); &#125; //根据ID获得锁对象 RLock lockId = redisson.getLock(id); try &#123; //尝试加锁最多等待20秒，成功后10秒删除 Boolean flag=lockId.tryLock(20,10,TimeUnit.SECONDS); if(flag)&#123; //执行业务逻辑 userDao.deleteById(id); &#125;else &#123; //没有获取到锁 throw new RuntimeException(\"当前人数过多，请重试\"); &#125; &#125;catch (Exception e)&#123; //加锁过程出现错误 throw new RuntimeException(\"遇到未知错误\"); &#125;finally &#123; //主动释放锁 lockId.unlock(); &#125; &#125; 三、限流方式1、对于热点数据通过semaphore防止缓存穿透public Article findById(String id) throws InterruptedException &#123; //先从缓存中查询当前对象 Article article= (Article) redisTemplate.opsForValue().get(\"article_\"+id); //如果没有取到 if(article==null)&#123; //通过信号量semaphore //Semaphore semaphore=new Semaphore(100); if(semaphore.tryAcquire())&#123; article = articleDao.findById(id).orElse(null); //存入缓存 if(article!=null)&#123; redisTemplate.opsForValue().set(\"article_\"+id,article); &#125; //释放锁 semaphore.release(); &#125;else &#123; //获取不到等待一段时间再次获取 Thread.sleep(100); article=findById(id); &#125; &#125; return article; &#125; 2、通过redis 1、首先redis加入库存2、秒杀开启，重复请求缓存并返回请勿重复下单3、redis库存大于订单数，则下单成功，推送到mq队列，redis库存小于下单数，则直接返回库存不足4、再异步从mq消费消息，开一个只允许1000个线程工作的线程池，对数据库执行更新操作，并将结果存储到mq队列5、消费结果队列，并发送短信给用户","tags":[{"name":"集群搭建","slug":"集群搭建","permalink":"https://xulilei.github.io/tags/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"}]},{"title":"设计模式","date":"2020-07-27T10:51:53.000Z","path":"2020/07/27/秋招复习之spring 设计模式、事务/","text":"设计模式Spring 中的设计模式工厂模式Spring使用工厂模式通过 BeanFactory、ApplicationContext创建 bean 对象 单例模式Spring 中 bean 的默认作用域就是 singleton(单例)的 public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(beanName, \"'beanName' must not be null\"); synchronized (this.singletonObjects) &#123; // 检查缓存中是否存在实例 Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; //...省略了很多代码 try &#123; singletonObject = singletonFactory.getObject(); &#125; //...省略了很多代码 // 如果实例对象在不存在，我们注册到单例注册表中。 addSingleton(beanName, singletonObject); &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null); &#125; 代理模式Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么Spring AOP会使用JDK Proxy，而对于没有实现接口的对象会使用Cglib 具体在AnnotationAwareAspectJAutoProxyCreator的父类中定义了warpifnecessary方法，通过里面的creatProxy方法 适配器模式适配器模式(Adapter Pattern) 将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。 在Spring AOP 中，其实现是基于代理模式的。但是，在Spring AOP的增强或者通知（Advice）中，使用到了适配器模式。与之相关的适配器模式为AdvisorAdapter。 模版方法模式模板方法模式是一种行为设计模式，它定义一个操作中的算法的骨架，而将一些步骤延迟到子类中 观察者模式当一个对象发生改变的时候，这个对象所依赖的对象也会做出反应。 Spring 事件驱动模型就是观察者模式很经典的一个应用。 // 定义一个事件,继承自ApplicationEvent并且写相应的构造函数 public class DemoEvent extends ApplicationEvent&#123; private static final long serialVersionUID = 1L; private String message; public DemoEvent(Object source,String message)&#123; super(source); this.message = message; &#125; public String getMessage() &#123; return message; &#125;// 定义一个事件监听者,实现ApplicationListener接口，重写 onApplicationEvent() 方法；@Componentpublic class DemoListener implements ApplicationListener&lt;DemoEvent&gt;&#123; //使用onApplicationEvent接收消息 @Override public void onApplicationEvent(DemoEvent event) &#123; String msg = event.getMessage(); System.out.println(\"接收到的信息是：\"+msg); &#125;&#125;// 发布事件，可以通过ApplicationEventPublisher 的 publishEvent() 方法发布消息。@Componentpublic class DemoPublisher &#123; @Autowired ApplicationContext applicationContext; public void publish(String message)&#123; //发布事件 applicationContext.publishEvent(new DemoEvent(this, message)); &#125;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://xulilei.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"JAVA WEB、SpringMVC、SpringBoot","date":"2020-07-27T04:46:19.000Z","path":"2020/07/27/秋招复习之JavaWeb/","text":"JAVA WEBjava web 三大组件Servlet servlet是一个Java接口 servlet接口定义的是一套处理网络请求的规范，所有实现servlet的类，都需要实现它那五个方法，其中最主要的是两个生命周期方法 init()和destroy()，还有一个处理请求的service()，也就是说，所有实现servlet接口的类，或者说，所有想要处理网络请求的类，都需要回答这三个问题： 你初始化时要做什么 你销毁时要做什么 你接受到请求时要做什么 servlet可以处理请求吗不能，因为在servlet中不会写监听比如8080端口的代码，servlet不会直接和客户端打交道！ 那请求怎么来到servlet呢？答案是servlet容器，比如我们最常用的tomcat，只有将我们写的servlet部署到一个容器中，servlet才会起作用。 tomcat才是与客户端直接打交道的 监听了端口 请求过来后，根据url等信息，确定要将请求交给哪个servlet去处理 然后调用那个servlet的service方法 service方法返回一个response对象tomcat再把这个response返回给客户端。 生命周期Servlet的生命周期有四个阶段 实例化：调用构造方法创建Servlet实例 init()：用来对Servlet做一些初始化的操作 service()：用来处理请求的方法 destroy()：服务器停止时调用，用来释放资源。 FilterFilter的作用filter可以作用在某个Servlet或一组Servlet，主要流程为 对用户请求(HttpServletRequest)进行预处理 servlet处理用户请求 对服务器响应(HttpServletResponse)进行后处理 生命周期Filter的生命周期 实例化：调用构造方法创建Filter实例，Filter实例服务器一旦启动就会被创建 init()：用来对Filter做一些初始化的操作 doFilter()：Filter的主要方法，用来完成过滤器主要功能的方法 destroy()：服务器停止时调用，用来释放资源。 主要功能处理中文乱码 过滤敏感词汇 Listener当触发某个事件，如servlet context初始化完成时，需要做一些事情，servlet规范中定义了若干个Listener用于监听这些事件。 作用用于对特定对象的生命周期和特定事件进行响应处理，主要用于对Session,request,context等进行监控。 主要监听器ServletContextListener：ServletContext的创建和销毁 HttpSessionListener：HttpSession的创建和销毁 ServletRequestListener： ServletRequest的创建和销毁 主要接口ServletContextServlet与Servlet容器之间直接通信的接口,一个web应用只独有一个ServletContext，由web容器实现 用于在web应用范围内存取共享数据,如setAttribute(String name, Object object)，getAttribute() 获取当前Web应用的资源，如getContextPath() 获取服务器端的文件系统资源，如getResourceAsStream() 输出日志，如log(String msg) ： 向Servlet的日志文件中写日志 在具体ServletContext 实现中，提供了添加Servlet，Filter,Listener到ServletContext里面的方法 ServletRequest封装了客户端请求的所有信息，如果使用HTTP协议通信则包括HTTP协议的请求行和请求头。HTTP协议对应请求对象类型是HttpServletRequest类 获取HTTP协议请求头部，如getHeader、getHeaders 获取请求路径，如getContextPath、getServletPath 获取cookie的方法，如getCookies 获取session的方法，如getSession,session是存储在服务器内存中，返回响应的时候会写入浏览器一个sessionId的cookie，用来标示这一个会话 ServletResponseServlet通过ServletResponse对象来生成响应结果，定义了一系列与生成响应结果相关的方法，如: setCharacterEncoding() —— 设置相应正文的字符编码； setContentLength() —— 设置响应正文的长度； HttpSeesion服务器端为保存状态而创建的一个特殊的对象 与servletContext区别作用范围不同 HttpSession是针对每一个客户端浏览器单独有一个 ServletContext是针对每一个WEB应用程序有一个 存活时间不同： HttpSession第一次访问服务器，服务器端调用request.getSession()时创建，访问间隔时间超过30分钟就销毁。 ServletContext服务器启动时创建，服务器停止时销毁 Tomcattomcat等容器其实就是web服务的实现，暴露端口，按照特定资源URL找到处理的servlet。然后处理请求","tags":[{"name":"java-web","slug":"java-web","permalink":"https://xulilei.github.io/tags/java-web/"}]},{"title":"Spring IOC&AOP","date":"2020-07-25T06:52:01.000Z","path":"2020/07/25/秋招复习之springIOC AOP/","text":"秋招复习之springIOC AOPSpring IOCSpring 核心容器是整个spring的核心模块，其他的功能需要依赖 IOC：inversion of controller 控制反转：是面向对象编程中的一种设计原则，可以用来降低代码之间的耦合度 依赖注入（Dependency Injection，简称DI）：是IOC常见的实现方式 为什么要使用IOC？ 将对象之间的相互依赖关系交给IOC容器管理，并由IOC完成对象的注入，会大大简化程序的开发 如何将bean注册到容器中去 xml：XML添加对应约束 set注入和构造器注入 annotation：XML添加对应约束，打开注解扫描component-scan @component修饰想要IOC管理的类 javaconfig：指定@Configuration配置类，开启注解扫描@ComponentScan @component修饰想要IOC管理的类 @Bean 在配置类中创建新对象并交给IOC Import：在配置类上通过import直接注册组件 实现了ImportBeanDefinitionRegistrar接口的类 ImportBeanDefinitionRegistrar提供了BeanDefinitionRegistry 实现ImportSelector接口的类 返回的是一个数组，可以批量的注册 自动装配只要在类的定义中提供依赖关系，Spring根据配置类型自动装配 @ Autowired 默认按照ByType匹配，会遇到匹配到相同类型多个Bean的问题 @ Qualifier(“bean的名字”) @ primary 指定主数据源 @ Resource 默认按照ByName匹配 可以通过@Resource(name=”beanName”) 指定被注入的bean的名称 作用域5种作用域，分别为 singleton、prototype、request、session和global session ，仅当用户使用支持 Web 的 ApplicationContext 时，最后三个才可用 singleton：单例模式 Spring IoC 容器中只会存在一个共享的 Bean 实例，无论有多少个Bean 引用它，始终指向同一对象 单例模式的bean是线程安全的吗？ 不是，由于所有线程操作的都是同一个bean，因此写操作会存在线程安全的问题，最简单的方法是将作用域改为prototype prototype：原型模式 每次通过 Spring 容器获取prototype定义的bean时，容器都将创建一个新的 Bean实例，每个Bean实例都有自己的属性和状态 request：一次request一个实例 在一次 Http 请求中，容器会返回该 Bean 的同一实例。而对不同的Http请求则会产生新的Bean，仅在当前Http Request内有效,随着当前 Http 请求结束而销毁 session：一个session，一个实例 global session：一个全局的Http Session中，容器会返回该 Bean 的同一个实例 两种IOC容器区别1、实例化bean对象时机不同，beanfactory是在用户需要时才会去实例化这个对象，因此属于懒加载。而applicationContext除了手动设置加载类型为懒加载外，会在容器创建时就实例化所有的bean对象，是即时加载 2、beanFactory是最原始的面向spring的工厂，它不支持aop，web等spring组件，而applicationContext则支持 3、继承关系，applicationContext继承了beanFactory对象，拥有beanFactory的所有功能外，更拓展了beanfactory，因此现在绝大多数的情况下都不再使用beanfactoty作为程序的入口 PostProcessor BeanPostProcessor：是Bean的后置处理器，bean创建对象初始化前后工作 BeanFactoryPostProcessor：是BeanFactory的后置处理器 BeanDefinitionRegistryPostProcessor：继承自BeanFactoryPostProcessor，多了postProcessBeanDefinitionRegistry可以向容器中注入BeanDefinition Bean循环依赖循环依赖的原因spring实例化一个bean的时，先分两步进行，首先createBeanInstance，然后再populateBean。为bean注入属性时，是先通过递归的方式实例化这个Bean依赖的bean。如果在这其中，形成了循环，那么就会导致循环依赖。 解决方案通过三级缓存，一级缓存为singletonObjects，存放的是完全实例化的bean，可以直接使用 二级缓存：earlySingletonObjects，存放早期bean的引用，尚未装配属性 三级缓存：singletonFactories，三级缓存，存放实例化完成的bean工厂 主要过程是，假设A依赖B，B依赖A： A一次执行doGetBean，查询缓存，createBean创建实例，实例化完成后放入三级缓存singletonFactories，接着执行populate方法装配时，发现依赖了B对象，此时以同样的方式执行B的bean创建，同样的会发现有一个属性是A对象，因此再次执行创建A bean，但执行到getSingleton时，从三级缓存中查询到了A对象未装配完成的实例，此时直接返回A，B就完成了装配，并加入一级缓存singletonObjects中，A自然也就装配完成了 Aware接口在创建对象时，调用规定方法可以注入Spring底层的组件，都通过相关的processor来处理 如ApplicationContext、BeanFactory、BeanName等 Bean的生命周期就是createBean的过程1、首先通过bean的注册器，将bean的各种信息，比如属性，构造方法参数，是否单例等信息转换成beanDefinition并保存在beanDefinitionMap中 2、从BeanDefinitionMap中取出bean对应的BeanDefinition，并实例化 3、对实例化的 Bean 进行配置，polulate设置属性 4、实现了.Aware接口的方法会在这里调用，即为实现该接口的对象传入对应的组件， 比如实现 BeanFactoryAware 接口，调用 setBeanFactory()等 5、如果存在与 bean 关联的任何 BeanPostProcessors，则调用 postProcessBeforeInitialization() 方法。 6、如果为 bean 指定了 init 方法，会按照@PostConstruct–&gt;InitializingBean–&gt;init method调用。 7、最后，如果存在与 bean 关联的任何 BeanPostProcessors，则将调用 postProcessAfterInitialization() 方法。 8、如果为 bean 指定了destroy 方法，会按照 PreDestroy–&gt;DisposableBean–&gt;destroy-method调用销毁方法 GetBean的过程1、geBean-&gt;getSingleton：先从一个singltonObject的concurrentHashMap中尝试获取bean，如果获取不到则执行createBean 2、先递归实例化这个bean依赖的bean，完成后通过resolveBeforeInstantiation判断能否获得这个对象的代理对象（如果这个对象被AOP增强了，那么就从这里拿到代理对象），如果获取不到则执行doCreateBean方法 3、bean的生命周期 容器初始化过程主要工作在refresh方法中 prepareRefresh()：初始化工厂类准备工作：包括设置 启动时间，是否激活标志位，初始化属性源配置 obtainFreshBeanFactory()：这一步初始化了一个beanFactory（DefaultListableBeanFactory），内部维护了一个BeanDefenitionMap，里面存放了后续定义bean的beanDefenition。 prepareBeanFactory(beanFactory)：会手动注册一些特殊的 bean，比如类加载器，ApplicationContextAwareProcessor用来注册ApplicationContext invokeBeanFactoryPostProcessors：先执行我们自己定义的BeanDefinitionRegistry，接着执行系统定义的BeanDefinitionRegistry，最后执行我们自己定义的BeanFactoryPostProcessor 这里要特别特一下，系统定义的BeanDefinitionRegistry中有个ConfigurationClassProcessor，用来处理@Configuration类的 registerBeanPostProcessors(beanFactory)：向Bean工厂注册BeanPostProcessor 初始化事件派发器，监听器等 finishBeanFactoryInitialization(beanFactory);最重要的方法就是preInstantiateSingletons()，初始化所有单实例Bean 先执行getBean()，如果拿不到则进行，doCreateBean的过程 finishRefresh();完成容器的初始化操作 Spring AOP基本概念使用场景AOP的编程思想就是把这些问题和主业务逻辑分开，达到与主业务逻辑解耦的目的。使代码的重用性和开发效率更高 日志记录、权限验证、效率检查事务管理、exception等等 增强术语target对象也称原始对象中的方法被称为jion point连接点，连接点的集合被称为point cut切点，连接点经过AOP增强的过程叫weaving织入，什么时候织入，织入到哪里被称为advice通知，生成新的对象叫Proxy代理对象 Aspect是一个实现交叉问题的类，可以使用@Aspect 注解将类声明为 Aspect。 Advice是针对特定 JoinPoint 采取的操作。可 以将 Advice 视为 Spring 拦截器（Interceptor）或 Servlet 过滤器（filter） JoinPointJoinPoint 是应用程序中的特定点，在 Spring AOP 中，一个JoinPoint 代表一个方法的执行。 Pointcut是与 JoinPoint 匹配的正则表达式，是JoinPoint的集合，用于声明切入点表达式。 如何声明一个通知切入点表达式 execution：用于匹配方法执行 join points连接点，粒度最小，使用最多 详细实例 @Pointcut(“execution(* com.chenss.dao..(..))”)//匹配com.chenss.dao包下的任意接口和类的任意方法 @Pointcut(“execution(public * com.chenss.dao..(..))”)//匹配com.chenss.dao包下的任意接口和类的public方法 @Pointcut(“execution(public * com.chenss.dao..())”)//匹配com.chenss.dao包下的任意接口和类的public 无方法参数的方法 @Pointcut(“execution(* com.chenss.dao..(java.lang.String, ..))”)//匹配com.chenss.dao包下的任意接口和类的第一个参数为String类型的方法 @Pointcut(“execution(* com.chenss.dao..(java.lang.String))”)//匹配com.chenss.dao包下的任意接口和类的只有一个参数，且参数为String类型的方法 @Pointcut(“execution(public * *(..))”)//匹配任意的public方法 @Pointcut(“execution(* te*(..))”)//匹配任意的以te开头的方法 @Pointcut(“execution(* com.chenss.dao.IndexDao.*(..))”)//匹配com.chenss.dao.IndexDao接口中任意的方法 @Pointcut(“execution(* com.chenss.dao...(..))”)//匹配com.chenss.dao包及其子包中任意的方法 几种类型的通知 @ Before（”pointCut1()&amp;&amp;!pointCut2()”）：满足pointCut1()切点不满足pointCut2()切点的连接点（方法）之前执行 @ After（”pointCut1()”）：满足pointCut1()切点的连接点（方法）之后执行 @ AfterReturning：正常返回后运行 @ AfterThrowing：抛出异常时运行 @ Around：围绕连接点执行 联合使用@Component@Aspectpublic class aopAspect &#123; @Pointcut(\"execution(* xu..*(..))\")//切入点表达式 public void pointCutA() &#123; &#125; @Before(\"pointCutA()\")//通知，对具体切入点所做的操作 public void before() &#123; System.out.println(\"before\"); &#125;&#125; AOP 两种代理方式AOP 代理主要分为静态代理和动态代理两大类，静态代理以 AspectJ 为代表；而动态代理则以 Spring AOP 为代表 静态代理（AspectJ AOP）静态代理是指使用 AOP 框架（如AspectJ）提供的命令进行编译，从而在编译阶段就可生成 AOP 代理类，基于字节码操作，因此也称为编译时增强； 动态代理（Spring AOP）动态代理则在运行时借助于 JDK 动态代理、CGLIB 等在内存中“临时”生成 AOP 动态代理类，是基于代理的，因此也被称为运行时增强。 JDK动态接口代理：主要涉及到 Proxy 和 InvocationHandler。InvocationHandler 是一个接口，通过实现该接口定义织入逻辑，并通过反射机制调用目标类的代码，动态将织入逻辑和业务逻辑编制在一起，生成目标类的代理对象。 CGLib动态代理：是一个强大的高性能， 高质量的代码生成类库，可以在运行期扩展 Java 类与实现 Java 接口， CGLib 封装了 asm，可以在运行期动态生成新的 class。和 JDK动态代理相比较： JDK只能为接口创建代理实例，而CGLib可以为类创建动态代理。 AOP实现原理 从一个注解说起@ EnableAspectJAutoProxy，该注解向容器中注入了AnnotationAwareAspectJAutoProxyCreator对象 AnnotationAwareAspectJAutoProxyCreator本质是InstantiationAwareBeanPostProcessor，会尝试在对象创建前获得该对象的代理对象 拦截后做了什么呢？ PostProcessorAfterInitialization：warpIfNecessary()获得代理对象 或取当前所有增强方法（通知方法）：找到能在当前Bean使用的增强器，通过切入点表达式进行匹配 如果当前Bean需要增强，通过ProxyFactory创建当前Bean的代理对象：通过是否实现接口等自动决定 JDK动态代理 cglib动态代理 拦截目标方法的执行，当执行目标方法的时候，代理对象就会执行通知方法中的逻辑 容器中保存了代理对象的详细信息，比如目标对象，增强器等、会生成一个拦截器链拦截目标方法的执行 面试答：Aop的实现原理从一个注解说起，@EnableAspectJAutoProxy。这个注解向容器中import了一个AnnotationAwareAspectJAutoProxyCreator对象，这个对象本质是一个InstantiationAwareBeanPostProcessor，他有两个主要的方法，一个是ApplyBeanPostProcessorBeforeInstantiation，这个方法会在createBean前尝试通过resolveBeforeInstantiation拿到代理对象，如果这个bean是aop的targetsource，则不用通过之后的createBean创建对象，而是通过另一个ApplyBeanPostProcessorAfterInitialization方法中的warpifNecessary去创建代理对象，通过切入点表达式找到能在当前bean使用的adivsor，通过proxyFactory创建当前Bean的代理对象，通过是否是接口自动决定，如果基于接口则通过JDK动态代理，基于类则通过cglib动态代理，这个代理对象包含包含target source和advisor等信息，会生成一个interceptor链，当目标方法需要执行则这个代理对象就会执行advisor中的逻辑","tags":[{"name":"Spring","slug":"Spring","permalink":"https://xulilei.github.io/tags/Spring/"}]},{"title":"中间件MQ","date":"2020-07-22T02:34:14.000Z","path":"2020/07/22/秋招复习之中间件/","text":"秋招复习之中间件MQ1、MQ的使用场景有哪些？异步：将非必要的逻辑业务写入消息队列，异步执行，加快响应速度，比如常见的发送短信验证码等 削峰：比如短时间内大量请求数据库，可以先存储进入mq消息队列，数据库再慢慢消费这些消息 解耦：对于新增业务模块可以单独扩展后写入消息队列，而不用加入原来的逻辑中，只需要订阅相应的消息队列即可 2、MQ有哪些角色生产者：消息的创建者，负责创建和推送数据到消息服务器 消费者：消息的接收方，用于处理数据和确认消息 消息服务器：就是RabbitMQ本身 3、组成部分channel信道channel 是真实 TCP 连接上的虚拟连接，发布消息订阅队列所有命令都是通过 channel 发送的，且每一个 channel 有唯一的ID。 RoutingKey路由键生产者在将消息发送给Exchange的时候，一般会指定一个routing key， 来指定这个消息的路由规则，而这个routing key需要与Exchange Type及binding key联合使用才能最终生效 exchange交换器生产者将消息发送到Exchange，内部保存了 binding 关系的查找表，由Exchange根据关系表将消息路由到一个或多个Queue中，Exchange并不存储消息。 bindingKey绑定键用于绑定queue和exchange之间的关联，就是基于路由键将交换器和消息队列连接起来的路由规则 queue消息队列消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。等待消费者连接到这个队列将其取走 4、Vhost作用即mini-RabbitMQ server，其内部含有独立的queue、bind、exchange等，vhost可以作为应用隔离的手段，即不同的应用跑在不同的vhost中 5、为什么使用rabbitMq1、像activeMq RocketMq kafka等响应时间是ms级，而rabbitMq则可以达到us级，性能出色 2、采用erlang语言开发，并发性能好，管理界面清晰 3、有相对比较活跃的开源社区，支持比较好 6、rabbitMq消息是如何发送的首先rabbitMq和server需要建立tcp连接，之后会创建一条channel信道，所有的消息都是通过这条信道传输的 7、有哪几种路由模式Direct直接： 消息中的routingkey如果和binding key 一致，交换器就将消息发到对应的队列中。它是完全匹配、单播的模式 Fanout分发： 每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。每个队列都会获得一份复制的消息 topic主题：可以使来自不同源头的消息能够到达同一个队列 8、如何确保生产者将消息正确的发送到了RabbitMQ？RabbitMQ提供transaction和confirm模式来确保生产者不丢消息 transaction机制发送消息前，开启事务，然后发送消息，如果发送过程中出现什么异常，事务就会回滚,如果发送成功则提交事务，这种方式有个缺点：吞吐量下降； confirm模式confirm模式是异步的，生产者在等待确认的同时，可以继续发送消息 生产者将信道设置成confirm模式，所有在该信道上发布的消息都会被指派一个唯一的ID，一旦消息被投递到所有匹配的队列，或者消息被持久化后，rabbitMQ就会发送一个包含消息的唯一ID的ACK信息给生产者 如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。 9、如何确保消费者消费了消息消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ才能安全地把消息从队列中删除。这里并没有用到超时机制，RabbitMQ仅通过Consumer的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ给了Consumer足够长的时间来处理消息。 下面罗列几种特殊情况： 如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要根据bizId去重） 如果消费者接收到消息却没有确认消息，连接也未断开，则RabbitMQ认为该消费者繁忙，将不会给该消费者分发更多的消息。 10、如何保证避免消息重复消费两个ID，一个生产者发送的inner-msg-id，一个消费时bizId。 在消息生产时，MQ内部针对每条生产者发送的消息生成一个唯一的inner-msg-id，作为去重和幂等的依据，避免重复的消息进入队列； 在消息消费时，要求消息体中必须要有一个bizId（对于同一业务全局唯一，如支付ID、订单ID、帖子ID等）作为去重和幂等的依据，避免同一条消息被重复消费。 11、如何保证使用rabbitMQ过程中不丢失数据生产者丢失transaction机制和confirm模式 消息队列丢失一般是开启持久化磁盘的配置解决消息队列丢失。 持久化配置是和confirm机制配合使用的，在消息持久化磁盘后，会生产者发送一个Ack信号。这样，如果消息持久化磁盘之前，rabbitMQ宕机了，那么生产者收不到Ack信号，会自动重发。 消费者丢失主要是因为消费的时候，刚消费到，还没处理，结果进程挂了，而rabbitmq认为已经消费了，数据就丢了。 这个时候关闭rabbitmq自动ack，即确保处理完的时候，再手动ack。这样的话，如果消费者还没处理完就挂掉，rabbitMQ就无法收到ack，就会认为消费者还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。 12、如何保证RabbitMQ消息的顺序性单线程消费保证消息的顺序性； 对消息进行编号，消费者处理消息时根据编号处理消息 13、死信消息 消息被拒绝并且设置 requeue 参数的值为 false 消息过期，且未被消费 队列达到最大的长度 14、rabbitMQ如何持久化rabbitTemplate调用converAndSend时默认就是持久化","tags":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://xulilei.github.io/tags/rabbitMQ/"}]},{"title":"redis28问","date":"2020-07-19T10:27:57.000Z","path":"2020/07/19/秋招复习redis/","text":"秋招复习redis之28问1、为什么要用redis/缓存高性能：对于热点数据，如果不做缓存，每次都要通过硬盘读取数据，会造成性能降低。 高并发：直接操作内存中数据的并发量是远远大于操作数据库的，添加缓存可以提升系统的并发度 2、redis数据类型String：包括数字，主要用于统计数据 Hash：包含键值对的散列表，适合存储对象，比如用户信息，订单信息等 List：双向链表，比如消息列表，还可以做分页 Set：不重复，自然序的列表数据，可判断一个成员是否在一个set内，比如好友列表 Sorted Set：按照一个权重参数score进行有序排列，多用于自定义的排行列表 3、为什么使用redis而不使用map/guava/cache等本地缓存首先缓存分为分布式缓存和本地缓存： 1、map/guava/cache等属于本地缓存，每个jvm实例都对应一份本地缓存，生命周期随着jvm的结束而结束，多个JVM实例会导致缓存不一致 2、redis是一种分布式缓存，多实例共享redis缓存，具有缓存一致性，并且redis支持的数据结构也优于本地缓存 4、redis为什么这么快1、redis完全基于内存，内存的读写速度远超硬盘 2、redis采用的是单线程epoll多路复用模型，是一种非阻塞I/O 3、redis单线程模型没有切换线程带来的开小 5、RDB持久化通过创建快照获取内存中数据某个时间点的副本，并将其存储到磁盘中，持久化的是数据 触发方式1、save 900 1：900秒后至少一个数据发生变化 2、save 300 10：300秒后至少10个数据放生变化 3、save 60 10000：60秒后至少10000个数据发生变化 过程：1、则父进程会fork一个子进程，fork期间父进程是阻塞的，无法处理其他命令 2、父进程fork完成后，不再阻塞，可以继续处理请求 3、子进程开始执行创建快照文件，并对原来的RDB文件进行替换，替换完成告知父进程，并自动结束 6、AOF持久化相比于RDB的数据持久化，AOF持久化的是操作redis的命令，在需要时通过命令恢复数据 触发方式：appendSync-always：即每次有数据修改就写入 appendSync-everySec：每秒钟写入一次 appendsync no ：交由操作系统决定 AOF重写由于存储的是操作redis的命令，随着redis的运行，aof文件会越来越大，此时会触发AOF重写 过程1、父进程会fork一个子进程，这段期间父进程是阻塞的 2、父进程接触阻塞，并维护一个缓冲区，记录子进程重写期间对数据改动的命令 3、子进程执行AOF重写没有读取上一个aof文件，而是将当前内存中的数据通过命令重新写入新的AOF文件 4、子进程AOF重写结束后，父进程将缓冲区的命令追加到aof的末尾，使得数据状态一致 7、AOF/RDB对比 RDB AOF 内容 全量备份所有数据 增量备份修改命令 体积 小 大 恢复速度 快 慢 安全性 丢失数据 根据策略，every sec可能会丢失一秒数据 8、混合持久化重写时，这一刻的内存rdb快照数据和AOF修改命令日志文件存在一起，都写入新的aof文件，快速加载的时候优先加载aof，避免丢失过多的数据 由于AOF文件中不单是AOF格式还有RDB的部分，因此可读性较差， 9、redis数据过期删除策略立即删除立即删除能保证内存中数据的最大新鲜度，因为它保证过期键值会在过期后马上被删除，其所占用的内存也会随之释放。但是立即删除对cpu是最不友好的。因为删除操作会占用cpu的时间，如果刚好碰上了cpu很忙的时候，会给cpu造成额外的压力,所以并不适合用来处理大量的时间事件。 惰性删除惰性删除是指，某个键值过期后，此键值不会马上被删除，而是等到下次被使用的时候，才会被检查到过期，此时才能得到删除。所以惰性删除的缺点很明显，浪费内存。 定时删除从上面分析来看，立即删除会短时间内占用大量cpu，惰性删除会在一段时间内浪费内存，所以定时删除是一个折中的办法。定时删除是：每隔一段时间扫描部分设置了过期时间的key，删除已经过期的数据。此种做法可以减少删除操作对cpu的影响。也有效的减少了因惰性删除带来的内存浪费。 10、redis内存淘汰机制内存淘汰策略的选取并不会影响删除策略的执行，是在内存空间不足时采取的申请空间的策略 volatile-lru：从已设置过期时间中，淘汰最近最少使用的least recently used volatile-lfu：从已设置过期时间中，淘汰最不经常的数据least frequently used allkeys-lru：在全局键空间中，淘汰最近最少使用的key allkeys-lfu：在全局键空间中，淘汰最不经常使用的key 11、redis如何保证数据都是热点数据删除策略和内存淘汰策略结合使用 12、redis线程模型单线程多路复用模型多个套接字、IO多路复用程序、事件队列、文件事件分派器、事件处理器 消息处理流程 通过epoll多路复用程序来同时监听多个套接字 当被监听的套接字准备好执行连接应答(accept)、读取(read)、写入(write)、关闭(close)等操作时，与操作相对应的文件事件就会产生 尽管多个文件事件可能会并发地出现，但redis会将所有产生事件的套接字都推到一个有序队列里面 然后通过这个队列，以有序、同步、每次一个套接字的方式向文件事件分派器传送套接字，当上一个套接字产生的事件被处理完毕之后才会继续向文件事件分派器传送下一个套接字 13、redis内存优化用好redis的几种基本数据类型，让数据更紧凑的放置在一起 比如一个对象有几种属性，不要为每个属性设置单独的key，而是应该把这个对象的属性存储到这个对象的hash中去 14、redis事务特性1、redis不支持回滚，而是继续执行余下的任务，因此事务没有原子性，但是事务中的命令是原子操作 2、如果某个事务中的命令错误，那么所有命令都不会执行，具有一致性 3、如果某个事务出现运行错误，那么正确的命令仍然会得到执行 4、由于redis同一时间只能执行一个事物，因此具有隔离性 15、redis事务实现1、watch：相当于java中的cas是一个乐观锁机制，当一个事务开始执行，其他事务就不会执行 2、multi：用于开启一个事务，当multi执行后，redis继续接受消息，并将这些命令放入一个事务块队列 3、exec：执行事务队列中的命令 4、discard：清空事务队列，放弃执行事务，退出事务模式 16、redis主从模式目的将数据复制给从服务器，写命令发送给主服务器，读命令则发送给从服务器，从而实现读写分离 同步策略主从刚刚连接时执行全量同步，全同步完成后执行增量同步 同步过程1、从服务器连接主服务器，发送sync同步命令 2、主服务器接收到从服务的sync命令后，开始RDB持久化，并通过缓存区保存持久化期间写命令 3、主服务器完成RDB持久化后，向所有从服务器发送RDB快照文件，并继续保存期间写命令 4、从服务器受到RDB快照后，载入快照文件，并继续使用旧数据提供读服务 5、主服务器发送完快照文件后开始向从服务器发送缓冲区的写命令 6、从服务器完成对快照文件的载入后丢弃旧数据，并增量同步来自主服务器的写命令 Tips：具体搭建过程见项目实操部分 17、redis哨兵模式工作流程哨兵是一个独立的进程，也是一个redis服务器，但是并不提供数据服务，端口号默认为26379，而是监控提供数据服务的主从服务器，当发现主服务器宕机会自动的将从服务器切换成主服务器，并通知其他的从服务器，实现自动故障转移 详细工作监测：第一个哨兵获取master状态后，会根据master的信息获取该master主机下的从服务器，接着第二个哨兵以同样的方式获取信息，并与第一个哨兵共享信息，并检测哨兵是否咋子先，依次类推 自动故障转移：当一个哨兵认为master挂掉后，会通知其他哨兵，并将服务器状态设置为s_down。此时会触发哨兵投票机制，当半数以上的哨兵发现服务器挂了，会将master状态设置为o_down，并下线这个master，选取响应快的slave作为新的主节点并告知其他从服务器 Tips：具体搭建过程见项目实操部分 18、集群cluster模式为什么采用分布式集群即使是哨兵模式，也是一种全量存储模式，每个redis服务器存储的都是完整的数据，浪费内存 分布式集群每个节点存储一定哈希槽区间的数据，通过哈希的方式，将数据分片到这些槽中，解决了哨兵模式下内存浪费的情况 哈希槽具体方案1、通过一个散列性良好哈希算法，将数据均匀的分散到16384个哈希槽中，至少需要3主3从 2、每个主从节点均匀分片存储一定哈希槽区间的数据 3、数据先写入该数据所在哈希槽的主节点，再同步到从节点 4、读取数据时，每个节点会将key指向正确的节点 5、每个节点之间通过16379端口通信 节点间的内部通信节点间通过cluster bus来通信，基于gossip流言协议，就是节点间彼此不断交换信息，一段时间后每个节点都知道其他节点的详细信息，用以进行监测，自动故障转移 gossip协议：meet（加入），ping（发送信息），pong（回复信息），fail（下线消息） 问题：哈希槽的存储是对服务器的数量取模，使得每个服务器均匀分片存储一定区间的哈希槽。这样的问题在于当服务器的数量发生改变的时候，数据的位置就会相应的发生改变，会导致缓存雪崩 一致性哈希具体方案使用的哈希值对2的32次方进行取模，将整个哈希值空间组织成一个顺时针的虚拟的圆环，即0和2^32-1会在0点钟方向会和 根据各个服务器的ip或者主机名等关键字作一个哈希，确定在哈希环上的位置 再对数据key以同样的方式进行哈希，并确定数据在哈希环上的位置，从此位置沿顺时针行走，遇到的第一个服务器就是数据存储的服务器 当服务器数量发生变化时，只会影响存储在这个服务器上的数据，其他不受影响 19、缓存雪崩指缓存同一时间大面积的失效，请求直接落到数据库上，造成数据库短时间内承受大量请求而崩掉 解决方案事前：尽量保证redis服务的稳定，宕机尽快补上，这是防止缓存雪崩的根本，比如通过主从，哨兵，集群等方式。如果是因为短时间内大量key失效导致的缓存雪崩，则通过离散化失效时间来防止 事中：通过hystrix限流保证不会有大量线程对数据库进行一次性读写，以及临时时间本地缓存对热点数据作二级缓存 事后：如果发生了缓存雪崩，则利用redis持久化尽快恢复 20、缓存穿透指缓存和数据库中都没有的数据，穿透了过去，导致所有的请求都落在数据库上，造成数据库短时间承受大量请求而崩掉 解决方案：提前做好参数校验，比如用户身份的鉴权，满足条件好再给予发送请求的权利，其次就是规定参数格式，拒绝不合法的参数 对于同一个key的反复攻击，设置key-null在缓存中存储，但对于key快速变化的意义不大 布隆过滤器：由hash函数和位数组构成的一个可以快速查询数据是否存在或者一定不存在的过滤器，会拦截一个一定不存在的数据 布隆过滤器原理底层是一个bit数组，对于每个映射到过滤器中的值，都通过多个哈希函数生成多个哈希值，并将哈希值对应的位置都值为1.查询时，如果值对应的多个哈希函数的值位置都为1，则判断该值可能存在，反之如果有一个不为0则判断这个值一定不存在 21、缓存击穿指缓存中没有，但数据库中由的数据。与缓存雪崩不同的是，缓存击穿是大量请求查询同一数据 解决方案：1、对热点数据设置长时间不过期 2、对于热点数据采用加锁的形式，比如semaphore等 Tips：具体搭建过程见项目实操部分 22、缓存预热系统上线后，将相关的热点数据直接加载进入缓存系统。用户就不用在第一次查询时，先走数据库而是直接查询缓存 23、缓存降级目的是为了防止redis发生的故障导致数据库跟着一起发生雪崩问题，是一种保护数据库的机制 比较常见的做法是redis出现问题，不去查询数据库而是直接返回默认值给用户 24.redis分布式锁什么情况下使用分布式锁分布式架构下对数据有精确控制的情况，比如商品秒杀 为什么不能用syncronized锁在分布式架构下，存在多个服务实例时，由于一个对应对应一个JVM，而syncronized是JVM级别的锁，因此可能会发生超卖的问题 redis锁为什么可以用？1、redis是单线程模型，采用一个队列将并发访问变成串行访问 2、基于redis的setnx命令，如果key存在不作任何操作，key不存在才可以添加，key可以设置成这个商品的名称 3、添加成功后获取锁，执行逻辑代码，最后删除key 25、redis分布式锁基本实现发生的问题和可以优化的点1、死锁问题原因：获得锁后，执行代码逻辑过程遇到长时间等待等错误导致key无法删除而造成其他请求无法执行造成死锁， 解决方法：是对key设置一个过期时间，并且用try catch包围加锁过程 2、但是会造成新的问题–无法保证互斥性原因：已经超过key的过期时间，key已经被删除了，但是上一个逻辑代码由于某一些原因还没有执行结束，这时便存在多个进程操作一个资源，是去了互斥性 解决方案：通过redisson提供的加锁机制，每隔1/3时间检查是否还持有锁，如果持有就延长锁的时间，保证了互斥性 3、又会回到死锁的问题（自己乱猜的，问到再说）原因：即一个进程一直持有这把锁，不释放。 解决方案：那么就需要一个控制逻辑执行时间的事务，这个时间要略微小于key过期的时间，时间允许范围内，如果逻辑没有执行完毕那么就回滚并结束进程。 26、主从架构下的redis分布式锁1、单点局限性原因：在单点模式下，如果这个redis实例挂了，那么整个服务就挂了 解决方案：搭建主从模式，这样的话即使一个redis宕机了，其他也能提供服务 2、锁丢失的情况原因：在主节点向从节点写入lock key的过程中，如果恰好此刻主节点宕机，并且lock key还没有写入新主节点，那么就会使得其他进程仍然可以获得该锁 解决方案：redlock方案 27、基于reddison的redLock实现分布式锁抛弃主从模式，直接使用多个master，相互独立，这样就保证了在master宕机的情况下，不会出现从服务器数据丢失的情况 基本原理1、设置两个时间，一个是锁失效时间。一个是请求超时时间这个时间要远小于超时时间，防止长时间等待redis服务器响应 2、依次尝试从n个实例，使用相同的key和value获取锁，当且仅当超过半数的锁获取成功，且时间小于锁失效的时间，锁才算获取成功 3、如果获取失败，则应该在已经添加了锁的服务器上解锁 Tips：具体搭建过程见项目实操部分 28、缓存是数据库双写一致性的问题1、如果一定要做到一致性，那么可以采用串行化的方式，但是开销太大，性能大幅降低 2、如果允许暂时不一致的情况，则遵循先写数据库的原则，因为如果缓存写入成功，而数据库没有写成功，那么之后高并发的读取都是错误的数据 3、正确的做法是先写入数据库，再将缓存中的key设置为无效，数据库修改成功后再返回来修改缓存，这样的话。最多在写入数据库时缓存短暂失效，但写回后即可重新生效。而不会发生误读的情况 29、redis实现延迟队列大概步骤为： 1、将整个redis当作消息池，以kv的形式存储消息 2、使用ZET作优先队列，按照score维持优先级 3、使用list结构，以先进先出的方式消费 4、ZSet和list存储消息地址（对应消息池的每个key） 5、还需要维持Zset和list的一个路由关系 6、使用TTL实现一个消息延迟 30、redis实现异步队列使用redis中的list（列表）实现异步消息，使用rpush/lpush操作插入队列消息，使用lpop和rpop来出队消费消息 会出现队列空的情况，会造成一个空轮询的情况，此时可以使用命令blpop、brpop，当队列没有数据的时候，会立即进入休眠状态。","tags":[{"name":"redis","slug":"redis","permalink":"https://xulilei.github.io/tags/redis/"}]},{"title":"mysql之底层原理","date":"2020-07-18T05:41:17.000Z","path":"2020/07/18/秋招复习mysql之底层原理/","text":"秋招复习mysql之底层原理基础知识数据库三大范式1、每个列都不可以再拆分 2、在第一范式的基础上，非主键列完全依赖于主键列，而不是依赖主键列的一部分 3、在第二范式的基础上，非主键列只依赖与主键列，不依赖于其他主键列、 Binlog是mysql数据库的二进制日志，用来保存数据库除了查询之外的记录，通过mysqlbinlog查看 三种模式statement：每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能，但是无法记录一些函数比如sleep之类，可能会导致问题 row：基于行的复制(row-based replication, RBR)：不记录每一条SQL语句的上下文信息，仅需记录哪条数据被修改了，修改成了什么样子了。 mixed：用statement记录，记录不了的使用row 存储引擎InnoDB支持事务和行级锁，外键，采用密集索引，支持mvcc 密集索引：密集索引的data域存储了完整的数据记录包括相邻叶子节点的信息，决定了叶子节点的物理排列顺序，因此一个表只能创建一个密集索引，辅助索引则存储了对应的主键，具体过程为：在根据主键索引搜索时，直接找到索引所在的节点即可取出数据，在根据辅助索引查找时，先取出主键索引的值，再走一遍主键索引 四大特性插入缓冲：每次插入数据时，先判断要插入的数据页是否在缓存中，如果在则直接插入，否则先放入一段buffer缓冲区，再插入 预读：根据请求，预先读取一部分数据在缓冲区中 自适应哈希：对于热点数据，则对二级索引页自动建立hash索引方便下次读取 二次写：为了防止数据库在数据写入磁盘奔溃导致本次数据丢失的情况 MyISAM不支持事务和行级锁，只支持表级锁，采用稀疏索引，不支持外键，不支持MVCC，强调性能 稀疏索引：稀疏索引的data域只存储了主键和数据地址等部分信息，具体过程过程为：根据索引取出data域的数据保存的地址，再根据地址读取相应的数据 索引基本认识什么是索引？索引是一种数据结构，以协助快速查询，更新数据库中的数据，更通俗的说，索引就相当于多级目录 为什么要使用索引避免全表扫描，提升查询效率 索引的数据结构有哪些B+Tree索引，hash索引 hash索引的缺点1、仅能满足“=”，“in” 不能使用范围查询 2、不能避免全表扫描 3、当哈希值大量相同时，效率会退化 为什么使用B+树作为索引二叉查找树左子树的值小于根的值，右子树的值大于根的值，这种会遇到退化成链表的情况，时间复杂度由O（logN）变为O（n） 二叉平衡树满足二叉查找树的条件，且任何节点的左右子树的高度差最大为1，控制时间复杂度为O（logN），但是其添加删除数据的操作会频繁的涉及到左旋右旋，因此也不适合作为索引 红黑树红黑树在二叉搜索树的基础上又对增删的进行了改进，使得不用频繁旋转，但是由于每个节点只能存储一个数据，因此随着数据增多，树的深度会很深，查找数据经历的IO次数会太多 B-treeInnoDB是以页为存储单位读取数据的，每个页都有索引有助于快速定位数据的位置，虽然每个节点可以存储多份数据，但B-tree每个节点都包含data值，与B+Tree相同索引空间下，会导致页存储的索引数量受限，会造成树的深度过深，查找到最终数据经历的I/O次数太多，并且数据的删除与添加也很不便 B+tree是B-tree的一种优化，相较于B-tree，B+tree主要有以下几点不同： 1、非叶子节点只存储定位索引的信息，相当于操作系统中的多级页表。带来的好处是非叶子节点存储更多的索引定位信息，大大降低树的高度，减少磁盘IO的次数 2、所有数据都存储在叶子节点上，且叶子节点之间存在链指针。带来的好处是据的增删效率也大大增加 索引种类种类分为主键索引、唯一索引、普通索引、联合索引主键索引: 数据列不允许重复，不允许为NULL，一个表只能有一个主键。 唯一索引: 数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。 普通索引: 基本的索引类型，没有唯一性的限制，允许为NULL值。 联合索引：联合索引是指对表上的多个列进行索引，顺序不同索引不同，根据联合索引树找到主键值，再从主键树上查找数据 索引的使用场景whereorder by如果不添加索引，会将查询出的所有数据使用外部排序（将数据从硬盘分批读取到内存使用内部排序，最后合并排序结果），而添加索引后，由于索引本身就是有序的，可以直接根据索引映射关系读出数据 join语句匹配关系（on）涉及的字段外键最左前缀原则命中索引时一直向左匹配直到遇到范围查询，范围查询后面的索引失效，如果前面的索引没有命中，那么后面的索引是无效的 因此在联合索引中将选择性最高的列放在索引最前面，依次降低 索引命中规则索引命中规则详解： t这张表 a,b,c 三个字段组成组合索引select * from t where a=? and b=? and c=? 全命中select * from t where c=? and b=? and a=? 全命中 解析MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引select * from t where a=? 命中a 解析:最左前缀匹配select * from t where a=? and b=? 命中a和b 解析:最左前缀匹配select * from t where a=? or b=? 一个没命中 解析or无法命中select * from t where a=? and c=? 命中a 解析:最左前缀匹配，中间没有则无法使用索引 select * from t where a=? and b in ( x, y, z) and c=? 全部命中 in精确匹配可以使用索引 select * from t where b=? 一个没命中 解析:最左前缀匹配原则 select * from t where b=? and c=? 一个没命中 解析:最左前缀匹配原则 select * from t where a=? and b like 'xxx%' 命中a select * from t where a=? and b like '%xxx' 命中a和b select * from t where a&lt;? and b=? 命中a 解析这个是范围查找 select * from t where a between ? and ? and b=? 命中a和b 解析BETWEEN相当于in操作是精确匹配 select * from t where a between ? and ? and b=? and c and between ? and ? 全部命解析中同上 select * from where a-1=? 函数和表达式无法命中索引 索引覆盖尽可能的通过索引规则，使得索引覆盖的字段更多 创建索引的原则1、只在需要索引的字段建立索引，比如where条件查询，join on字段，orderby字段等 2、最左前缀原则，尽量使索引覆盖字段最多 3、重复值多的，null值多的字段不适合做索引 4、尽量扩展索引，而不添加索引，比如原先有字段A有索引，现在想要（A,B）组合索引，那么修改原来的A索引，而不是去新建一个A,B索引 5、外键一定要建索引，因为如果外键不建索引，那么关联子表查询时，会对子表进行全表扫描 事务四大特性原子性：不可分割的操作，要么成功要么失败 隔离性：操作间不能相互影响 一致性：从某种一致性的状态转换到另一个一致性的状态 持久性：永久保存 事务：保证原子性、一致性、隔离性、持久性的数据操作称为一个事务 隔离性导致的问题脏读：一个事务读到了另一个事务没有提交的操作 不可重复读：同一个事务两次读取的数据不一样 幻读：一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的数据行 隔离性 脏读 不可重复读 幻读 读未提交 会发生 会发生 会发生 读已提交 不会发生 会发生 会发生 可重复度 不会发生 不会发生 mysql下不会发生 串行化 不会发生 不会发生 不会发生 MVCC多版本并发控制InnoDB行格式除了保存数据和其他字段外，还保存了三个字段。第一个是row_id，其次是trx_id，指的是数据改动的版本，还有一个point_id用于事务间的回滚，这样就形成了一个数据的版本链 InnoDB控制并发操作，用的就是MVCC和锁相结合的方式，相较于单一锁机制，该种机制可以提升系统性能 read viewreadView是MVCC多版本并发控制的一个实现手段，就是在事务开启的时候创建一个事务列表集合，在不同的隔离级别下，看到的事务列表集合可能也不同 读已提交隔离级别使用MVCC避免脏读原理在这种隔离级别下，readview事务列表集合存储的是仍处于活跃状态的事务，即未提交的失误，每当事务提交，则重新生成。读取数据时，会从当前最新的版本开始，按照版本链的顺序，根据readview事务列表，找到最近的不活跃的版本中的数据。如此一来，就避免了读取到未提交事务的操作 可重复度隔离级别使用MVCC避免不可重复读原理在RR隔离级别下，readview用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。但是之后，这个事务执行期间，其他事务的更新（数据版本）对它不可见。当查询数据时，会按照启动时的版本链找到最近的不活跃的版本数据 锁机制按操作数据类型来分S锁读锁：只给读不给写，称共享锁、S锁 select … in share mode：将查找的数据加一个S锁，允许其他事务继续获得该记录的S锁，不能获取X锁 场景：读取数据时，其他事务不能修改，自己也不一定能修改，因为其他事务可能也加了读锁 X锁写锁：不给其他事务读，也不给写，线程阻塞，称排它锁、X锁 select … for update：将查找的数据加一个X锁，不允许其他事务获得该记录的S锁、X锁，不能获取X锁 场景：当前事务可以读写，其他事物不能读写，update、delete、insert都会默认加写锁 按锁的粒度划分行锁访问数据库的时候，锁定整个行数据，防止并发错误。 InnoDB存储引擎默认使用行锁 特点是：并发度高，开销高，粒度最细 表锁访问数据库的时候，锁定整个表数据，防止并发错误。 MyISAM存储引擎使用表锁 特点是：并发低，开销低，粒度大 gap锁介于二者中间的一种锁，只锁定一段范围内的数据 表锁和行锁时机行级锁都是基于索引的，如果一条SQL语句用不到索引则会使用表级锁 按上锁的行为划分悲观锁每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁 乐观锁每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制 RR级别下解决幻读的原理在快照读读情况下，mysql通过mvcc来避免幻读在RR隔离级别下，readview用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。但是之后，这个事务执行期间，其他事务的更新（数据版本）对它不可见。当查询数据时，会按照启动时的MVCC版本链找到最近的不活跃的版本数据。 在当前读读情况下，mysql通过next-key来避免幻读record lock：单个行记录上的锁 Gap lock：间隙锁，锁定一个范围，不包括记录本身 next-key lock：行锁(record lock)+间隙锁(gap lock)，锁定一个范围，包含记录本身 1、当查询语句包含唯一属性时且全部命中时，此时的next-key锁会降级成行锁，是由于其他事务的操作不会对本次查询造成影响 2、其他情况会添加next-key锁，锁住包含当前记录的一个范围，这样其他事务就无法在这个范围内添加数据 视图什么是视图？视图的作用优点？视图本质上是一种虚拟表，在物理上是不存在的，其内容来源于sql语句查询时引用的基本表，因此视图具有逻辑独立性 提高复杂sql语句的复用性，查出后可以存储方便下次查询时就不用再次编写复杂语句 由于视图只含有查询出的特定数据，而没有来源表中的其他数据，因此提高了数据的安全性 修改视图？由于视图来源于基本表，因此修改视图时必须转化为对基本表的某些行的修改 数据库优化数据库发生死锁如何解决？死锁是两个或多个事务在同一资源上相互占用， 并等待对方释放锁的现象 1、如果多个项目读取同一个表，尽量约定同一顺序读取 2、如果该表死锁发生频繁可以升级锁粒度 3、同一个事务一次锁定所有需要的资源，但是会导致并发降低 数据库优化如何定位并优化慢查询1、根据慢日志定位到慢查询sql 2、使用explain工具分析sql，字段type：，all表示走的全表 3、修改sql，或者让sql尽量走更多的索引，range表示走索引是优化的目标 索引类型 TYPE 类型 ALL 全表扫描 index 走索引树的全表扫描 range 扫描部分索引，开始于索引的某一个点，结束另一个点 ref 使用非唯一索引或非唯一索引前缀进行的查找 const 使用=比较主键索引或者唯一索引 大表优化当mysql单表记录数过大时，数据库的crud性能会明显下降 1、限定数据查询范围禁止不带任何限制条件的查询 2、主从复制、读/写分离（分库）Mysql的主从复制和mysql的读写分离两者有紧密的联系，首先要部署主从复制，只有主从复制完成了，才能再此基础上进行数据的读写分离 主库负责写，从库负责读 3、垂直水平分表垂直分表：即根据数据的相关性，将多列的表拆分成少列多张表 优点：列数据变小，减小IO次数，简化表结构，易于维护 缺点：会出现数据冗余，并且会出现JOIN操作，导致事务变得复杂 水平分表：保持数据结构不变，将存储数据分片，再存储到不同的表或库中 优点：支持非常大数据的存储，且应用端改造少 缺点：拆分会给服务端带来逻辑，部署，运维的各种难度，因此不建议对数据进行分片 分库分表后，id主键如何处理分成多个表后，不应让每个表的id从1开始累加，而应该控制全局唯一ID支持 SQL注入sql注入，简单来说就是用户在前端web页面输入恶意的sql语句用来欺骗后端服务器去执行恶意的sql代码，从而导致数据库数据泄露或者遭受攻击。 方案java防SQL注入,最简单的办法是杜绝SQL拼接,SQL注入攻击能得逞是因为在原有SQL语句中加入了新的逻辑 如果使用PreparedStatement来代替Statement来执行SQL语句，其后只是输入参数，SQL注入攻击手段将无效 在WEB层我们可以过滤用户的输入来防止SQL注入比如用Filter来过滤全局的表单参数","tags":[{"name":"mysql","slug":"mysql","permalink":"https://xulilei.github.io/tags/mysql/"}]},{"title":"mysql之sql语句","date":"2020-07-17T10:58:31.000Z","path":"2020/07/17/秋招复习mysql之sql语句/","text":"秋招复习mysql之sql语句基础语句SELECT 语句SELECT 列名称 FROM 表名称SELECT * FROM 表名称例子:SELECT LastName,FirstName FROM Persons WHERE条件限定如需有条件地从表中选取数据，可将 WHERE 子句添加到 SELECT 语句。 SELECT 列名称 FROM 表名称 WHERE 列 运算符 值SELECT * FROM Persons WHERE City='Beijing'表中选取居住在不包含 \"lon\" 的城市里的人：SELECT * FROM Persons WHERE City NOT LIKE '%lon%' 运算符 操作符 描述 = 等于 != 不等于 &gt; 大于 &lt; 小于 &gt;= 大于等于 &lt;= 小于等于 BETWEEN 在某个范围内 LIKE 搜索某种模式 IN 操作符IN 操作符允许我们在 WHERE 子句中规定多个值 从Persons表中选取姓氏为 Adams 和 Carter 的人：SELECT * FROM Persons WHERE LastName IN ('Adams','Carter')等同于SELECT * FROM Persons WHERE LastName ='Adams' or LastName ='Carter' BETWEEN 操作符操作符 BETWEEN … AND… （左闭右开）会选取介于两个值之间的数据范围。这些值可以是数值、文本或者日期。 以字母顺序显示介于 \"Adams\"（包括）和 \"Carter\"（不包括）之间的人，请使用下面的 SQL：SELECT * FROM Persons WHERE LastName BETWEEN 'Adams' AND 'Carter' limit offset分页查询表示读取前三条数据select * from article limit 3从1+1=2开始读3条，就是跳过1条数据后读取3条数据select * from article limit 1,3offset代表跳过几条，limit代表读取几条select * from article limit 3 offset 1 TOP语句现在，我们希望从上面的 \"Persons\" 表中选取头两条记录SELECT TOP 2 * FROM Persons现在，我们希望从上面的 \"Persons\" 表中选取 50% 的记录SELECT TOP 50 PERCENT * FROM Persons DISTINCT关键词 DISTINCT 用于返回唯一不同的值。SELECT DISTINCT 列名称 FROM 表名称 AND 和 OR 运算符AND 和 OR 可在 WHERE 子语句中把两个或多个条件结合起来 如果第一个条件和第二个条件都成立，则AND位true 如果第一个条件和第二个条件中只要有一个成立，则OR为true 使用 AND 来显示所有姓为 \"Carter\" 并且名为 \"Thomas\" 的人：SELECT * FROM Persons WHERE FirstName='Thomas' AND LastName='Carter'使用 OR 来显示所有姓为 \"Carter\" 或者名为 \"Thomas\" 的人：SELECT * FROM Persons WHERE firstname='Thomas' OR lastname='Carter' ORDER BY 语句ORDER BY 语句用于根据指定的列对结果集进行排序。 ORDER BY 语句默认按照升序对记录进行排序，如果望按照降序对记录进行排序，可以使用 DESC 关键字。 以逆字母顺序显示公司名称，在公司名称相同的情况下以数字顺序显示顺序号：SELECT Company, OrderNumber FROM Orders ORDER BY Company DESC, OrderNumber ASC INSERT INTO语句INSERT INTO 语句用于向表格中插入新的行。 语法INSERT INTO 表名称 VALUES (值1, 值2,....)INSERT INTO Persons VALUES ('Gates', 'Bill', 'Xuanwumen 10', 'Beijing')也可以指定所要插入数据的列：INSERT INTO table_name (列1, 列2,...) VALUES (值1, 值2,....)INSERT INTO Persons (LastName, Address) VALUES ('Wilson', 'Champs-Elysees') INSERT INTO 语句从一个表中选取数据，然后把数据插入另一个表中 将select查询的数据插入已存在的表orderinfo，当表不存在时，通过将insert into改为create table INSERT into orderinfoSELECT p.username,o.orderNoFROM persons as pINNER JOIN orders as oon p.id_p=o.id_p Update 语句Update 语句用于修改表中的数据 语法：UPDATE 表名称 SET 列名称 = 新值 WHERE 列名称 = 某值修改地址address，城市名称city当LastName为WilsonUPDATE Person SET Address = 'Zhongshan 23', City = 'Nanjing' WHERE LastName = 'Wilson' DELETE 语句DELETE 语句用于删除表中的行 \"Fred Wilson\" 会被删除：DELETE FROM Person WHERE LastName = 'Wilson' 可以在不删除表的情况下删除所有的行。这意味着表的结构、属性和索引都是完整的：DELETE FROM table_name或者：DELETE * FROM table_name 高级语句CREATE TABLECREATE TABLE Persons(列名称 数据类型Id_P int,Name varchar(255),Address varchar(255),City varchar(255)) 数据类型（data_type）规定了列可容纳何种数据类型。下面的表格包含了SQL中最常用的数据类型： 数据类型 描述 integer(size)、int(size)、smallint(size)、 tinyint(size) 仅容纳整数。在括号内规定数字的最大位数。 decimal(size,d) 、numeric(size,d) 容纳带有小数的数字。”size” 规定数字的最大位数。”d” 规定小数点右侧的最大位数。 char(size) 容纳固定长度的字符串（可容纳字母、数字以及特殊字符）。在括号中规定字符串的长度。 varchar(size) 容纳可变长度的字符串（可容纳字母、数字以及特殊的字符）。在括号中规定字符串的最大长度。 date(yyyymmdd) 容纳日期。 SQL 约束约束用于限制加入表的数据的类型。 可以在创建表时规定约束（通过 CREATE TABLE 语句），或者在表创建之后也可以（通过 ALTER TABLE 语句）。 CREATE TABLE Persons(Id_P int NOT NULL PRIMARY KEY)或者ALTER TABLE Personsadd PRIMARY KEY(id_p)drop PRIMARY KEY 添加外键，要指明指向的是哪个表的逐渐ALTER TABLE ordersadd CONSTRAINT aliasFOREIGN KEY(id_p)REFERENCES persons(id_p)删除外键ALTER TABLE ordersDROP FOREIGN KEY alias 在已经存在表的情况下，添加default约束ALTER TABLE PersonsALTER City SET DEFAULT 'SANDNES'或者删除default约束ALTER City DROP DEFAULT ALTER table personsadd CONSTRAINT aliasCHECK(id_p&gt;0 and city='beijing') 我们将主要探讨以下几种约束： 约束名 含义 NOT NULL 约束强制列不接受 NULL 值 UNIQUE 唯一标识数据库表中的每条记录，可以有多个 PRIMARY KEY 唯一标识数据库表中的每条记录，每个表都应该有且仅有一个主键 FOREIGN KEY 用于预防破坏表之间连接的动作，防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一 DEFAULT 如果没有规定其他的值，那么会将默认值添加到所有的新记录 CHECK 此约束会在特定的列中对值进行限制 sql通配符SQL 通配符必须与 LIKE 运算符一起使用 通配符 描述 % 替代一个或多个字符 _ 仅替代一个字符 [charlist] 字符列中的任何单一字符 [^charlist]或者[!charlist] 不在字符列中的任何单一字符 使用 % 通配符从 \"Persons\" 表中选取居住在以 \"Ne\" 开始的城市里的人：SELECT * FROM Persons WHERE City LIKE 'Ne%'使用 _ 通配符从 \"Persons\" 表中选取名字的第一个字符之后是 \"eorge\" 的人：SELECT * FROM Persons WHERE FirstName LIKE '_eorge'使用 [charlist] 通配符从 \"Persons\" 表中选取居住的城市以 \"A\" 或 \"L\" 或 \"N\" 开头的人：SELECT * FROM Persons WHERE City LIKE '[ALN]%'从 \"Persons\" 表中选取居住的城市不以 \"A\" 或 \"L\" 或 \"N\" 开头的人：SELECT * FROM Persons WHERE City LIKE '[!ALN]%' sql别名可以通过as为列名称和表名称指定别名（Alias） 查询出来的code表的codeid显示为cid，role表的roleid显示为ridSELECT c.codeid as cid,r.roleid as ridcode表起名c，role表起名rFROM code AS c,role as rcode表的userid为1和role表rolename为userwhere c.userid=1 and r.rolename='user' sql JOINWHERE子句中使用的连接语句，在数据库语言中，被称为隐性连接。INNER JOIN……ON子句产生的连接称为显性连接。（其他JOIN参数也是显性连接） WHERE和INNER JOIN产生的连接关系，没有本质区别，结果也一样。 inner joinSELECT p.username,o.orderNoFROM persons as p,orders as owhere p.id_p=o.id_p等价于内连接SELECT p.username,o.orderNoFROM persons as pINNER JOIN orders as oon p.id_p=o.id_p三表连接SELECT p.username,o.orderNo,t.addressfrom(persons as pinner joinorders as oon p.id_p=o.id_p)inner joinTMD as ton p.id_p=t.id_p outer joinleft join：理解为“有左显示”，比如on a.field=b.field，则显示a表中存在的全部数据及a、b中都有的数据，a中有、b中没有的数据以null显示right join：理解为“有右显示”，比如on a.field=b.field，则显示b表中存在的全部数据及a、b中都有的数据，b中有、a中没有的数据以null显示 SQL UNIONUNION 操作符用于合并两个或多个 SELECT 语句的结果集，UNION 内部的 SELECT 语句必须拥有相同数量的列，列也必须拥有相似的数据类型。 SQL CREATE INDEX在表中创建索引，以便更加快速高效地查询数据。用户无法看到索引，它们只能被用来加速搜索/查询 方式一create，但是无法建立primaryKeyCREATE UNIQUE INDEX PersonIndexON Person (LastName, FirstName)删除ALTER TABLE PersonDROP INDEX PersonIndex方式二 alter addALTER TABLE Personsadd PRIMARY KEY(id_p)方式三 create table时添加索引 SQL ALTER TABLE用于在已有的表中添加add、修改modify或删除drop列 在表 \"Persons\" 中添加一个名为 \"Birthday\"类型为“DATE”的新列。ALTER TABLE PersonsADD Birthday date 改变 \"Persons\" 表中 \"Birthday\" 列的数据类型为“year”。ALTER TABLE PersonsMODIFY COLUMN Birthday year 删除 \"Person\" 表中的 \"Birthday\" 列：ALTER TABLE PersonDROP COLUMN Birthday SQL AUTO INCREMENT在每次插入新记录时，自动地为主键字段创建一个唯一的值 CREATE TABLE Persons(P_Id int NOT NULL AUTO_INCREMENT,PRIMARY KEY (P_Id)) SQL VIEW视图是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据 创建视图create view other as select a.name as username, b.name as goodsname from user as a, goods as b, ug as c where a.id=c.userid and c.goodsid=b.id;创建好视图后，可以直接从view中查询select * from other删除视图DROP VIEW view_name SQL DATE下面的表格列出了 MySQL 中最重要的内建日期函数： 函数 描述 NOW() 返回当前的日期和时间 CURDATE() 返回当前的日期 CURTIME() 返回当前的时间 DATE() 提取日期或日期/时间表达式的日期部分 EXTRACT() 返回日期/时间的单独部分 DATE_ADD() 给日期添加指定的时间间隔 DATE_SUB() 从日期减去指定的时间间隔 DATEDIFF() 返回两个日期之间的天数 DATE_FORMAT() 用不同的格式显示日期/时间 SQL NULL对于可选列，当插入一条可选列无值的数据，会以NULL值保存 无法使用比较运算符来测试 NULL 值，比如 =, &lt;, 或者 &lt;&gt;， 必须使用 IS NULL 和 IS NOT NULL 操作符。 SELECT LastName,FirstName,Address FROM PersonsWHERE Address IS NOT NULL 涉及到计算时通过IFNULL(VALUE,0),COALSCE(VALUE,0) SELECT ProductName,COALESCE(OrderNo,0)FROM Products SQL函数常见sql函数，详见https://blog.csdn.net/zeng_ll/article/details/87706409 函数名 作用 avg(数值列) 返回数值列的平均值。NULL 值不包括在计算中 abs(数值列) 返回数值列的绝对值 count(字段名) 返回匹配指定条件的行数 first(字段名)/last(字段名) 函数返回指定的字段中第一个/最后一个记录的值 max(字段名)/min(字段名) 返回一列中的最大值/最小值 ucase(字段名)/lcase(字段名) 字段值转换为大写/小写 len(字段名) 文本字段中值的长度 ROUND(字段名，小数位数) 把数值字段舍入为指定的小数位数 IF(expr,v1,v2） 如果表达式 expr 成立，返回结果 v1；否则，返回结果 v2 GROUP BYGROUP BY 语句根据一个或多个列对结果集进行分组，在分组的列上我们可以使用 COUNT, SUM, AVG等合计函数 SELECT Customer,SUM(OrderPrice) FROM OrdersGROUP BY Customer HAVING在 SQL 中增加 HAVING 子句原因是，WHERE 关键字无法与合计函数一起使用 HAVING SUM(OrderPrice)&lt;2000中的“SUM(OrderPrice)&lt;2000”即为合计函数 SELECT Customer,SUM(OrderPrice) FROM OrdersGROUP BY CustomerHAVING SUM(OrderPrice)&lt;2000 找到客户BUSH或者ADAMS中订单超过1500的金额SELECT Customer,SUM(OrderPrice) FROM OrdersWHERE Customer='Bush' OR Customer='Adams'GROUP BY CustomerHAVING SUM(OrderPrice)&gt;1500","tags":[{"name":"mysql","slug":"mysql","permalink":"https://xulilei.github.io/tags/mysql/"}]},{"title":"操作系统","date":"2020-07-15T07:39:07.000Z","path":"2020/07/15/秋招复习之操作系统/","text":"秋招复习之操作系统进程进程间的通信方式1、匿名管道：用于具有亲缘关系的父子进程或者兄弟进程之间的通信，存放于内存中 2、有命管道：匿名管道由于没有名字，只能用于亲缘关系进程之间的通信。有名管道以磁盘文件方式存在，可以实现本机任意两个进程通信，遵守先进先出 3、信号：用于通知接收进程某个事件已经发生 4、消息队列：是消息的链表，具有特定的格式，存放在内存中并有消息队列标识符标识，可以实现消息的随机查询，不一定按照FIFO的顺序，可以按照消息的类型读取 5、信号量：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步，主要用于解决与同步相关的问题，并避免竞争条件 6、共享内存：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享数据的更新，但需依赖互斥锁，信号量等，是最有用的线程间通信方式 7、套接字：用于客户端进程和服务器之间通过网络进行通信 线程间的同步方式1、互斥量：即某一时刻，互斥对象中只有一个能够访问公共资源，比如java中的Syncronized 2、信号量：它允许同一时刻多个线程访问同一资源，比如semaphore等 3、事件：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。比如wait，notify等，以及countlatch等组件 进程调度算法1、先到先服务：从就绪队列选择一个最早进入队列的进程，为该资源分配进程立即执行 2、短作业优先：从就绪队列选择一个估计运行时间最短的进程，为该资源分配进程立即执行 3、时间片轮转：每个进程被分配一个时间段，称作它的时间片，即该线程允许运行的时间 4、优先级：为每个进程分配优先级，高优先级先执行，相同优先级先到先执行 5、多级反馈队列：既保证高优先级进程得到响应，又能使短作业进程快速完成 进程的状态1、new：进程正在被创建，还未就绪 2、ready：线程已经准备就绪，当获得cpu资源即可开始运行 3、running：线程正在运行中 4、waiting：等待状态，即该进程让出CPU资源，即使CPU空闲也不会运行 5、ending：进程从系统中结束 内存操作系统内存管理做了什么主要负责内存的分配与回收，以及讲逻辑地址映射成响应的物理地址 常见的内存管理机制连续分配管理：为一个进程分配一个连续的内存空间，如块式管理，如果进程只需很小的空间的话，会造成浪费 非连续分配管理：允许一个程序使用的内存分布在离散的内存中 页式管理：将主存分为大小相等且固定的一页一页的形式，粒度更小，通过页表对应物理和逻辑地址 段式管理：将主存分为一段一段，每个段赋予了逻辑信息，通过段表对应物理和逻辑地址 段页式管理机制：结合了段式和页式管理的优点，先将主存分成若干段，再将每个段分配成若干页 段页机制的共同点与区别相同点1、分页机制和分段机制都是为了提高内存利用率，减少内存碎片 2、页和段都是离散存储的，但是段和页内的内存是连续的 不同点1、页大小固定，段大小根据运行的程序 2、分页是为了满足操作系统内存管理的需求，而段是具有逻辑信息的，体现为代码段，数据段等 多级页表和快表快表为了解决虚拟地址到物理地址的转换速度，使用页表后转换流程 1、根据虚拟地址中的页号查快表 2、如果该页在快表中，则直接从快表中读取相应的物理地址 3、如果不在快表中，则访问页表，得到物理地址后，映射一份到快表中，以备下次转换 4、快表满后，则根据淘汰策略淘汰一页 多级页表避免把全部页表一直放在内存中占用过多空间，多级页表通过一个顶级页表为真正有用的页表提供索引，这样一些不需要的页表就不用一直存储在内存中了，只需要通过顶级页表索引查询到具体的页表即可，是一种时间换空间的做法 虚拟(逻辑)地址与物理地址程序产生的与段相关的偏移地址，而物理地址则是代表真实物理内存中的地址 CPUcpu寻址cpu通过虚拟寻址将虚拟地址翻译成物理地址，这样才能访问到真正的物理内存 虚拟地址空间没有虚拟地址空间的时候，程序直接访问和操作的都是物理内存会造成以下问题 1、用户程序可以随意访问任意内存，很容易破坏系统 2、运行多个程序不便，比如A程序分配了1XX的内存地址，当另一个程序也分配到这里的时候会造成覆盖 使用虚拟地址空间： 1、用户可以使用相邻的虚拟地址访问物理地址不相邻的内存 2、不同程序之间虚拟地址被隔离，保护了系统，以及运行的程序 局部性原理表现为以下两个方面：时间局部性：如果程序中的某条指令一旦执行，则不久之后该指令可能再次被执行；如果某数据被访问，则不久之后该数据可能再次被访问。 空间局部性：是指一旦程序访问了某个存储单元，则不久之后，其附近的存储单元也将被访问。 CPU对应的做法时间局部性：如果一个信息项正在被访问，数据在寄存器被计算完成后，将会放入高速缓存中。 空间局部性：在读取内存的时候将该内存附近的内存也读进缓存中。 虚拟内存虚拟内存可以让程序拥有超过物理内存大小的可用内存空间，定义了一个连续的虚拟地址空间，并把内存扩展到硬盘空间 虚拟内存的实现1、在载入程序的时候，装入程序的一部分，而另一部分留在外寸 2、缺页中断：当程序执行过程中，访问信息不在内存中时（成为缺页缺段），再将需要的部分读入内存，继续执行程序 3、虚拟地址空间：逻辑地址到物理地址的转换 页面置换算法地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断，如果当前内存中没有空闲的页面，操作系统就必须在内存选择一个页面将其一出内存，这就涉及到了页面置换算法 LFU页面置换算法：系统会维护一个按最近一次访问时间排序的页面链表，链表首节点最近刚刚使用过的页面，链表尾节点是最久未使用的，缺页时，置换链表尾节点的页面。也就是说，内存使用越频繁的页面，保留的时间也越长","tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://xulilei.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"IO模型","date":"2020-07-14T06:07:52.000Z","path":"2020/07/14/秋招复习之IO/","text":"秋招基础复习之IO模型基本四个：InputStream，outputStream，reader，writer 字节流和字符流的区别1、字节流是最小单元，但是在字符与字节流的转化过程中，可能会造成乱码，因此提供了直接操作字符的工具 2、字节流在操作时本身不会用到缓冲区（内存），是文件本身直接操作的；而字符流在操作时使用了缓冲区，通过缓冲区再操作文件。 什么是缓冲区？有什么作用？缓冲区就是一段特殊的内存区域，很多情况下当程序需要频繁地操作一个资源（如文件或数据库）则性能会很低，所以为了提升性能就可以将一部分数据暂时读写到缓存区，以后直接从此区域中读写数据即可，这样就显著提升了性能。 缓冲和缓存的区别缓存（cache）是在读取硬盘中的数据时，把最常用的数据保存在内存的缓存区中，再次读取该数据时，就不去硬盘中读取了，而在缓存中读取。缓冲（buffer）是在向硬盘写入数据时，先把数据放入缓冲区,然后再一起向硬盘写入，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。 BIO/NIO/AIOBIO两个阻塞点：Socket socket=serverSocket.accept()处理请求的时候，另一个是InputStream is=socket.getInputStream()处理io流的时候 优点是：一个线程为一个客户端服务，质量好。 缺点是：并发量大的时候性能差 NIO具体实现从两个事件介绍，一个是selector的accpet事件，另一个是read事件 accpet事件的执行过程为： 1、介绍几个概念，第一个是selector选择器，用于监听注册在其上的selectionKey事件集合的状态，第二个是serversocketChannel，主要关心的是accept事件，第三个是channel，是对BIO的流的模拟，即数据从一个地方到另一个地方一定要经过这个流。 2、第一步，创建serversocketChannel并设置为非阻塞模式，将其注册到selctor上去，并监听slectionKey.op_accept事件 3、Selector对象循环监听每一个Channel通道的事件，循环执行 Selector.select() 方法（这个就是多路复用模型selector/epoll/poll等），轮询就绪的Channel，如果事件为op_accept就执行serversocketChannel.accept建立连接，这也是为什么说serversocketChannel关心的accept事件 4、接着将事件的状态改为OP_read，进入读取进制，并删除OP_ACCEPT的selectionKey，表明这个时间完成了 下面执行的是读取机制 要介绍几个新的概念，第一个是buffer缓冲区，在NIO中所有数据都通过buffer来处理，实质是一个数组，比如byteBuffer（option，limit来限定每个channel所在的位置），还有一个SocketChannel，关心的是IO事件。 1、首先打开socketChannel，并设置为非阻塞模式，将其注册到selector上去，并监听selectionKey.op_read事件 2、selector继续轮询监听各个事件，在读取机制中，检测的是Selection.op_read事件，如果事件为op_read，则将数据异步的读取到buffer中，再将buffer中的信息写到socketChannel中，获取消息 I/O多路复用机制多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉。当有一个或多个流有 I/O事件时，就从阻塞态中唤醒，依次顺序的处理就绪的流，这种做法就避免了大量的无用操作 多路复用流程用户态将文件描述符传入内核 select/poll：将用户态文件拷贝到内核中，监听IO操作。其中select有fd数量限制，默认是1024。 epoll：会在内核的中建立一颗红黑树以及就绪链表。每一个用户态文件描述符会对应红黑树的一个节点，同时注册回调函数。 内核态检测文件描述符读写状态 select/poll：采用轮询方式，遍历所有fd，找到就绪的fd。 epoll：采用回调机制。内核在检测到事件时会调用回调函数，该回调函数会将就绪的事件放在就绪链表中。 找到就绪的文件描述符传递给用户态 select/poll：将之前传入的就绪fd拷贝到用户态。 epoll：epoll_wait只用观察就绪链表中有无数据依次处理即可。 多路复用优点用select/epoll的优势在于，它可以同时处理很多个连接。与一条线程维护一个连接相比，系统不必创建线程，也不必维护这些线程，从而大大减小了系统的开销。 AIO异步IO，指的是当有IO请求时，不用拿到IO，而线程可以继续运行","tags":[{"name":"IO","slug":"IO","permalink":"https://xulilei.github.io/tags/IO/"}]},{"title":"java基础（一）","date":"2020-07-12T08:15:47.000Z","path":"2020/07/12/秋招复习之java基础/","text":"秋招复习之java基础JAVA概述1、JVM、JRE、JDKJVM：被称为java虚拟机，是运行java字节码的虚拟机 JRE：java运行时环境，包括JVM，Java类库，Java命令和其他一些基础组件 JDK：拥有JRE所拥有的一切，还有java编译器javac和工具 2、什么是字节码？好处是什么？字节码是经过java虚拟机编译后形成的.class文件，不面向平台，只面向对应的虚拟机，因此java程序无需重新编译即可在不同的平台运行 3、java中的编译器和解释器java源代码先经过编译器编译成虚拟机能够理解的代码，再由解释器解析在特定的环境中运行 4、java和c++的区别1、都是面向对象的语言，都支持继承封装，多态三大特性 2、java不提供指针直接操作内存，相比C++更加安全 3、java类是单继承原则，c++可以多继承 基础语法1、数据类型引用数据类型：类，接口，数组 基本数据类型：整型4个，浮点型2个，字符型1个，布尔型1个。 2、switch 是否能作用在 byte 上，是否能作用在 long 上，是否能作用在 String 上switch语句可以执行byte，short，int，char，string，枚举类型，但是目前为止不支持长整形 3、Math.round(11.5) 等于多少？Math.round(-11.5)等于多少计算规则，+0.5取整，因此前者为12，后者为-11 4、float=3.4是否正确？3.4是双精度型，双精度型赋值给单精度型是向下赋值，会造成精度丢失，因此需要强转，float f =(float)3.4或者float f =3.4F 5、short s1 = 1; s1 = s1 + 1有错吗?short s1 = 1; s1 += 1有错吗？s1=1，1+1位int型，因此需要强转，错误 s1+=1，隐含了s1=（short）（s1+1），因此正确 6、JAVA采用何种编码？特点？java采用Unicode标准码编码，为每个字符指定了唯一的数值，因此可以在任意平台放心使用 7、访问修饰符private：在同一类内可见，可以修饰方法，变量，内部类（外部类不可以） protected：同一包可见，外包子类可见，修饰方法，变量，内部类（不能修饰外部类） default（即缺省，不加关键字修饰）：在同一包中可见，外包子类不可见，修饰方法，变量，类，接口 public：所有可见 8、&amp;和&amp;&amp;的区别逻辑与(&amp;)和短路与(&amp;&amp;)在运算上对条件的结果判断不会产生影响,但会对条件判断的运算有影响 关键在于,逻辑与(&amp;)在运算时会连续运算所有需要判断的命令.但短路与当遇到false时就会停止运算 同样的，逻辑或运算符（|）和短路或运算符（||）的差别也是如此。 9、final关键字修饰变量：如果是基本数据类型，则其数值一旦在初始化后就不能更改；如果是引用类型的变量，则对其初始化后就不能再指向另一个对象 修饰类：表明这个类不能被继承 修饰方法：防止该方法被重写，private方法都隐式都指定为final 10、final、finally、finalize区别final：看9 finally：一般用作try-catch块中，通常将一定要执行的代码方法finally代码块中，表示不管有没有异常，该部分逻辑都要执行 finalize：是垃圾回收期在GC时调用 11、this和superthis是代表指向自身的对象，可以理解为一个指向本身的一个指针 super是指向离自己最近的父类对象 在构造函数中使用时，都需放在构造函数的第一行，且不能在同一个构造函数中同时使用super和this 静态方法中不能使用super和this关键字 12、break、continue、returnbreak：跳传当前的循环体，要退出多层嵌套循环，可以在循环外定一个标志位，使用break+标志位退出到标志点 continue：跳传本次循环，继续执行下次循环 return：程序返回，不再执行下面的代码 13、自动装箱与拆箱装箱：将基本数据类型用他们对应的引用类型包装起来 拆箱：将包装类型转换为基本数据类型 一种机制，使得这些基本类型在一般的编程中被当作非对象的简单类型处理，在另一些场合，又允许它们被视作是一个对象 面向对象1、面对对象的理解面向对象易维护，易复用，易扩展。因为面向对象有封装、继承、多态三大特性，所以基于面对对象思想构建的程序具有低耦合、更灵活、易维护等特点 封装、继承、多态封装：把一个对象的属性私有化，同时提供一些可以被外界访问属性的方法 继承：是指可以让某个类型的对象获得另一个类型的对象的属性的方法。 多态：就是指一个类实例的相同方法在不同情形有不同表现形式，多态的三个必要条件：继承、重写、向上转型 2、面对过程优点：由于面向对象需要实例化对象，维护对象之间的关系，因此面对过程效率比面向对象高，开销少，比如linux，单片机等都是面对过程开发 缺点：面对对象的优点就是面对过程的缺点，比如不易复用，不易维护，不易扩展 3、面对对象的五大原则单一职责原则：类的功能要单一 开闭原则：对于拓展是开放的，对于修改是封闭的 里氏替换原则：子类可以替换父类出现在父类能够出现的任何地方、 依赖倒置原则：低层次模块要依赖高层次模块，具体依赖抽象 接口分离原则：拆分不同功能到不同的接口中 4、重载、重写与重构的区别重载：发生在同一个类中，方法名必须相同，参数类型，个数，顺序，返回值类型，访问修饰符等都可以不同 重写：是子类对父类允许访问的方法的实现过程进行重新编写，发生在子类中，方法名、参数列表必须相同，返回值范围小于等于父类，访问修饰符范围大于等于父类，如果父类是private修饰的就不能重写该方法。也就是说方法提供的行为改变，而方法的外貌并没有改变 重构：是重写的一种特殊方式，子类与父类的成员方法的返回值、方法名称、参数类型及个数完全相同，唯一不同的是方法实现内容，这种特殊重写方式被称为重构。 5、接口和抽象类以JDK1.8为基准 相同点：二者都不能被实例化，只能实例化实现或者继承他们的类，接口可以有静态方法，抽象类一直都可以有 不同点：1、接口中变量只能是publis static final类型的，而抽象类中的变量可以任意修饰 2、接口中不能有构造函数，抽象类中可以有 3、抽象类可以用除了private之外的修饰符修饰，而接口只能使用public4、类只能继承一个类，但可以实现多个接口 6、对象实例和对象引用的区别对象实例存放在堆内存中，可以有n个引用指向他。而对象引用存放在栈内存中，可以指向0或者1个对象实例 7、static静态主要意义用于创立独立于具体对象之外的变量和方法，以至于不实例化对象，就可以使用属性和方法 由于生命周期从属于类，因此static修饰的代码只会被执行一次，可用于优化代码 static修饰的变量属于类变量，存放在方法区/元空间中，被该类的对象共享 用法静态只能访问静态，非静态可以访问静态也可以访问非静态 静态可以不用实例化，直接通过类名.属性名或者方法名调用，生命周期从属于类 非静态必须要实例化对象后，通过对象调用，生命周期从属于对象 8、静态变量、成员变量和局部变量的区别 所属不同： 静态变量：属于类，也称为类变量 成员变量：属于对象，也称为对象变量或实例变量。 局部变量：属于方法 在内存中的位置不同： 静态变量：存储于方法区/元空间。 成员变量：存储于堆内存 局部变量：存储于栈，随着方法结束自动回收 生命周期不同： 静态变量：随着类的加载而加载，随着类的消失而消失。 成员变量：存在于类中方法外，随着对象的创建而存在，随着对象的消失而消失。 局部变量：存在于方法内部，随着方法的调用而存在，随着方法的调用完毕而消失 调用不同： 静态变量：可以通过对象名调用，也可以通过类名调用 成员变量：只能通过对象名调用 局部变量：方法外部无法调用 初始值不同： 静态变量：有默认值 成员变量：有默认值 局部变量：么有默认值，必须先赋值 9、空构造函数的作用构造函数的作用：当new一个对象的时候，调用构造函数完成对象的初始化 在类中如果没有参构造函数，系统会默认一个无参构造函数，此时写不写空构造没有影响。但如果父类只定义了有参构造，在子类的构造函数中，又没有通过super()来调用父类特定有参构造函数的情况下，将会发生编译错误。 10、内部类静态内部类类内部由static修饰的类，需要通过outer.inner inner=new outer.inner();实例化 成员内部类类内部非static类，需要先实例化外部类，在通过外部类对象outer.inner inner=outer.new inner()实例化 局部内部类定义在方法中的内部类，就是局部内部类。需要在方法中实例化这个类，并调用这个类的方法 匿名内部类匿名内部类就是没有名字的内部类，匿名内部类必须继承一个抽象类或者实现一个接口。 11、为什么要使用内部类，哪些应用场景1、内部类可以访问创建它的外部类的属性 2、内部类不为同一包的其他类所见，有很好的封装性 3、内部类拓展了多重继承，优化了类单继承的缺陷 使用场景是某个类只会被它的外部类调用的时候 12、==与equals方法==：判断两个对象的地址是不是相等，即判断两个对象是不是同一个对象，基本数据类型比较的是值，引用数据类型比较的是内存地址 equals：若没有重写equals方法，则比较对象时，等价于“==”，若重写了equals，则等价于重写的相等的逻辑 public class Main&#123; public static void main(String[] args) &#123; String a = new String(\"ab\"); // a 为⼀个引⽤ String b = new String(\"ab\"); // b为另⼀个引⽤,对象的内容⼀样 String aa = \"ab\"; // 放在常量池中 String bb = \"ab\"; // 从常量池中查找 //true，同一对象 System.out.println(aa==bb); //false，非同一对象 System.out.println(a == b); //String对equals方法进行了重写，a的值与b的值相等 System.out.println(a.equals(b))； &#125;&#125; 13、重写equals方法为什么要重写hashcode()hashcode值是基于对象内存地址和内容得到的值，作用是获取hash码定位哈希表中索引的位置 如果两个对象相等，那么他们的hashcode值一定是相同的，而如果两个对象不相同那么他们的hashcode也有可能相等 以hashmap为例，首先获得对象的hashcode定位到要加入的位置，再通过equals方法判断两个对象是否真的相同 如果重写了euqals方法，而不重写hashcode方法，那么就会导致相同的对象equals不相等，这样一来，就会导致get出的值为null 14、为什么说java只有值传递Java总是采用按值调用。也就是说，方法得到的是所有参数值的一个拷贝，方法不能修改传递给它的任何参数变量的内容。 第一种是int之类的基本数据类型，值的副本不会改变 第二种是数组之类的引用数据类型，传递的引用的副本，由于引用副本也是指向的同一个对象,所以方法可以改变对象参数，但其本质仍然是按值调用 值调用表示方法接收的是调用者提供的值 按引用调用表示方法接收的是被调用对象的地址 15、浅拷贝、深拷贝浅拷贝：对基本数据类型进行值传递；如果该字段是引用类型的话，则复制引用但不复制引用的对象 ，因此原始对象及其副本引用同一个对象 深拷贝：对基本数据类型进行值传递；如果该字段是引用类型的话，则创建一个新的对象，并复制其内容，赋值给这个新的对象 16、直接引用与符号引用符号引用：在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。 直接引用：直接引用可以是直接指向目标的指针 17、对象的序列化和反序列化序列化：把对象转换为字节序列的过程称为对象的序列化。保存(持久化)指定的对象，并在将来重新读取被保存的对象。 反序列化：把字节序列恢复为对象的过程称为对象的反序列化 对于不想序列化的变量，使用transient关键词修饰 18、java泛型泛型，即“参数化类型”。就是将类型由原来的具体的类型参数化 19、Comparator和Comparable的区别二者都可以用来实现集合中元素的比较，排序 comparable将比较逻辑封装在实现了comparable接口对象的内部，通过compareTo方法实现，可以直接使用collection.sort排序 comparator则在另一个实现了comparator接口的实体类compare方法中实现比较逻辑，使用collection.sort时需要传入这个实体类 因此，comparable耦合性比较强 String相关1、StringBuffer、StringBuilder、StringString：由final关键字修饰，即String对象是不可变的，线程安全 StringBuffer：对象可变，线程安全 StringBuilder：对象可变，线程不安全 2、字符串常量池字符串常量池位于堆内存中，专门用于存储字符串常量，可以提高内存的使用率，避免开辟多块内存存储相同字符串 3、String str=”i”与 String str=new String(“i”)一样吗？不一样因为，前者会将其分配到常量池中，存储于元空间中。而后者会存放在字符串常量池中，存在于堆中 4、String s = new String(“xyz”);创建了几个字符串对象两个对象，一个是静态区的”xyz”，一个是用new创建在堆上的对象。 反射 异常反射机制1、java异常体系 如果某个方法不能按照正常的途径完成任务，就可以通过另一种路径退出方法。在这种情况下会抛出一个封装了错误信息的对象。此时，这个方法会立刻退出同时不返回任何值。另外，调用这个方法的其他代码也无法继续执行，异常处理机制会将代码执行交给异常处理器 异常分类Error：类是指 java 运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果出现了这样的错误，除了告知用户，剩下的就是尽力使程序安全的终止。Exception（RuntimeException、 CheckedException）：RuntimeException 如 ： NullPointerException、ClassCastException； 一个是检查异常CheckedException，如 I/O 错误导致的 IOException、 SQLException。 处理方式抛出异常有三种形式，一是 throw,一个 throws，还有一种系统自动抛异常 ： throws 用在函数上，后面跟的是异常类，可以跟多个； 而 throw 用在函数内，后面跟的是异常对象 try-catchtry块：用于捕获异常，其后可跟0或多个catch块，如果没有catch块，则必须跟一个finally块 catch块：用于处理try捕获到的异常 finally块：无论是否捕获到或者处理了异常，finally块里的语句都会被执行,弱try或者catch语句有return语句时，finally中的语句会被执行，若有返回值会覆盖原始的返回值，如下例子，最终返回0 public static int f(int value) &#123; try &#123; return value * value; &#125; finally &#123; if (value == 2) &#123; return 0; &#125; &#125;&#125; 2、java语言的反射机制指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法；并且对于任意一个对象，都能够调用它的任意一个方法；这种动态获取信息以及动态调用对象方法的功能称为 Java 语言的反射机制 获取calss对象的三种方法//1、调用某个对象的getClass()方法： Person p=new Person(); Class clazz=p.getClass();//2、调用某个类的 class 属性来获取该类对应的 Class 对象：如 Class clazz=Person.class;//3、使用 Class 类中的 forName()静态方法(最安全/性能最好/最常用) ：如 Class clazz=Class.forName(\"类的全路径\"); 获取类方法属性信息//Field 类：Java.lang.reflec 包中的类，表示类的成员变量，可以用来获取和设置类之中的属性值Field[] field=clazz.getDeclaredFields(); for(Field f:field)&#123; System.out.println(f.toString());&#125;//Method 类：Java.lang.reflec 包中的类，表示类的方法，它可以用来获取类中的方法信息或者执行方法Method[] method=clazz.getDeclaredMethods();for(Method m:method)&#123; System.out.println(m.toString()); &#125;//Constructor 类：Java.lang.reflec 包中的类，表示类的构造方法Constructor[] constructor=clazz.getDeclaredConstructors(); for(Constructor c:constructor)&#123; System.out.println(c.toString()); &#125; 通过反射创建对象的方法//1、使用 Class 对象的 newInstance()方法来创建该 Class 对象对应类的实例，但是这种方法要求 该 Class 对象对应的类有默认的空构造器Person p=(Person) clazz.newInstance();//2、先使用 Class 对象获取指定的 Constructor 对象，再调用 Constructor 对象的 newInstance() 方法来创建 Class 对象对应类的实例Constructor c=clazz.getDeclaredConstructor(String.class,String.class,int.class);Person p1=(Person) c.newInstance(\"李四\",\"男\",20); JAVA8新特性 速度更快 – 红黑树：HashMap数据结构由数组+链表改成数组+链表+红黑树 代码更少 – Lambda：允许把函数作为一个方法的参数 强大的Stream API – Stream： 支持链式编程，为集合类和数组提供了一些方便的操作方法 public class test &#123; public static void main(String[] args) &#123; List&lt;String&gt; collected1 = Arrays.asList(\"alpha\",\"beta\"); //对collected1中的元素进行toUpperCase() //将一个集合转换成stream后，通过Filter，map对流进行一些操作，最后再转回对应的ji collected1 = collected1.stream().map(string -&gt; string.toUpperCase()).collect(Collectors.toList()); System.out.println(collected1); String ids = \"1,2,3,4,5\"; List&lt;String&gt; listIds = Arrays.asList(ids.split(\",\")).stream().filter(e -&gt; Integer.parseInt(e)&gt;3).collect(Collectors.toList()); listIds.forEach(e-&gt; System.out.println(e)); //System.out.println(listIds); int[] arr=&#123;1,3,5,7,8,9&#125;; //对arr筛选 int[]arr1= Arrays.stream(arr).filter(e-&gt;e&gt;3).toArray(); &#125;&#125; 最大化减少空指针异常 – Optional： 是一个容器类，代表一个值存在或不存在，原来用null 表示一个值不存在，现在Optional 可以更好的表达这个概念，并且可以避免空指针异常","tags":[{"name":"java基础","slug":"java基础","permalink":"https://xulilei.github.io/tags/java%E5%9F%BA%E7%A1%80/"}]},{"title":"多线程（二）","date":"2020-07-11T07:32:32.000Z","path":"2020/07/11/秋招复习之多线程2/","text":"秋招基础复习之多线程（二）AQSAQS（AbstractQueuedSynchronizer 类）是一个用来构建锁和同步器的框架，各种 Lock 包中的锁（常用的有 ReentrantLock、 ReadWriteLock，countdownlatch、cyclicbarrier）都是基于 AQS 来构建 AQS 工作原理AQS的核心思想是，如果被请求的资源空闲，则将当前请求的线程设置为工作线程，并将该资源设置为锁定状态。如果被请求的资源已经被占用，那么就需要一套线程阻塞等待以及唤醒时锁分配的机制，而这个机制是通过CLH队列锁实现的，即将分配不到锁的线程加入到队列中 CLH锁CLH队列是一个虚拟的双向队列，即不存在队列的实例，仅存在节点之间的关联关系，AQS将请求线程封装成CLH队列的一个Node节点，是一个FIFO的过程 AQS工作步骤AQS 在内部定义了一个 volatile int state 变量，表示同步状态：当线程调用 lock 方法时，会通过tryAcquire()独占该锁 ，如果 state=0，说明没有任何线程占有共享资源的锁，可以获得锁并将 state=1；如果 state不为0，先判断是否属于重入的情况，不是的话，则说明有线程目前正在使用共享变量，则该线程必须加入同步队列（CLH）的队尾进行等待，直到占有资源的线程通过tryRelease()对state进行减一操作释放锁到state=0，其他线程才能够去获取该锁。 AQS公平锁非公平锁 公平锁：在获取锁时，增加了一个当前线程是否为head结点的判断，当且仅当等待队列为空或者当前线程是等待队列的head结点时才会获取该锁 非公平锁：那些尝试获取锁且尚未进入等待队列的线程会和等待队列的head节点的线程发生竞争 AQS组件ReentrantLock与Synchronized 相比，可重入锁ReentrantLock其实现原理有什么不同？从加锁方面：synchronized操作Mark Word，lock调用AQS的state和FIFO队列来控制加锁 Synchronized 通过在对象头中设置标记实现了这一目的，是一种 JVM 原生的锁实现方式 而 ReentrantLock 以及所有的基于 Lock 接口的实现类，都是通过用一个 volitile 修饰的 int 型变量，并保证每个线程都能拥有对该 int 的可见性和原子修改， 其本质是基于 AQS 框架。 从锁释放方面 Synchronized 在 JVM 层面上实现的，不但可以通过一些监控工具监控 Synchronized 的锁定，而且在代码执行出现异常时，JVM 会自动释放锁定； Lock 是通过代码实现的，需要通过 unLock() 来释放锁 从锁粒度方面，ReentrantLock 比 Synchronized 的同步操作更精细 如等待可中断：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，对处理执行时间非常长的同步块很有用。 带超时的获取锁尝试：在指定的时间范围内获取锁，如果时间到了仍然无法获取则返回。 可以判断是否有线程在排队等待获取锁，以及是否获取成功。 可以实现公平锁。 ReadWriteLock虽然 ReentrantLock 和 Synchronized 简单实用，但是行为上有一定局限性，要么不占，要么独占。实际应用场景中， 有时候不需要大量竞争的写操作，而是以并发读取为主，为了进一步优化并发操作的粒度，Java 提供了读写锁。 读写锁基于的原理是多个读操作不需要互斥，如果读锁试图锁定时，写锁是被某个线程持有，读锁将无法获得，而只好等待对方操作结束， 这样就可以自动保证不会读取到有争议的数据 CountDownLatch某个线程通过awit阻塞，其他线程通过countDown方法，每调用一次计数器减1，当计数器为0，主线程awiat放行 CyclicBarrierCyclicBarrier 叫循环栅栏，它实现让一组线程等待至某个状态之后再全部同时执行，而且当所有等待线程被释放后，CyclicBarrier 可以被重复使用。 SemaphoreSemaphore是一个计数信号量，它的作用是限制某段代码块的并发数。通过传入int n表示至多n个线程同时访问，如果超出n则等待，当n=1时，semaphore就是一个syncronized 线程池1：降低线程切换所带来的资源消耗 2：解耦作用：线程的创建于执行分开，方便维护 3：便于其他线程的复用 实现原理 在 Java 中，所谓的线程池中的“线程”，其实是被抽象为了一个静态内部类 Worker，它基于 AQS 实现，存放在线程池 的HashSet workers 成员变量中； 需要执行的任务则存放在BlockingQueue workQueue中。 这样，整个线程池实现的基本思想就是：从workQueue 中不断取出需要执行的任务，放在 Workers 中进行处理。 blockingQueue：生产者不断的向队列中生产任务，直到队列满了阻塞生产者线程一直到队列不满。同样的消费者不断的从队列中取出任务消费直到队列为空时阻塞，不为空继续执行。 创建线程池阿里的开发手册不允许使用Executors去创建线程池，而是通过ThreadPoolExecutor ？通过Executors创建的线程池，通过内部构造方法生成的线程池的初始参数会导致OOM FixedThreadPool 和SingleThreadExecutor：初始化请求队列的长度为Integer.MAX_VALUE，可能会堆积大量请求，导致OOM CachedThreadPool和ScheduledThreadPool：允许创建线程池的数量为Integer.MAX_VALUE，可能会创建大量线程导致OOM ThreadPoolExecutor类分析常见参数corePoolSize：线程池的核心线程数。 在刚创建线程池时线程不会立即启动，到有任务提交时才开始创建线程并逐步线程数目达到corePoolSize maximumPoolSize：线程池允许的最大线程数。 当核心线程满，且阻塞队列也满时，才会判断当前线程数是否小于最大线程数，才决定是否创建新线程 keepAliveTime：超过核心线程数时闲置线程的存活时间。workQueue：任务执行前保存任务的队列，保存由 execute 方法提交的 Runnable 任务。handler：线程池允许的最大线程数。 线程池中的线程已经用完了，无法继续为新任务服务，等待队列也已经排满了，再也塞不下新任务了，这时候我们就需要拒绝策略机制合理的处理这个问题。 线程池种类SingleThreadExecutor 线程池 这个线程池只有一个核心线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束， 那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 FixedThreadPool 线程池 固定大小的线程池，只有核心线程。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。 线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 CachedThreadPool 线程池 无界线程池，如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60 秒不执行任务）线程， 当任务数增加时，此线程池又可以智能的添加新线程来处理任务。 ScheduledThreadPool 线程池 核心线程池固定，大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 ThreadPoolExecutor handler拒绝策略AbortPolicy ： 直接抛出异常，阻止系统正常运行 CallerRunsPolicy ： 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。 DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。 DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。 执行execute()⽅法和submit()方法的区别是什么呢？execute()：用于提交不需要返回值的任务，所以通常传入Runnable对象 submit()： 用于提交需要返回值的任务，线程池会返回一个Futrue类型的对象，通过get获取返回值，因此通常传入Callable对象 创建线程池过程 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务； 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列； 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务； 如果等待队列满了的同时，正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会执行拒绝策略。 当一个线程完成任务时，它会从队列中取下一个任务来执行。 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断。 如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。 任务调度的过程维护了一个二级队列，当有外部任务进来时候，会根据任务的优先级进行区分，并存放在不同的优先级队列中，调度线程是一个死循环，会一直执行任务调度 当线程池队列满时，暂时不进行任务调度，直到线程池队列有空间，遍历二级队列，找到优先级最高的任务将其放入线程池队列中，并结束本轮循环。如果没有高优先级的任务，则先设定一个阈值N，当活跃线程大于N时才会去执行低优先级的任务。设置这个阈值是为了高优先级的任务无法得到优先执行 具体情况下如何设置线程池线程数1、高并发，执行时间短的业务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换 2、并发不高、任务执行时间长的计算密集型，和1策略一样，仍然是降低线程池线程数，减少上下文切换带来的开小 3、并发不高、任务执行时间长的IO密集型，可以增大线程池数量，因为io密集型不涉及cpu，因此可以让cpu尽可能多的利用 ThreadLocalThreadLocal，线程本地存储， ThreadLocal 的作用是提供线程内的局部变量， 这种变量只在本线程的生命周期内起作用 实现原理ThreadLocal类中有一个静态内部类ThreadLocalMap，相当于一个哈希表，用private Entry[ ] table来存储数据，其中Entry是一个实现了弱引用（下次GC会被回收）的内部类，它的key为弱引用，目的是为了在GC时防止内存泄漏。而value是强引用，GC是会产生key为null，值为value无法回收的内存，造成内存泄露，ThreadLocalMap会在key回收时，自动清理掉key为null的记录 原子类以AtomicInteger为例 public final int get() //获取当前的值public final int getAndSet(int newValue)//获取当前的值，并设置新的值public final int getAndIncrement()//获取当前的值，并⾃增public final int getAndDecrement() //获取当前的值，并⾃减public final int getAndAdd(int delta) //获取当前的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输⼊的数值等于预期值，则以原⼦⽅式将该值设置为输⼊值（update） AtomicInteger原理AtomicInteger主要利用CAS+Volatile+Native方法来保证原子操作，通过本地方法objectFieldO!set()拿到原来值的内存地址，再拿到Volatile修饰的value，最后再通过CAS来进行最终更新值的操作，足以保证在任何时刻任何线程拿到的都是该变量的最新值","tags":[{"name":"多线程","slug":"多线程","permalink":"https://xulilei.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"多线程（一）","date":"2020-07-10T07:16:32.000Z","path":"2020/07/10/秋招复习之多线程/","text":"秋招基础复习之多线程（一）线程线程和进程的区别？进程是系统资源分配的最小单位，线程是CPU调度的基本单位 线程不能看成独立应用，而进程可以 进程有独立的地址空间，相互不影响，而线程没有独立的地址空间，只是进程的不同执行路径 进程的切换开销比线程大 Java进程和线程的关系运行一个程序会产生一个进程，一个进程至少一个线程 每个进程对应一个JVM实例，多个线程共享JVM的堆 线程的状态(6种)初始(NEW)：新创建了一个线程对象，但还没有调用start()方法。 运行(RUNNABLE)：Java线程中将就绪（ready）和运行中（running）两种状态笼统的称为“运行”。 阻塞(BLOCKED)：表示线程阻塞于锁。 等待(WAITING)：进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断)不会被分配CPU执行时间，由Object.wait()和Thread.join()导致 超时等待(TIMED_WAITING)：该状态不同于WAITING，它可以在指定的时间后自行返回。 终止(TERMINATED)：表示该线程已经执行完毕 start和run方法的区别run()方法只是Thread的一个普通方法的调用，会继续使用当前线程执行该方法 start()方法会创建一个新的线程并启动,start()方法会调用JVM的StartThread方法创建一个子线程，并且通过thread_entry方法取调用子线程中的run方法 所有线程都是通过start方法开启的 Thread类和Runnable接口是什么关系?Thread是实现了Runnable接口的类，使得run支持多线程 因为类的单一继承性，推荐多使用Runnable接口 Runnable需要通过构造:Thread t = new Thread(new Runnable()) t.start()启动 实际上所有的多线程代码都是通过运行Thread的start()方法来运行的。因此，不管是扩展Thread类还是实现Runnable接口来实现多线程，最终还是通过Thread的对象的API来控制线程的 如何实现处理线程的返回值1：主线程等待法(缺点是需要自己实现循环的等待方法，变量多的话代码臃肿) 2：使用Thread类的join()阻塞当前线程以等待子线程处理完毕，缺点是不能更精细的处理，只能等待join()线程全部执行完毕 3：通过Callable接口实现：FutureTask和线程池获取 利用FutureTask获取: FutureTask&lt;&gt; task = new FutureTask&lt;&gt;(new MyCallable())，这里的MyCallable必须实现Callable接口,然后new Thread(task).start()开启新线程，调用task.get();可以或者返回值 利用线程池获取: ExecutorService newCachedThreadPool = Executors.newCachedThreadPool(); 然后调用线程池的提交方法Future future = newCachedThreadPool.submit(new MyCallable()); 返回一个Future，调用future.get()获取返回值 sleep()和wait()的区别sleep是Thread类的方法，wait是Object类中定义的方法，也是native中的方法 sleep()方法可以在任何地方使用，而wait()方法只能在synchionized方法或synchronized块中使用 最本质区别： Thread.sleep只会让出CPU，不会导致锁行为的改变 Object.wait()不仅让出CPU，还会释放已经占有的同步资源锁，并进入等待池中，不会再竞争锁，需要通过notify或者notifyAll()唤醒 锁池和等待池的区别锁池：假设某个线程想进入一个对象的synchronized方法，而这个对象锁却被其他线程所占有，该线程就会进入一个地方取等待锁的释放，这个地方就是锁池 等待池：假设线程A调用了某个对象的wait方法，线程A就会释放该对象的锁，同时进入该对象的等待池中，进入到等待池中的线程不会取竞争该对象的锁，除非被 notify唤醒 notify()和notifyAll()的区别 notify只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会 notifyAll会让所有处于等待池的线程全部进入锁池去竞争获取锁的机会 interrupt()调用interrupt()，通知线程应该中断了 1：如果线程处于被阻塞状态，那么线程将立即退出被阻塞状态，并且抛出一个InterruptedException异常。 2：如果线程处于正常活动状态，那么会将线程的中断标志设置为true，设置中断标志的线程将继续正常运行，不受影响,在运行任务时，我们已经经常检查本线程的中断标志位，如果被设置了中断标志，就自行停止线程 调用stop()，是让线程强制执行，已经不再推荐使用 死锁线程死锁和进程死锁线程死锁：线程A想要持有线程B持有的资源1，线程B想要持有线程A持有的资源2，互相等待，造成死锁 进程死锁的四大条件 互斥条件：即任意时刻，一个资源只能有一个线程持有 请求与保持：在一个线程请求资源而阻塞的时候，不会释放自己已经持有的资源 不可剥夺：线程已经获得的资源不能被其他线程强行剥夺，只能等待自己释放 循环等待：若干进程之间形成一种头尾相接的循环等待的关系 如何避免死锁破坏进程死锁的四大条件 互斥条件：这个做不到 请求与保持：一次性申请所有用到的资源，申请不到线程不工作 不可剥夺：申请其他资源时，如果一段时间申请不到则主动释放已持有的资源 循环等待：破坏循环等待 synchronized线程安全的主要诱因 1：存在共享数据（也成临界资源） 2：存在多条线程共同操作这些共享数据 解决线程安全问题的根本方法 同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再对共享数据进行操作 互斥锁的特性 互斥性：在同一时间只允许一个线程持有某个对象锁 可见性：必须确保在锁被释放之前，对共享变量所做的修改，对于随后获得该锁的另一线程是可见的 什么是可重入性 ，为什么说 Synchronized是可重入锁？ 从互斥性的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁时，将会处于阻塞状态，但当一个线程再次请求自己持有对象的锁时，这种情况属于重入。可重入性是锁的一个基本要求，如果不能够重入，会发生自己锁死自己的情况。 获取对象锁的两种用法 同步代码块，synchronized(this)，锁的是括号中的实例对象，代码块的外面，方法的里面还是异步的。 同步非静态方法（synchronized method），锁的是当前对象的实例对象，方法整个都是同步的，需要获得当前对象的锁 获取类锁的两种用法 同步代码块 synchronized(类.class) 锁的是小括号()中的类对象(Class对象) 同步静态方法 synchronized static method 锁的是当前对象的类对象(Class对象) 底层实现 Java对象在内存中由三部分组成，对象头，实例数据，对齐填充，其中对象头的是synchronized的核心，其中的Mark Word部分存储着锁信息，包括锁的类型，状态标志，通过在对象头设置标记，从而达到了获取锁和释放锁的目的 monitor:每个java对象天生自带了一把看不见的锁,就是monitor锁，在java虚拟机中，monitor是由ObjectMonitor(在JVM中由C++)实现的，查看JVM中ObjectMonitor源码，里面有一个count_计数器 sychronized方法：生成的字节码文件中会多一个ACC_SYNCHRONIZED标志位，当一个线程访问方法时，会先取检查是否存在ACC_SYNCHRONIZED标志，如果存在，执行线程将先获取monitor，获取成功后才能执行方法体，方法执行完后再释放monitor。方法执行期间，其他任何线程都无法再获得同一个monitor对象 synchronized代码块：加了synchronized关键字的代码段，生成的字节码文件中会多出monitorenter和monitorexit两条指令，每个monitor维护着一个记录着次数的计数器_count，未被拥有的monitor的该计数器为0，当一个线程执行monitorenter指令，当前线程试图获取对象锁，如果此时的monitor的count计数器为0，线程成功获得monitor，计算器加1，当同一个线程执行了monitorexit指令，计算器减1，当计算器为0时，monitor便被释放. JDK6以后对于synchronized的优化自旋锁和自适应自旋锁 许多情况下，共享数据的锁定状态持续时间较短，切换线程不值得，通过让线程执行忙循环等待锁的释放，不让出CPU、 缺点：若锁被其他线程长时间占用，会带来许多性能上的开销 自适应自旋锁：自旋的次数不再固定，由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定 锁消除 如果某个锁不可能被其他线程引用，比如局部变量，由于栈私有，JVM会自动消除内部对象的锁 锁粗化 如果检测到一连串的操作都是对同一个对象加锁，JVM会将锁的范围粗化到这一连串操作的外部 synchronized锁的四种状态以及升级过程过程 无锁–偏向锁–轻量级锁–重量级锁 偏向锁: 如果一个线程获得了锁，那么锁就进入偏向模式，Mark Word结构也变为了偏向锁结构，当该线程再次请求锁时，只需要检查Mark Word的锁标记位为偏向锁以及当前线程的ID等于Mark Work 的ThreadID即可。 不适用于锁竞争比较激烈的多线程场合 轻量级锁 轻量级锁由偏向锁升级来的，当第二个线程加入锁的争用时，偏向锁会升级为轻量级锁 每个线程都有自己的栈针，会在栈针中生成一个LockRecord指针，通过CAS去争夺这个锁，LR修改成功的线程获得该锁，而另一个线程会自动进入循环CAS获取这个锁的过程，该过程被称为自旋，因此轻量级锁也被称为自旋锁 重量级锁 轻量级锁自旋锁由于一直处于循环CAS的过程，会占据一定量的系统资源，自JDK6后JVM会自适应控制自选次数，当自选次数超过该阈值，则会自动升级为重量级锁。 升级成重量级锁后，会形成一个队列，没有竞争到锁的线程会进入该队列，且不消耗系统资源 三种锁的优缺点以及使用场景 偏向锁的优缺点以及使用场景 优点：加锁和解锁不需要CAS操作，没有额外的性能消耗，和非同步方法相比性能差距较小 缺点：如果线程间存在锁竞争，会带来额外的锁撤销的消耗 使用场景：只有一个线程访问同步块或者同步方法 轻量级锁的优缺点以及使用场景 优点：竞争的线程不会阻塞，提高了响应速度 缺点：若线程长时间抢不到锁，自旋会消耗CPU性能 使用场景：线程交替执行同步块或者同步方法的场景 重量级锁的优缺点以及使用场景 优点：线程竞争不适用自旋，不会消耗CPU 缺点：线程阻塞，相应时间缓慢，在多线程下，频繁的获取释放锁，会带来巨大的性能消耗 使用场景：追求吞吐量，同步块或同步方法执行时间较长的场景 Volatile指令重排序指令重排序是编译器和处理器为了高效对程序进行优化的手段，它只能保证程序执行的结果时正确的，但是无法保证程序的操作顺序与代码顺序一致。这在单线程中不会构成问题，但是在多线程中就会出现问题。 指令重排序需要满足的条件 在单线程环境下不能改变程序运行的结果 不存在数据依赖关系的 不满足happens-before原则 Java内存模型JMM JMM中的主内存（main memory） 存储Java实例对象 包括成员变量，类信息，常量，静态变量 属于数据共享的区域，多线程并发操作会引发线程安全问题 JMM中的工作内存（L1,L2,L3） 存储当前方法的局部变量信息，局部变量对其他线程不可见 字节码行号指示器，Native方法信息 属于线程私有的数据区域，不存在线程安全问题 读写过程 将主存中的数据加载到工作内存中 CPU对工作内存中的数据进行修改 将每个线程工作内存中修改后的值刷新到主内存中 Volatile原理关键字 volatile 是 Java 虚拟机提供的最轻量级的同步机制。当一个变量被定义成 volatile 之后，具备两种特性： 1.保证此变量对所有线程的可见性。当一条线程修改了这个变量的值，新值对于其他线程是可以立即得知的。 2.禁止指令重排序。普通变量仅仅能保证在该方法执行过程中，得到正确结果，但是不保证程序代码的执行顺序。 如何实现上述两种特性？ 线程可见性：主要通过缓存一致性协议和总线锁两种方式实现 立即将线程中工作内存的数据写会到主内存中 其他处理器数据监测判断自己线程工作区内存中的值是不是过期了，如果过期了，就会将对应的数据置为无效。而当处理器对这个数据进行修改时，会重新从内存中把数据读取到缓存中进行处理。 禁止指令重排序： 代码级别：对变量加上volatile修饰 字节码级别：会生成ACC_volatile指令 JVM级别：通过JVM的内存屏障禁止内存屏障前后的指令执行重排序优化 DCL单例模式需不需要volatile指令？需要，因为在new一个对象的过程中对象并不是刚被创建就会将构造函数中的参数赋值给变量，而是会有一个半初始化的状态，此时如果发生指令重排序会使得别的线程拿到这个半初始化的对象，造成BUG，因此需要双重检测（对象创建的过程见https://xulilei.github.io/2020/07/06/%E7%A7%8B%E6%8B%9B%E5%A4%8D%E4%B9%A0%E4%B9%8BJVM/） //单例模式public class Singleton{ private Volatile static Singleton instance; private Singleton(){}; public static Singleton getInstance(){ //第一次检测 if(instance==null){ synchronized(Singleton.class){ //第二次检测 if(instance==null){ instance=new Singleton(); } } } return instance; }} Syncronized和volatile对比 volatile本质是告诉JVM当前变量在工作内存中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住直到该线程完成变量操作为止。 volatile仅能使用在变量上；synchronized则可以使用在变量，方法和类级别 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞 volatile仅能实现变量的修改的可见性，不能保持原子性；而synchronized则可以保证变量修改的可见性和原子性 CAS 实现过程 底层通过Unsafe类实现原子性操作，包括三个操作数——内存地址V，预期原值A和新值B 将内存地址的值与预期原值进行比较，如果匹配，那么处理器将该位置的值，自动更新为新值，否则会进行自旋，然后再重新以当前的值为原值再次比较，这也是自旋锁实现的基础 乐观锁悲观锁 悲观锁Syncronized：是典型的悲观锁，总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。 乐观锁CAS：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据 CAS缺点（乐观锁的缺点） 如果自旋时间长，则CPU资源开销很大 只能保证一个共享变量的原子操作 ABA问题 如果内存地址V初次读取的值为A，并且在准备赋值的时候检查到也为A，如果它曾经被改为了B，但是后来又被改成了A，那么CAS就会误认为它从来没被改变过 解决：给值加上一个版本号每当修改一次将值加1，或者使用AtomicStampedReference（ 版本戳） document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"多线程","slug":"多线程","permalink":"https://xulilei.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"集合","date":"2020-07-08T04:59:33.000Z","path":"2020/07/08/秋招复习之集合/","text":"秋招基础复习之集合 集合类存放于 Java.util 包中， 主要有 3 种： set(集）、 list(列表包含 Queue）和 map(映射)。Collection： Collection 是集合 List、 Set、 Queue 的最基本的接口。Iterator：迭代器，可以通过迭代器遍历集合中的数据。Map：是映射表的基础接口 。 Collection对比 ListArrayList（数组，线程不安全）ArrayList 是最常用的 List 实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数组的缺点是每个元素之间不能有间隔， 当数组大小不满足时需要增加存储能力，就要将已经有数组的数据复制到新的存储空间（1.5倍扩容）中。 当从 ArrayList 的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。 Vector（ 数组，线程安全）Vector 与 ArrayList 一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写 Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问 ArrayList 慢，扩容机制与arraylist相似，但是扩容的大小被称为扩容因子，可以自己定义一般为1倍。 stack继承自vector，是一个先进后出的数据结构 LinkList（链表，线程不安全）LinkedList 底层使用的数据结构是一个双向链表，，由于有每个元素之间有指针指向，因此适合增删，而查找需要从头结点开始遍历，因此不适合快速查找，添加元素直接在相应的位置添加，没有初始化大小因此没有扩容机制。 SetHashSet（Hash表）set最主要的功能是去重，底层是一个hashmap，key存储的是hashset的值，value是一个静态的present对象，由于hashmap的key是唯一的，因此达到去重的功能。 HashSet 存储元素的顺序并不是按照存入时的顺序（和 List 显然不同） 而是按照哈希值来存的所以取数据也是按照哈希值取得。元素的哈希值是通过元素的hashcode 方法来获取的, HashSet 首先判断两个元素的哈希值，如果哈希值一样，接着会比较equals 方法 如果 equls 结果为 true ， HashSet 就视为同一个元素。如果 equals 为 false 就不是同一个元素，以链表的形式。 TreeSet（二叉树）底层使用的是treeMap，TreeSet()是使用二叉树的原理对新添加的对象按照指定的顺序排序（升序、降序），每增加一个对象都会进行排序，将对象插入的二叉树指定的位置，如果key已经存在，则采用覆盖的做法，达到了去重的目的Integer 和 String 对象都可以进行默认的 TreeSet 排序，而自定义类的对象是不可以的， 自己定义的类必须实现 Comparable 接口，才可以正常使用。 LinkHashSet（ HashSet+LinkedHashMap）对于 LinkedHashSet 而言，它继承与 HashSet、又基于 LinkedHashMap 来实现的。由于底层使用 LinkedHashMap 来保存所有元素 ，因此可以通过双向链表来记录插入的顺序 Queue队列主要遵循FIFO的规则，其下主要有dqueue和priorityQueue，duque是一个双端队列，可以实现从队首和队尾添加元素删除元素 Map HashMap底层实现JDK1.7实现数组+链表 HashMap 的主干是一个数组，然后数组中每个元素是一个单向链表。上图中，每个绿色的实体是嵌套类 Entry 的实例， Entry 包含四个属性： key, value, hash 值和用于单向链表的 next。 //默认大小static final int DEFAULT_INITIAL_CAPACITY = 16;//最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//默认负载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;//存储元素的数组transient Entry[] table;//键值对数量transient int size;//阈值，size大于阈值触发扩容int threshold;//负载因子默认是0.75final float loadFactor;//修改次数transient volatile int modCount; Put的过程面试答： 容器为空时，调用初始化方法，找到大于threshold的最小二次幂数 如果键为空，则放在数组下标为0的位置，如果已经存在就覆盖旧值 根据key得到hash值，再通过indexFor方法得到数组下标 若该数组没有数据，则新建链表一个节点 若该数组下标有数据，则遍历链表，若value存在，则用新value覆盖oldvalue， 若value不存在，则采用头插法新建一个链表节点 上述新建过程需要判断size是否大于threshold，触发相应的扩容过程 resize过程 创建一个新的Hash Table，两倍大小 将Old Hash Table上的数据迁移到New Hash Table上 transfer()，采用头插法，rehash，用hash&amp;（扩容后的length-1） 重新计算threshold //resize()方法中的transfer()，采用头插法 void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125; &#125; 造成死循环的原因在扩容的过程中，将原来hashMap数组中的链表转移到新的hashmap中时，采用的是头插法进行指针操作，会将原hashmap的链表顺序反转，但如果此时再进来一个线程，会导致next指针指向一个环，形成死循环 JDK1.8实现数组+链表+红黑树，当链表中的元素超过了 8 个以后，会将链表转换为红黑树 put过程文字描述示意图 resize过程与1.7相差不多 主要是transfer()不一样 采用尾插法，rehash采用hash与数组长度右移一位，为0下标不变，为1下标加上原来长度 ConCurrentHashMap底层实现hashTable实现表锁 JDK1.7基于reentrantlock+segment+HashEntry实现 put过程与hashmap不同的是在定位存储位置时，需要通过2次hash定位 第一次key的hash来定位segment的位置，如果该segment还没有初始化，即通过cas操作进行初始化操作 第二次hash定位真正要插入的hashEntry数组索引，利用继承reentrantlock获得的tryLock方法获取锁 获取成功，遍历链表，key值存在更新value，不存在则setNext(first)在 头部插入新节点 获取失败，则以自旋的方式继续条用trylock获取锁 get过程get通过大量的volatile关键字，保证读取到的数据是最新的，过程也是先定位到segment再定位到hashEntry的具体位置 resize过程使用头插法的方式迁移，由于segment锁的存在，这里不会是线程安全的 创建一个两倍长度大小的新数组 遍历旧数组，找到第一个后续所有节点扩容后index不变的节点，记为LastRun，并将其迁移到新数组中 接着处理lastRun之前的节点，将其逐一迁移到新数组中 JDK1.81.8的ConcurrentHashMap取消了分段锁，采用CAS和syncronized来保证并发安全，syncronized只锁定一个node链表的首节点 put过程 根据key的hash值，找到对应的数组索引节点，如果还没有初始化，则通过cas进行初始化工作 若该节点的值为moved说明正在扩容，则加入扩容过程，对该桶的节点进行转移（扩容时的写操作） 对桶中第一个节点加锁，若获取成功，遍历node节点，key值存在更新value，不存在则采用尾插法加入新节点 若长度达到红黑树转化阈值，则转化为红黑树 get过程 计算hash值，定位到该table索引位置 遍历node节点，匹配则返回value，没有返回null 如果该数组位置正在扩容，通过forwardingNode定位到对应位置，帮助扩容，完成后读取数据 resize过程一个线程发起扩容过程后，其他线程发起的读写请求遇到forwardingNode时会加入扩容过程 HashMap面试问题总结1、为什么hashmap的长度是2的幂次方？首先不可能直接用散列化后的值直接作为数组下标，而是需要对长度进行取模运算，再得到下标。这个数组下标的计算方法为（n-1）&amp;hash。之所以使用与操作是因为与操作的性能优于取余。而当length是2的幂次方时，hash%length==hash&amp;（length-1），因此长度是2的幂次方。 2、hashmap1.7与1.8的区别(1)结构不同1.7采用数组+链表，1.8采用数组+链表+红黑树 为什么采用红黑树 链表在数据量大的时候查询会变得很缓慢 对于二叉搜索树，可能存在极度不均衡退化成链表或者层数过多的情况 红黑树相比于AVL树并不追求极致的平衡，因此在增删的时候不需要频繁的旋转 (2)插入位置不同JDK1.7用的是头插法，而JDK1.8及之后使用的都是尾插法，因为JDK1.7是用单链表进行的纵向延伸，当采用头插法时可以避免遍历链表造成的性能损失，但是会容易出现逆序及多线程下环形链表死循环问题。但是在JDK1.8之后因为加入了红黑树使用尾插法，插入效率提升，且能够避免出现逆序和链表死循环的情况 (3)扩容数据存储位置的计算方式不一样1.7通过扰动之后的hash&amp;（length-1）得到数组下标，1.8在扩容中只用判断原来的 hash 值与数组长度左移动的一位(扩大一倍)按位与操作是 0 或 1 就行，0 的话索引就不变，1 的话索引变成原索引加上扩容前数组 (4)扩容时数据的插入时机不同1.7是先扩容后插入（先判断达不达到扩容要求），1.8是先插入后扩容（先插入后再判断需不需要扩容） 3、为什么HashMap是线程不安全的，实际会如何体现第一，如果多个线程同时使用put方法添加元素:假设正好存在两个put的key发生了碰撞(hash值一样)，那么根据HashMap的实现，这两个key会添加到数组的同一个位置，这样最终就会发生其中一个线程的put的数据被覆盖 第二、hashmap1.7在扩容时，由于采取头插法会导致死循环 4、为什么要使用syncronized来代替reentrantlock主要原因是由于锁的粒度降低了，1.7中使用的是segment锁，范围大。但在1.8中由于只锁定数组的头结点，因此syncronized的效率并不低","tags":[{"name":"集合","slug":"集合","permalink":"https://xulilei.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"JVM","date":"2020-07-06T07:07:16.000Z","path":"2020/07/06/秋招复习之JVM/","text":"秋招基础复习之JVMJVM内存模型 JVM-GC垃圾回收知识点概览 判断对象可回收引用计数法（JVM中不用）给对象添加一个计数器，每当有一个地方引用计数器+1，反之失效-1，当计数器为0的时候，则代表该对象不太可能会被继续用到，则判断该对象为可回收对象，但是会出现循环引用的问题 可达性分析算法为了解决引用计数法的循环引用问题， Java 使用了可达性分析的方法。通过一系列的“GC roots”对象作为起点搜索。如果在“GC roots”和一个对象之间没有可达路径，则称该对象是不可达的。 GC roots：类加载器，Thread，虚拟机栈的引用，方法区static变量的引用，本地方法栈的引用等等 强软弱虚引用强引用在 Java 中最常见的就是强引用， 把一个对象赋给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它处于可达状态，它是不可能被垃圾回收机制回收的，即使该对象以后永远都不会被用到 JVM 也不会回收。因此强引用是造成 Java 内存泄漏的主要原因之一。 软引用软引用需要用 SoftReference 类来实现，对于只有软引用的对象来说，当系统内存足够时它不会被回收，当系统内存空间不足时它会被回收。软引用通常用在对内存敏感的程序中。 弱引用弱引用需要用 WeakReference 类来实现，它比软引用的生存期更短，对于只有弱引用的对象来说，只要垃圾回收机制一运行，不管 JVM 的内存空间是否足够，总会回收该对象占用的内存。 虚引用不能单独使用，必须和引用队列联合使用。 虚引用的主要作用是跟踪对象被垃圾回收的状态。 垃圾收集算法分代收集算法新生代的复制算法eden、survivorFrom SurvicorTo按照8比1比1划分新生代 1：eden、 survivorFrom 复制到 SurvivorTo，年龄+1首先，把 Eden 和 survivorFrom 区域中存活的对象复制到 SurvivorTo 区域（如果有对象的年龄以及达到了老年的标准15，则赋值到老年代区），同时把这些对象的年龄+1（如果 SurvivorTo 不够位置了就放到老年区）； 2：清空 eden、 survivorFrom然后，清空 Eden 和 survivorFrom 中的对象 3： SurvivorTo和 ServicorFrom 互换最后， SurvivorTo 和 survivorFrom互换，原 SurvivorTo 成为下一次 GC 时的 survivorFrom区。 老年代的标记-整理算法首先扫描一次所有老年代，标记出存活的对象，让所有存活对象都向一端移动，然后直接清理掉端边界以外的内存 分区收集算法分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的好处是可以控制一次回收多少个小区间 , 根据目标停顿时间, 每次合理地回收若干个小区间(而不是整个堆), 从而减少一次 GC 所产生的停顿。 垃圾收集器 新生代Serial：单线程收集器，采用复制算法它不但只会使用一个 CPU 或一条线程去完成垃圾收集工作，并且在进行垃圾收集的同时，必须暂停其他所有的工作线程，直到垃圾收集结束。它简单高效，对于限定单个 CPU 环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此 Serial垃圾收集器依然是 java 虚拟机运行在 Client 模式下默认的新生代垃圾收集器。 Parnew：serial收集器的多线程版本，采用复制算法除了使用多线程进行垃圾收集之外，其余的行为和 Serial 收集器完全一样， ParNew 垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程，ParNew垃圾收集器是很多 java虚拟机运行在 Server 模式下新生代的默认垃圾收集 Parallel Scavenge：复制算法，可控制吞吐量的收集器采用复制算法，多线程并行，这些与parnew相似，它的独特之处在于它关注的点是一个可控制的吞吐量，通过参数MaxGCPauseMillis可以控制收集器最大停顿时间，GCTimeRatio可以直接设置吞吐量的大小，以及UseAdaptiveSizePolicy开启GC自适应调节策略，将gc细节交给JVM完成，这是parnew所没有的 老年代Serial Old：serial收集器的老年代版本，使用标记-整理算法工作时会暂停用户线程 Parallel Old：Parallel Scavenge收集器的老年代版本，多线程，标记-整理算法工作时会暂停用户线程 CMS：采用标记-清除算法由于耗时最长的并发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作， 所以总体上来看CMS 收集器的内存回收和用户线程是一起并发地执行。 第一步-初始标记只是标记一下 GC Roots 能直接关联的对象，速度很快，仍然需要暂停所有的工作线程。 第二步-并发标记进行 GC Roots 跟踪的过程，和用户线程一起工作，不需要暂停工作线程 第三步-重新标记为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。 第四步-并发清除清除 GC Roots 不可达对象，和用户线程一起工作，不需要暂停工作线程。 缺点：1、并发清理阶段产生的没有被回收掉的浮动垃圾，从而导致另一次full GC的产生。 2、并发清楚会产生内存碎片 Garbage first： 分区收集以及采用标记-整理算法基于标记-整理算法，不产生内存碎片。可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。 G1 收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间， 优先回收垃圾最多的区域。区域划分和优先级区域回收机制，确保 G1 收集器可以在有限时间获得最高的垃圾收集效率。 JVM类加载机制类加载过程 加载加载是类加载过程中的一个阶段， 这个阶段会在内存中生成一个代表这个类的 java.lang.Class 对象 验证这一阶段的主要目的是为了确保 Class 文件的字节流中包含的信息语法符合当前虚拟机的要求 准备准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。 解析解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。 符号引用符号引用就是 class 文件中的： CONSTANT_Class_info、 CONSTANT_Field_info、 CONSTANT_Method_info 等类型的常量，在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。 直接引用直接引用可以是指向目标的指针。如果有了直接引用，那引用的目标必定已经在内存中存在 初始化初始化阶段是类加载最后一个阶段，前面的类加载阶段由 JVM 主导。到了初始化阶段，才开始真正执行类中定义的 Java 程序代码 类加载器类加载器的种类 启动类加载器(Bootstrap ClassLoader)：负责加载核心库java.*，由C++编写。 扩展类加载器(Extension ClassLoader)：负责加载扩展库，由java编写。 应用程序类加载器(Application ClassLoader)：负责加载程序所在目录，java编写。 以及自定义加载器。 双亲委派机制与全盘委派机制1、双亲委派机制：先自下而上的委托父类加载目标类，只有当父类加载器反馈自己无法完成这个请求的时候，子类加载器会自上而下的会尝试自己去加载 2、全盘委派机制：该类所依赖的类都由该类的类加载器加载 类加载方式new 隐式加载，支持传参，loadclass与forname显式加载，不支持传参。springioc可以懒加载 对象创建的步骤区别于类加载的过程1、虚拟机遇到new命令时，首先检查这个对应的类能否在常量池定位到一个符号引用 2、判断这个类是否已经被加载解析（解析让符号引用变成直接引用）和初始化，如果没有则进行相应的类加载过程 3、为新生对象在java堆中分配内存空间（指针碰撞和空闲链表），这一步是半初始化（单例的双重检测机制就是为了防止半初始化） 4、设置对象头相关数据（GC分代年龄、对象的哈希吗、锁等元数据信息）–java对象模型 5、执行init方法，赋值 对象分配流程1、首先尝试栈上分配，即如果该对象的作用域不会逃逸出该方法之外，则可以将其分配在栈上，随着方法的结束而销毁，不用通过GC收集 2、若失败则采用tlab分配，会先构造一种线程私有的堆空间，哪怕这块堆空间特别小，但是只要有，就可以每个线程在分配对象到堆空间时，先分配到自己所属的那一块堆空间中，避免同步带来的效率问题，从而提高分配效率 3、若还是失败，则正常的分配至eden区，若太大则直接进入老年代 JVM核心参数-Xms：最小堆 -Xmx：最大堆 -Xmn：新生代内存 -Xss：栈大小","tags":[{"name":"JVM","slug":"JVM","permalink":"https://xulilei.github.io/tags/JVM/"}]},{"title":"计网","date":"2020-07-05T07:39:30.000Z","path":"2020/07/05/秋招复习之计网/","text":"秋招基础复习之计网7 层模型主要包括： 物理层：设备之间的比特流传输。 数据链路层：主要将从物理层接收的数据进行 MAC 地址（网卡的地址）的封装与解封装。在这一层工作的设备是交换机，数据通过交换机来传输。 主要协议为ARP协议，提供IP 地址到对应的硬件地址提供动态映射 ARP协议：IP地址到对应的硬件地址提供动态映射 ARP欺骗：主机的地址映射是基于高速缓存的，动态更新的。地址刷新是有时间限制的。可以通过下次更新之前修改计算机上的地址缓存，造成网络不通 网络层：主要将从下层接收到的数据进行 IP 地址（例 192.168.0.1)的封装与解封装。在这一层工作的设备是路由器，常把这一层的数据叫做数据包。 传输层：定义了一些传输数据的协议和端口号（WWW 端口 80 等），如：TCP，UDP协议。 主要是将从下层接收的数据进行分段进行传输，到达目的地址后在进行重组。 常常把这一层数据叫做段。 会话层：通过传输层（端口号：传输端口与接收端口）建立数据传输的通路。主要在你的系统之间发起会话或或者接受会话请求（设备之间需要互相认识可以是IP也可以是 MAC 或者是主机名） 表示层：主要是进行对接收的数据进行解释、加密与解密、压缩与解压缩等（也就是把计算机能够 识别的东西转换成人能够能识别的东西（如图片、声音等）） 应用层：主要是一些终端的应用，比如说FTP（各种文件下载），WEB（IE浏览），QQ之类的（你 就把它理解成我们在电脑屏幕上可以看到的东西．就 是终端应用）。 TCP/IP协议TCP协议：是一种可靠的，面向连接的基于字节流的传输控制协议 UDP协议：是一种不可靠的，面向报文的用户数据报协议 IP协议：解决了在虚拟网络中数据报传输路径的问题，使得网络层屏蔽底层细节，专注于网络层数据的转发，根据路由表完成数据包的发送 TCP三次握手四次挥手三次握手 过程首先，客户端会发送一个syn=1，以及本次握手的序列号seq=x给服务端，并进入同步已发送的状态，服务端接收到客户端的连接请求后，会回发一个syn=1，确认号ACK=1，以及第二次握手的序列号seq=y，第一次握手的序列号加1的确认号给客户端，并进入同步已收到的状态，客户端收到服务端的信息后会检查确认号ACK是否为1，以及确认序列号是否正确，如果正确，则会回发ack=1，第三次握手的序列号，以及第二次握手的序列号加1的确认序列给服务端并进入建立连接状态，同样的服务器在接受到消息后会检查ack确认号是否为1以及确认序列号是否正确，如果正确则进入建立连接状态，自此3次握手结束，连接建立。 为什么要三次握手？即为什么A还要发送一次确认请求给服务器B，这是为了防止已经失效的连接请求突然又传送到了B。存在这样的一种情况，当A发送连接请求给B，此时由于网络拥堵造成服务器B没有及时收到连接请求，因此A又重新发送了一个请求给B，正常建立连接后，拥堵的第一次请求又传送到了服务器B，如果不采用三次握手，那么B又会发送确认连接的请求给B，又会建立一个新的连接，会浪费许多资源 syn攻击在第一次握手后，服务器向客户端发送确认请求信息后需要等待客户端的再次确认信息，如果此时客户端掉线，服务器会一直尝试发送5次请求信息，会浪费大量资源，可能导致正常的syn请求无法完成。 那么如何防护呢？ 当syn队列满后，通过tcp_syncookies参数回发syn_cookie给客户端，如果正常连接，客户端会回发这个syn_cookie给服务器，此时即使syn队列满了，依然可以正常建立连接 建立连接后客户端出现问题怎么办？服务器会发送保持会话报文，若一直没有响应一定次数，服务器会中断此次会话 四次挥手 过程首先，客户端会发送一个fin=1，第一次挥手的序列号seq=x给服务端，并进入终止等待1状态，服务店在接受到来自客户端请求终止连接的请求后会回发一个ack=1，第二次挥手的序列号seq=y，以及第一次挥手的序列号加1的确认序列给客户端并进入等待关闭状态，客户端收到消息后检查ack是否为1以及确认序列是否正确，若正确会进入终止等待2状态。当服务端发送完所有的数据后，会向客户端发送fin=1，确认号ack=1，第三次挥手的序列号，以及第一次挥手序列号+1的确认序列给客户端，并进入最终确认状态，客户端收到后再次检查信息是否正确，若正确回回发一个确认号ack=1，第四次挥手的序列号，以及第三次挥手的序列号+1的确认序列给服务端，并进入timewait状态，等待2nmsl后会自动关闭，客户端收到信息后确认是否正确，若正确则立即关闭连接，自此四次挥手结束，连接关闭 为什么要四次挥手？因为TCP是全双工的，客户端给服务器发送信息的同时，服务器也可以给客户端发送，之所以需要四次挥手，是因为在客户端发送结束请求后，可能服务器的数据还没有传输完毕，因此需要2个等待关闭的状态确保所有数据传输完毕，因此需要四次挥手 为什么客户端还要等待2msl？因为服务器给客户端发送的第二次FIN请求后，客户端回发给服务器的最终确认可能丢失，如果服务器没有收到最终确认，则会再次发送FIN请求给客户端，那么在客户端等待关闭的这2MSL里再次收到请求后，会再次发送最终请求，使得服务器能够正常准确的关闭 如何理解IP协议的不可靠和无连接？不可靠：指的是不能保证数据报能成功地到达目的地。 发生错误时候，丢弃该数据包，发送 ICMP 消息给信源端，可靠性由上层提供。 无状态：IP 不维护关于后续数据报的状态信息。 体现在，IP 数据可以不按顺序发送和接收。A 发送连续的数据报， 来回路由选择可能不一样，路线也不一样，到达先后顺序也不一样。 TCP如何保证可靠性？ 确认机制，发送报文后停止发送，等待确认后再发送 重发机制，没有及时收到确认，将重发数据段。 拥塞控制，当网络拥塞时启用 慢启动（窗口从1开始逐渐增大） 快速重传（收到失序报文立刻重传） 快速恢复（收到重复确认可能没有拥堵，因此不执行慢启动而是快速恢复） 拥塞避免（门限设为一半后开始慢启动算法） 排序，有专门的序列号字段，丢弃重复数据 流量控制，通过滑动窗口实现 TCP链接的数据量只能限制在这个滑动窗口范围内，这个滑动窗口根据情况变化 TCP与UDP区别 tcp对应的协议有：FTP、HTTP udp对应的协议有：DNS HTTP协议http请求报文和响应报文http请求报文由请求行（get/post方法，url的path路径，http版本）、请求头（键值对）、请求体（body） get/post区别1、get请求是通过URL传参，而post请求被放在请求体中，因此决定了get不能代替post发送大量数据 2、get请求的安全性不如post，是由于get请求在url中会被看到 3、get请求是幂等的，post不幂等（幂等就是多次操作结果一样，get查询多次肯定一样，post是改肯定不一样） http响应报文由状态码（Status Code）、HTTP头部（编码格式，过期时间）、响应体（响应的内容） 状态码1XX：请求已接受一部分，正等待剩余部分 2XX：正常接收，201创建资源，202处理完成 3XX：重定向，资源转移，301永久重定向，302暂时移动到新地址 4XX：客户端请求出错，400语法错误，401是要求身份认证，403服务器拒绝请求，404服务器找不到请求的页面 5XX：服务端出错，500服务器内部错误，501服务器不支持本次请求，503服务器维护 转发和重定向的区别转发：是由服务端进行的页面跳转，跳转完后响应到客户端，服务器地址不变 重定向：是由客户端进行的页面跳转，服务器地址改变，请求了两次 需要保留请求数据的使用转发，其他使用重定向，即查询使用转发，增删改使用重定向 http请求过程1、DNS域名解析器解析出IP地址 2、TCP连接（三次握手） 3、浏览器发送HTTP请求 4、服务器处理请求并返回HTTP响应 5、浏览器解析渲染页面 6、释放连接（四次挥手） DNS解析过程1、浏览器首先检查自身缓存有没有解析过这个ip地址，如果有则解析结束 2、如果浏览器中没有，会从操作系统的hosts文件中查找有无缓存 3、若仍然没有，才会真正的请求本地域名服务器，到这里大约80%的域名解析都可以完成 4、若此时仍然没有解析成功，那么就需要顶级域名服务器请求解析 5、顶级域名服务器告诉本地域名服务器该去哪个服务器查询 6、本地域名服务器去对应的服务器查找 7、将最终结果告诉给主机- http长连接，短连接，无状态，HTTP/1.0，HTTP/1.1，HTTP/2.0无状态无状态：。HTTP 是一个无状态的面向连接的协议，所谓的无状态，指的是协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。也就是说，打开一个服务器上的网页和上一次打开这个服务器上的网 页之间没有任何联系，无状态不代表 HTTP 不能保 持 TCP 连接，更不能代表 HTTP 使用的是 UDP 协议（无连接）。 长短连接HTTP/1.0 短连接：客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。适用于而像 WEB 网站的http服务 HTTP/1.1 默认使用长连接：在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据 的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。适用于于操作频繁，点对点的通讯，而且连接数不能太多情况。 HTTP/1.1和HTTP/2.0区别1.1管道传输与 多路复用HTTP/1.1使用管道传输，即客户端与服务器建立连接后不用每次等待服务器响应就可发送新的请求，但是服务器仍然会顺序响应。如果某一请求出现问题，那么后面的请求都无法加载，这就会出现队头阻塞的问题。 在HTTP/2.0中通过多路复用解决了这个问题，即将一个TCP连接分为若干个流（Stream），每个流中可以传输若干消息（Message），这样即使一个请求被阻塞了，也不会影响其他请求 头部数据压缩在HTTP1.1中，消息主体都会经过gzip压缩，但状态行和头部却没有经过任何压缩，直接以纯文本传输。 HTTP2.0对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。 传输格式2.0采用二进制格式而非文本格式 HTTP和HTTPS的区别1、HTTP是超文本传输协议，是明文传输，而HTTPS则是具有安全协议SSL的加密传输 2、http是无状态的，而https是有可以进行加密传输，身份认证的 4、HTTP默认端口是40，HTTPS是443 https工作步骤客户端向服务端发送https请求，请求建立SSL连接 服务端收到请求会将网站的证书公钥等发送给客户端 客户端服务端确认SSL连接的安全等级 客户端向服务端发送根据公钥加密得来的秘钥 服务端解析秘钥，建立连接 HTTPS的优缺点优点1、最主要体现的就是安全性，大大增加了人工攻击的成本 缺点多了一层验证，他们它的效率自然比不上http，价格也是考虑的一个因素 cookie和session的区别1、存储位置不同cookie的数据信息存放在客户端浏览器上。 session的数据信息存放在服务器上。 2、存储方式不同cookie中只能保管ASCII字符串，并需要通过编码方式存储为Unicode字符或者二进制数据。 session中能够存储任何类型的数据，包括且不限于string，integer，list，map等。 3、隐私策略不同cookie对客户端是可见的，别有用心的人可以分析存放在本地的cookie并进行cookie欺骗，所以它是不安全的。 session存储在服务器上，对客户端是不可见的，不存在敏感信息泄漏的风险。 4、有效期不同开发可以通过设置cookie的属性，达到使cookie长期有效的效果。 session依赖于名为JSESSIONID的cookie，而cookie JSESSIONID的过期时间默认为-1，只需关闭窗口该session就会失效，因而session不能达到长期有效的效果。 5、服务器压力不同cookie保管在客户端，不占用服务器资源。对于并发用户十分多的网站，cookie是很好的选择。 session是保管在服务器端的，每个用户都会产生一个session。假如并发访问的用户十分多，会产生十分多的session，耗费大量的内存。","tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xulilei.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"十次方微服务复习","date":"2020-07-01T08:17:02.000Z","path":"2020/07/01/十次方微服务复习/","text":"利用SpringDataJPA完成问答、文章、招聘、交友、吐槽、用户、管理员的增删改以及模糊分页查询1、IdWorker：采用推特开源的雪花算法工具类，每秒能产生26W的id，而不产生id碰撞 SpringDataJpa用法：Dao层接口继承JpaRepository,JpaSpecifationExecutor（复杂查询使用）接口 模糊分页查询 实现条件查询： ​ 3种方式 ：一种是通过在dao层通过nativeQuery编写模糊查询语句，第二种是在dao层通过findBy**Like 另一种通过service层new Specification构造动态查询语句 public List&lt;Label&gt; findSearch(Label label) { return labelDao.findAll(new Specification&lt;Label&gt;() { @Override public Predicate toPredicate(Root&lt;Label&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; list=new ArrayList&lt;&gt;(); //相当于 ****** where labelname like \"%label.getLabelname()%\" if(label.getLabelname()!=null&amp;&amp;!\"\".equals(label.getLabelname())){ //通过root拿到字段名 Predicate predicate = cb.like(root.get(\"labelname\").as(String.class), \"%\" + label.getLabelname() + \"%\"); //一个条件，添加到cb中 list.add(predicate); } //将条件链表转化为数组 Predicate[] parr=new Predicate[list.size()]; list.toArray(parr); //合并所有条件，一起查询 return cb.and(parr); }); } 实现分页查询 dao层构建查询方法时传入pageable对象 service层调用JPA封装的方法时传入page和size，通过PageRequest生成Pgeable对象，service层返回Page对象 controller调用service方法，并通过之前定义好的分页类，返回给前端 //dao层public Page&lt;Label&gt; findAll(Pagealbe pageable){}//service层public Page&lt;Label&gt; findAll(int page,int size){ Pageable pageable=PageRequest.of(page-1,size); return labelDao.findAll(pageable);}//controller@RequestMapping(value = \"/{page}/{size}\",method = RequestMethod.GET) public Result findAll(@PathVariable int page,@PathVariable int size){ Page&lt;Label&gt; all = labelService.findAll(page,size); return new Result(true, StatusCode.OK,\"查询成功\",new PageResult&lt;&gt;(all.getTotalElements(),all.getContent())); }//pageResult类public class PageResult&lt;T&gt; { private long total; private List&lt;T&gt; rows; public long getTotal() { return total; } public void setTotal(long total) { this.total = total; } public List&lt;T&gt; getRows() { return rows; } public void setRows(List&lt;T&gt; rows) { this.rows = rows; } public PageResult() { } public PageResult(long total, List&lt;T&gt; rows) { this.total = total; this.rows = rows; }} 问答模块主要业务主要包含两个个表问题表，回答表 问题表包含：问题id，问题标题，内容，发布日期，最新回复时间、最新回复人，发布人id，点赞数，是否解决 回答表包含：回答id，问题id，回答内容，回答日期，回答人id等 完成的主要业务有 1、最新回答列表：最新回复的问题显示在上方， 按回复时间降序排序 2、热门回答列表：按回复数降序排序 3、等待回答列表： 回复数为0按时间升序排序 在问题展示，会将每个问题的回复通过分页查询的形式返回给前端 招聘模块主要业务招聘微服务主要有两块：企业信息和招聘信息 企业表包含：id，name，summary，address，ishot等字段 招聘信息表包含：jobid，jobname，salary，企业id，发布日期，截止日期，状态（0表关闭，1表开启，2表推荐），关注人数等字段 完成的主要业务有 1、展示热门企业列表（通过findByIshot查询） 2、推荐职业列表（通过findTop4ByStateOrderByCreatetimeDesc：查询状态为2并以创建日期降序排序，查询前4条记录） 3、最新职位列表（findTop12ByStateNotOrderByCreatetimeDesc：查询状态不为0并以创建日期降序排序，查询前12条记录） 文章模块主要业务文章表包含：文章id，类别，用户id，文章标题，内容，发布日期，审核状态（0，1），点赞数，是否热门等 完成的主要业务有 1、管理员审核文章：状态改为1 2、用户对文章进行评论 3、通过springdataredis对热门文章缓存,可设置缓存时间 public Article findById(String id) { //先从缓存中查询当前对象 Article article= (Article) redisTemplate.opsForValue().get(\"article_\"+id); //如果没有渠道 if(article==null){ article = articleDao.findById(id).get(); //如果热门存入缓存 if(article.getIshot()==1){ redisTemplate.opsForValue().set(\"article_\"+id,article); } } return article;} 4、利用Elasticsearch和ik分词器完成文章的搜索功能，利用logstash同步mysql至elasticsearch //创建新的实体类，这里只需要一些必须的字段@Document(indexName = \"articleindex\",type = \"article\")public class Article implements Serializable { @Id private String id; //@Field注解作用 //是否能被搜索到 //是否分词，整体匹配还是分词匹配 //是否在页面上显示，即数据库中在该实体类中的字段，就是要显示的 //analyzer,分词 //searchAnalyzer，搜索 @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String title; @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String content; public String getId() { return id; } public void setId(String id) { this.id = id; } public String getTitle() { return title; } public void setTitle(String title) { this.title = title; } public String getContent() { return content; } public void setContent(String content) { this.content = content; }}//dao层public interface ArticleDao extends ElasticsearchRepository&lt;Article,String&gt; { public Page&lt;Article&gt; findByTitleOrContentLike(String title, String content, Pageable pageable);}//service层 public Page&lt;Article&gt; findByKey(String key, int page, int size) { Pageable pageable= PageRequest.of(page-1,size); return articleDao.findByTitleOrContentLike(key,key,pageable); }//controller层@RequestMapping(value = \"/{key}/{page}/{size}\",method = RequestMethod.GET) public Result findByKey(@PathVariable String key,@PathVariable int page,@PathVariable int size){ Page&lt;Article&gt;pageData=articleService.findByKey(key,page,size); return new Result(true,StatusCode.OK,\"搜索成功\",new PageResult&lt;Article&gt;(pageData.getTotalElements(),pageData.getContent())); } 吐槽模块吐槽表：_id，内容content，发布时间，用户id，点赞数，上级吐槽id 使用springdataMongoDB完成的主要业务有 1、发布吐槽，如果是在别人下面吐槽需要将上级吐槽回复数加1 if(spit.getParentid()!=null&amp;&amp;!\"\".equals(spit.getParentid())){//表示是在别人下面回复 Query query=new Query(); query.addCriteria(Criteria.where(\"_id\").is(spit.getParentid())); Update update=new Update(); update.inc(\"thumbup\",1); mongoTemplate.updateFirst(query,update,\"spit\");} 2、根据上级id查询吐槽列表 3、吐槽点赞，并通过redis使其不能重复点赞 //使用mongoDB原生方式实现自增public void thumbUp(String id){ //方式一,与数据库多次交互性能较低 //Spit spit=spitDao.findById(id).get(); //spit.setThumbup((spit.getThumbup()==null?0:spit.getThumbup())+1); //spitDao.save(spit); //相当于使用原生mongo命令实现自增：db.spit.update({\"_id\":\"1\"},{$inc:{thumbup:NumberInt(1)}}) Query query=new Query(); query.addCriteria(Criteria.where(\"_id\").is(\"id\")); Update update=new Update(); update.inc(\"thumbup\",1); mongoTemplate.updateFirst(query,update,\"spit\"); }@RequestMapping(value = \"/thumbup/{spitId}\",method = RequestMethod.PUT)public Result thumbUp(@PathVariable String spitId){ //由于没有做登陆认证，因此暂时写死ID，实现一个用户只能点赞一次 String userid=\"111\"; if(redisTemplate.opsForValue().get(\"thumbup_\"+userid)!=null){ return new Result(false,StatusCode.REPERROR,\"不能重复点赞\"); }; spitService.thumbUp(spitId); redisTemplate.opsForValue().set(\"thumbup_\"+userid,1); return new Result(true,StatusCode.OK,\"点赞成功\");} 管理员模块管理员登陆，JWT鉴权，在完成鉴权后通过feign可以操作其他模块的业务 1、在招聘模块对关注人数超过一定值的招聘信息可以设置为推荐，删除超过截止日期的招聘信息 2、手动设置热门企业 3、对用户进行管理 4、审核为通过审核文章，删除违规的文章 用户中心模块用户登陆，JWT鉴权，在完成鉴权后通过feign可以操作其他模块的业务 完成的主要业务有 1、用户注册：本地生成6位验证码，redis缓存一份，向rabbitmq发送一份，在处理短信的模块中，监听mq的短信队列拿到想换验证码和手机号，通过阿里云的短信API实现发送短信的功能（处理短信的模块是自动完成的，只需向mq发送相关信息即可） 2、用户登录：通过spring security的BCryptPasswordEncoder实现密码的加密解密，完成用户登录，登录成功通过JWT向用户发送token，以后请求服务需要在头信息中添加token信息 交友模块分为好友表和非好友表 好友表包含：用户id，朋友id，islike（0表单向喜欢，1表双向喜欢） 非好友表包含：用户id，朋友id 完成的业务： 1、当A点击喜欢B，好友表增加记录，非好友表删除A不喜欢B，当B喜欢A，修改islike为1 2、当A点击拉黑B，非好友表增加记录，好友表删除A-B的记录，若B喜欢A，则修改为单向喜欢 3、于此同时，A喜欢B，A的关注数加1，B的粉丝数加1 public int addFriend(String userid, String friendid) { //先判断userid到friendid是否有数据，有就是重复添加好友，返回0 Friend friend=friendDao.findByUseridAndFriendid(userid,friendid); if(friend!=null){ return 0; } //再判断以前是否不喜欢 if(noFriendDao.findByUseridAndFriendid(userid, friendid)!=null){ noFriendDao.deleteByUseridAndFriendid(userid,friendid); } //直接添加好友，让好友表中的userid到friendid方向的type为0 friend=new Friend(); friend.setUserid(userid); friend.setFriendid(friendid); friend.setIslike(\"0\"); friendDao.save(friend); //再判断friendid到userid是否有数据，如果有则把双方的状态都改为1 if(friendDao.findByUseridAndFriendid(friendid,userid)!=null){ //把双方islike都改为1 friendDao.updateIslike(\"1\",userid,friendid); friendDao.updateIslike(\"1\",friendid,userid); }; return 1;}public int addNoFriend(String userid,String friendid) { //先判断是否已经是非好友 NoFriend noFriend=noFriendDao.findByUseridAndFriendid(userid, friendid); if(noFriend!=null){ return 0; } //如果之前是好友，现在单方面删除 if(friendDao.findByUseridAndFriendid(userid,friendid)!=null){ friendDao.deleteByUseridAndFriendid(userid,friendid); if(friendDao.findByUseridAndFriendid(friendid,userid)!=null) friendDao.updateIslike(\"0\",friendid,userid); } //删完再添加到noFriend表 noFriend=new NoFriend(); noFriend.setUserid(userid); noFriend.setFriendid(friendid); noFriendDao.save(noFriend); return 1; } 完成项目的微服务化 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[]},{"title":"使用jekins完成项目部署于Docker容器","date":"2020-06-30T07:52:28.000Z","path":"2020/06/30/使用jekins完成项目部署/","text":"使用jekins完成项目部署于Docker容器创建Docker私有仓库创建私有仓库容器拉去镜像，创建容器docker pull registrydocker run ‐di ‐‐name=registry ‐p 5000:5000 registry 打开浏览器 输入地址http://192.168.xxx.xxx:5000/v2/_catalog 看到 {“repositories”:[]} 表示私有仓库搭建成功并且内容为空 修改daemon.json让docker信任私有仓库 vi /etc/docker/daemon.json{\"insecure‐registries\":[\"192.168.xxx.xxx:5000\"]} maven插件自动部署修改宿主机docker配置使其可以远程访问vi /lib/systemd/system/docker.service其中ExecStart=后添加配置 ‐H tcp://0.0.0.0:2375 ‐H unix:///var/run/docker.sock 发布的项目pom文件引入插件&lt;build&gt; &lt;finalName&gt;tensquare_config&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!--docker的maven插件，官网： https://github.com/spotify/docker‐maven‐plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;!--上传私有仓库--&gt; &lt;imageName&gt;192.168.152.xx:5000/${project.artifactId}:${project.version}&lt;/imageName&gt; &lt;!--基础镜像，意味着docker容器中已经存在jdk8的镜像--&gt; &lt;baseImage&gt;jdk8&lt;/baseImage&gt; &lt;!--打包命令--&gt; &lt;entryPoint&gt;[\"java\", \"-jar\", \"/${project.build.finalName}.jar\"]&lt;/entryPoint&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory} &lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;dockerHost&gt;http://192.168.152.xx:2375&lt;/dockerHost&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 进入该工程所在目录执行命令mvn clean package docker:build -DpushImage 代码管理服务gogs安装gogsdocker pull gogs/gogsdocker run -d --name=gogs -p 10022:22 -p 3000:3000 -v /var/gogsdata:/data gogs/gogs 配置gogs在地址栏输入http://192.168.xxx.xxx:3000 会进入首次运行安装程序页面，我们可以选择一种数据库作为gogs数据的存储，最简单的是选择SQLite3。如果对于规模较大的公司，可以选择MySQL 页面展示idea上传至gogs仓库 jekins持续继承配置jekins下载安装完后需要配置用户和端口号JENKINS_USER=\"root\"JENKINS_PORT=\"8888\" 首次进入，安装插件主要的插件有两个一个是maven一个是git 全局工具配置服务器安装maven，JDK JDK配置git配置（一般服务器都已经安装）maven配置持续继承创建一个maven项目 源码管理选gitURL填写gogs仓库的地址 Buildpom要填写生成容器的子项目 执行任务 结果展示docker镜像 私有仓库 运行后可以成功展示！ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"jekins","slug":"jekins","permalink":"https://xulilei.github.io/tags/jekins/"},{"name":"gogs","slug":"gogs","permalink":"https://xulilei.github.io/tags/gogs/"}]},{"title":"集中配置组件SpringCloudConfig","date":"2020-06-26T07:58:27.000Z","path":"2020/06/26/集中配置组件SpringCloudConfig/","text":"集中配置组件SpringCloudConfigSpring Cloud Config简介在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所 以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库 中。在spring cloud config 组件中，分两个角色，一是config server，二是config client。 config server它用于集中管理应用程序各个 环境下的配置，默认使用Git存储配置文件内容 导入config-server依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 启动类添加@EnableConfigServer@SpringBootApplication@EnableConfigServerpublic class ConfigApplication { public static void main(String[] args) { SpringApplication.run(ConfigApplication.class); }} 修改配置文件这里如果uri使用的是http，则会出现不能clone仓库内容的错误，因此要换成ssh，并添加private-key，该配置文件不需要上传至云端 server: port: 12000spring: application: name: tensquare-config rabbitmq: host: 192.168.152.** cloud: config: server: git: uri: git@gitee.com:***/tensquare.git ignore-local-ssh-settings: true private-key: | -----BEGIN RSA PRIVATE KEY----- MIIEowIBAAKCAQEAxawgOKaig29oj/OqSVY9njJMnIYmedq4A7wvKEpg3Q/wYRl0 DO1QOl13ilyj20MyXUEUKON4dKWoBl+2/zhTtyI5cCDhcnISYAp9JSkYSzm8DTDp E+1Zwmq2yYE68mr5/UaRbhOHBPGr1GwrTNuraqnOtNDjUXm25E4HiCmHoc395RpA -----END RSA PRIVATE KEY----- config clientConfig Client是Config Server的客户端，用于操作存储在Config Server中的配置内容。 微服务在启动时会请求Config Server获取配置文件的内容，请求到后再启动容器。 导入config client依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 上传配置文件application.yml至gitee文件命名规则： {application}-{profile}.yml或{application}-{profile}.properties 其中application为应用名称，profile指的开发环境（用于区分开发环境，测试环境、生产环境等） 更换配置文件为bootstrap.ymlspring: cloud: config: #这个对应gitee配置文件的命名规则 name: base profile: dev label: master uri: http://127.0.0.1:12000 消息总线组件SpringCloudBusSpringCloudBus简介当云端修改配置文件后，本地不用修改和再次编译，只需向消息中间件发送一条修改提醒即可使得配置文件即时生效 配置服务端config-server导入SpringCloudBus和rabbitmq依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-bus&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 修改配置文件spring: rabbitmq: host: 192.168.152.128#暴露触发消息总线的地址，management: endpoints: web: exposure: include: bus-refresh 配置客户端功能子模块导入依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-bus&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 云端配置文件添加rabbitmq地址rabbitmq: host: 192.168.184. document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"SpringCloudConfig","slug":"SpringCloudConfig","permalink":"https://xulilei.github.io/tags/SpringCloudConfig/"}]},{"title":"微服务网关Zuul","date":"2020-06-26T07:40:35.000Z","path":"2020/06/26/微服务网关Zuul/","text":"微服务网关Zuul相关概念为什么使用网关不同的微服务一般有不同的网络地址，而外部的客户端可能需要调用多个服务的接口才 能完成一个业务需求。 如果客户端直接和微服务进行通信，会存在一下问题： 1、客户端会多次请求不同微服务，增加客户端的复杂性 2、存在跨域请求，在一定场景下处理相对复杂 3、认证复杂，每一个服务都需要独立认证 上述问题，都可以借助微服务网关解决。微服务网关是介于客户端和服务器端之间的中间层，所有的外部请求都会先经过微服务网关。 什么是zuulZuul是Netflix开源的微服务网关，他可以和Eureka,Ribbon,Hystrix等组件配合使用。 Zuul组件的核心是一系列的过滤器，这些过滤器可以完成以下功能： 1、身份认证和安全: 识别每一个资源的验证要求，并拒绝那些不符的请求 2、动态路由：动态将请求路由到不同后端集群 Zuul使用网关模块导入相关依赖zuul是依赖eureka实现的，通过微服务的name在eureka的服务器上寻找到对应的路径 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt; 配置application,ymlserver: port: 9011spring: application: name: tensquare-managereureka: client: service-url: defaultZone: http://127.0.0.1:6868/eureka/ instance: prefer‐ip‐address: truezuul: routes: tensquare-base: path: /base/** serviceId: tensquare-base tensquare-user: path: /user/** serviceId: tensquare-user tensquare-qa: path: /qa/** serviceId: tensquare-qa 修改启动类@SpringBootApplication@EnableEurekaClient@EnableZuulProxypublic class ManagerApplication { public static void main(String[] args) { SpringApplication.run(ManagerApplication.class); } @Bean public JwtUtil jwtUtil(){ return new JwtUtil(); }} 实例：通过ZuulFilter实现身份验证功能创建Filter类继承ZuulFilter，并实现其中的方法，具体细节请看注释 @Componentpublic class ManagerFilter extends ZuulFilter { @Autowired private JwtUtil jwtUtil; //过滤器类型 //“pre”执行之前，“post”执行时 @Override public String filterType() { return \"pre\"; } //排序，0表示优先执行 @Override public int filterOrder() { return 0; } //表示当前过滤器是否开启，true为开启 @Override public boolean shouldFilter() { return true; } //过滤器内执行的操作，return任何object表示继续执行， //setSendZullResponse(false)表示不再继续执行 @Override public Object run() throws ZuulException { //通过com.netflix.zuul得到request上下文 RequestContext currentContext =RequestContext.getCurrentContext(); //得到request域 HttpServletRequest request = currentContext.getRequest(); // 第一次转发始终放行，因为是根据配置文件中的路径去找其他服务 if(request.getMethod().equals(\"OPTIONS\")){ return null; } //登陆放行 if(request.getRequestURI().indexOf(\"login\")&gt;0){ return null; } //得到头信息 String header = request.getHeader(\"Authorization\"); if(header!=null&amp;&amp;!\"\".equals(header)){ if(header.startsWith(\"Bearer \")){ String token=header.substring(7); try { Claims claims = jwtUtil.parseJWT(token); String role= (String) claims.get(\"roles\"); if(role.equals(\"admin\")){ //把头信息继续往下传 currentContext.addZuulRequestHeader(\"Authorization\",header); return null; } }catch (Exception e){ //终止运行 currentContext.setSendZuulResponse(false); } } } //header为空返回错误信息 currentContext.setSendZuulResponse(false); currentContext.setResponseStatusCode(403); return null; }} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"zuul","slug":"zuul","permalink":"https://xulilei.github.io/tags/zuul/"}]},{"title":"Hystrix入门","date":"2020-06-25T13:58:25.000Z","path":"2020/06/25/Hystrix“入门/","text":"Hystrix熔断器相关概念为什么要使用熔断器在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障， 进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。而熔断器的产生，则有效规避了雪崩效应 熔断器工作机制当服务的某个API接口的失败次数在一定时间内小于设定的阈值时，熔断器处于关闭状态，该API接口正常提供服务。当该API接口处理请求的失败次数大于设定的阈值时，Hystrix判定该API接口出现了故障，打开熔断器，这时该API接口会执行快速失败的逻辑，不执行业务逻辑，请求的线程不会处于阻塞状态。处于打开状态的熔断器在一定时间后会处于半打开状态，并将一定数量的请求执行正常逻辑，剩余的请求会执行快速失败。若执行正常逻辑的请求失败了，则熔断器继续打开，若成功了，则熔断器关闭。这样熔断器就具有了自我修复的功能。 使用配置文件开启hystrix支持Feign本身支持Hystrix，因此不需要导入额外依赖 feign: hystrix: enabled: true 创建实现feign接口的实现类在声明式接口中的@FeignClient注解上添加fallback属性来配置快速失败的处理类。该处理类作为Feign熔断器的逻辑处理类，必须实现被@FeignClient修饰的接口 @FeignClient(value = \"tensquare-base\",fallback = BaseClientImpl.class)public interface BaseClient { @RequestMapping(value = \"/label/{labelId}\",method = RequestMethod.GET) public Result findById(@PathVariable(\"labelId\") String labelId);}@Componentpublic class BaseClientImpl implements BaseClient { @Override public Result findById(String labelId) { return new Result(false, StatusCode.ERROR,\"失败\"); }} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"Hystrix","slug":"Hystrix","permalink":"https://xulilei.github.io/tags/Hystrix/"}]},{"title":"SpringCloud架构模型","date":"2020-06-25T13:54:19.000Z","path":"2020/06/25/cloud常见模块/","text":"Spring Cloud架构模型 服务发现组件EurekaEureka是Netflix开发的服务发现框架，SpringCloud将它集成在自己的子项目spring-cloud-netflix中，实现SpringCloud的服务发现功能。Eureka包含两个组件：Eureka Server和Eureka Client。 Eureka Server提供服务注册服务，各个节点启动后，会在Eureka Server中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到。 详见：https://xulilei.github.io/2020/06/21/eureka%E5%85%A5%E9%97%A8/ 服务间调用Feignfeign是声明式的web service客户端，它让微服务之间的调用变得更简单了，类似controller调用service。Spring Cloud集成了Ribbon和Eureka，可在使用Feign时提供负载均衡的http客户端 详见：https://xulilei.github.io/2020/06/21/eureka%E5%85%A5%E9%97%A8/ 熔断器Hystrix在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障， 进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。而熔断器的产生，则有效规避了雪崩效应 当服务的某个API接口的失败次数在一定时间内小于设定的阈值时，熔断器处于关闭状态，该API接口正常提供服务。当该API接口处理请求的失败次数大于设定的阈值时，Hystrix判定该API接口出现了故障，打开熔断器，这时该API接口会执行快速失败的逻辑，不执行业务逻辑，请求的线程不会处于阻塞状态。处于打开状态的熔断器在一定时间后会处于半打开状态，并将一定数量的请求执行正常逻辑，剩余的请求会执行快速失败。若执行正常逻辑的请求失败了，则熔断器继续打开，若成功了，则熔断器关闭。这样熔断器就具有了自我修复的功能。 详见：","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://xulilei.github.io/tags/SpringCloud/"}]},{"title":"daySeven-eureka","date":"2020-06-21T15:04:08.000Z","path":"2020/06/21/十次方daySeven/","text":"交友服务搭建主要业务添加喜欢业务逻辑有两张表分别为tb_friend和tb_nofriend，当A添加喜欢B，先在tb_friend表中查询有无数据，如果有则代表已经添加喜欢了，回复不可重复添加，然后在tb_nofriend中查询是否之前A不喜欢B，如果有记录，则删除该记录。并在tb_friend中添加一条从A-B的记录，且状态为0，代表单向喜欢。如果在添加记录时，恰哈发现B-A已经有数据了，那么则将二者的状态都改为1，代表双向喜欢 业务实现，service层public int addFriend(String userid, String friendid) { //先判断userid到friendid是否有数据，有就是重复添加好友，返回0 Friend friend=friendDao.findByUseridAndFriendid(userid,friendid); if(friend!=null){ return 0; } //再判断以前是否不喜欢 if(noFriendDao.findByUseridAndFriendid(userid, friendid)!=null){ noFriendDao.deleteByUseridAndFriendid(userid,friendid); } //直接添加好友，让好友表中的userid到friendid方向的type为0 friend=new Friend(); friend.setUserid(userid); friend.setFriendid(friendid); friend.setIslike(\"0\"); friendDao.save(friend); //再判断friendid到userid是否有数据，如果有则把双方的状态都改为1 if(friendDao.findByUseridAndFriendid(friendid,userid)!=null){ //把双方islike都改为1 friendDao.updateIslike(\"1\",userid,friendid); friendDao.updateIslike(\"1\",friendid,userid); }; return 1;} 添加不喜欢业务逻辑当A添加B为不喜欢，首先查询tb_nofriend中是否已经有数据，如果有则提示不可重复拉黑。然后再去tb_friend中查询是否有A-B的喜欢，如果有则删除该记录，同时查询B-A是否也有记录，有则代表之前是双向喜欢，此时应将B-A的状态改为0，最后在tb_nofriend中添加一行A-B数据。 业务实现，service层public int addNoFriend(String userid,String friendid) { //先判断是否已经是非好友 NoFriend noFriend=noFriendDao.findByUseridAndFriendid(userid, friendid); if(noFriend!=null){ return 0; } //如果之前是好友，现在单方面删除 if(friendDao.findByUseridAndFriendid(userid,friendid)!=null){ friendDao.deleteByUseridAndFriendid(userid,friendid); //如果之前双向喜欢，则改为单向喜欢 if(friendDao.findByUseridAndFriendid(friendid,userid)!=null) friendDao.updateIslike(\"0\",friendid,userid); } //删完再添加到noFriend表 noFriend=new NoFriend(); noFriend.setUserid(userid); noFriend.setFriendid(friendid); noFriendDao.save(noFriend); return 1;} 上述功能用到的Dao层FriendDaopublic interface FriendDao extends JpaRepository&lt;Friend,String&gt; { public Friend findByUseridAndFriendid(String userid,String friendid); @Modifying @Query(value =\"update tb_friend SET islike=? where userid=? and friendid=?\",nativeQuery = true) public void updateIslike(String islike,String userid,String friendid); public void deleteByUseridAndFriendid(String userid,String friendid);} NoFriendDaopublic interface NoFriendDao extends JpaRepository&lt;NoFriend,String&gt; { public NoFriend findByUseridAndFriendid(String userid, String friendid); public void deleteByUseridAndFriendid(String userid,String friendid);} feign调用user模块业务业务逻辑当A添加B为喜欢时，在tb_user表中，userA的关注数+1，B的粉丝数+1。当A添加B为不喜欢时，userA的关注数-1，B的粉丝数-1。 User模块中粉丝关注业务实现Dao层public interface UserDao extends JpaRepository&lt;User,String&gt;,JpaSpecificationExecutor&lt;User&gt;{ @Modifying @Query(value =\"update tb_user set fanscout=fanscount+? where id=?\" ,nativeQuery = true) public void updateFans(int x, String friendid); @Modifying @Query(value =\"update tb_user set followcount=followcount+? where id=?\" ,nativeQuery = true) public void updateFollows(int x, String userid);} Service层@Transactionalpublic void updateFansAndFollowCounts(int x, String userid, String friendid) { //friendB粉丝数+1，userA的关注数+1 userDao.updateFans(x,friendid); userDao.updateFollows(x,userid);} Controller层//不返回result是因为这个业务是服务之间的调用，不涉及前台@RequestMapping(value = \"/{userid}/{friendid}/x\",method = RequestMethod.PUT)public void updateFansAndFollowCounts(@PathVariable int x,@PathVariable String userid,@PathVariable String friendid){ userService.updateFansAndFollowCounts(x,userid,friendid);} 交友模块中调用上述业务启动类添加相应注解@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@EnableFeignClientspublic class FriendApplication { public static void main(String[] args) { SpringApplication.run(FriendApplication.class); }} 创建client@FeignClient(\"tensquare-user\")public interface UserClient { @RequestMapping(value = \"/user/{userid}/{friendid}/x\",method = RequestMethod.PUT) public void updateFansAndFollowCounts (@PathVariable(\"x\") int x, @PathVariable(\"userid\") String userid, @PathVariable(\"friendid\") String friendid);} controller层调用//添加喜欢if(flag==1){ userClient.updateFansAndFollowCounts(1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\");}//添加不喜欢if(flag==1){ userClient.updateFansAndFollowCounts(-1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\");} 交友服务controller层整合@RequestMapping(value = \"/like/{friendid}/{type}\",method = RequestMethod.PUT )public Result addFriend(@PathVariable String friendid,@PathVariable String type){ //验证是否登陆，并拿到ID Claims claims = (Claims) request.getAttribute(\"user_claims\"); if(claims==null){ return new Result(false, StatusCode.LOGINERROR,\"权限不足\"); } String userid = claims.getId(); System.out.println(userid); //判断是添加好友还是非好友，直接传进来一个类型type，当type为1时，表示添加，2时表示拉黑 if(type!=null){ if(type.equals(\"1\")){ int flag=friendService.addFriend(userid,friendid); if(flag==0){ return new Result(false, StatusCode.ERROR,\"不能重复添加好友\"); } if(flag==1){ //后文介绍的添加粉丝与关注 userClient.updateFansAndFollowCounts(1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\"); } //添加好友 }else if(type.equals(\"2\")) { //添加黑名单 int flag= friendService.addNoFriend(userid,friendid); if(flag==0){ return new Result(false, StatusCode.ERROR,\"不能重复拉黑好友\"); } if(flag==1){ //后文介绍的减少粉丝与关注 userClient.updateFansAndFollowCounts(-1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\"); } } } return new Result(false, StatusCode.ERROR,\"参数异常\");} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"Eureka","slug":"Eureka","permalink":"https://xulilei.github.io/tags/Eureka/"},{"name":"交友业务","slug":"交友业务","permalink":"https://xulilei.github.io/tags/%E4%BA%A4%E5%8F%8B%E4%B8%9A%E5%8A%A1/"}]},{"title":"eureka入门","date":"2020-06-21T07:50:02.000Z","path":"2020/06/21/eureka入门/","text":"服务发现组件Eureka相关概念Eureka简介Eureka是Netflix开发的服务发现框架，SpringCloud将它集成在自己的子项目spring-cloud-netflix中，实现SpringCloud的服务发现功能。Eureka包含两个组件：Eureka Server和Eureka Client。 Eureka ServerEureka Server提供服务注册服务，各个节点启动后，会在Eureka Server中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到。 服务端开发第一步，在父工程中锁定版本，每一个版本的springboot都对应一个版本的springcloud &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.M9&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 第二步，Eureka子模块添加eureka-server &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 第三步，添加application.yml server: port: 6868eureka: client: register-with-eureka: false #是否将自己注册到Eureka服务中，本身就是所有无需注册 fetch-registry: false service-url: #Eureka客户端与Eureka服务端进行交互的地址 defaultZone: http://127.0.0.1:${server.port}/eureka/ 第四步，启动类 @SpringBootApplication@EnableEurekaServerpublic class EurekaServer { public static void main(String[] args) { SpringApplication.run(EurekaServer.class); }} Eureka ClientEureka Client是一个java客户端，用于简化与Eureka Server的交互，客户端同时也 就别一个内置的、使用轮询(round-robin)负载算法的负载均衡器。 客户端开发第一步，客户端模块添加eureka-client &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 第二步，修改每个微服务的application.yml，添加注册eureka服务的配置 eureka: client: service-url: defaultZone: http://127.0.0.1:6868/eureka/ instance: prefer‐ip‐address: true #跨域 第三步，启动类 @SpringBootApplication@EnableEurekaClient public class UserApplication { public static void main(String[] args) { SpringApplication.run(UserApplication.class, args); }} Feign实现服务间的调用谁调用别人就在谁的模块中搭建环境第一步，添加openfeign依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 第二步，启动类@SpringBootApplication@EnableEurekaClient//Eureka客户端@EnableDiscoveryClient//可以发现服务@EnableFeignClients//通过feign调用其他服务的业务public class QaApplication { public static void main(String[] args) { SpringApplication.run(QaApplication.class, args); }} 第三步，创建client包，创建要调用目标的接口默认采用的是ribbon的轮询负载均衡算法 //调用目标的名字，注意这里不能使用下划线，这也是其他模块的application.yml中名字不加下划线的原因@FeignClient(\"tensquare-base\")//调用目标controller层的方法public interface BaseClient { @RequestMapping(value = \"/label/{labelId}\",method = RequestMethod.GET) //这里的 @PathVariable 后面要加上具体的参数名称(\"labelId\")不然会找不到 public Result findById(@PathVariable(\"labelId\") String labelId);} 相关实践详见：https://xulilei.github.io/2020/06/21/%E5%8D%81%E6%AC%A1%E6%96%B9daySeven/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"eureka","slug":"eureka","permalink":"https://xulilei.github.io/tags/eureka/"}]},{"title":"daySix-JWT-BCryptPasswordEncoder","date":"2020-06-18T02:27:02.000Z","path":"2020/06/18/十次方daySix/","text":"管理员登陆验证与删除鉴权 利用Spring Security的BCryptPasswordEncoder与JWT实现 登陆验证签发tokenservice层public Admin login(Admin admin) { //想根据用户名查询对象 Admin adminLogin=adminDao.findByLoginname(admin.getLoginname()); //然后拿数据库中的密码和用户输入的密码匹配是否相同 if(adminLogin!=null&amp;&amp;encoder.matches(admin.getPassword(),adminLogin.getPassword())){ return adminLogin; } //登陆失败 return null;} controller层@RequestMapping(value = \"/login\",method = RequestMethod.POST)public Result login(@RequestBody Admin admin){ Admin adminLoginResult=adminService.login(admin); if(adminLoginResult==null){ return new Result(false,StatusCode.LOGINERROR,\"登陆失败\"); } //做一系列前后端通话的工作，用JWT来实现 //生成token并返回给客户端 String token=jwtUtil.createJWT(adminLoginResult.getId(),adminLoginResult.getLoginname(),\"admin\"); Map&lt;String,Object&gt;map=new HashMap&lt;&gt;(); map.put(\"token\",token); map.put(\"role\",\"admin\"); return new Result(true,StatusCode.OK,\"登陆成功\",map);} 返回给前端的token 利用拦截器解析token拦截器只是为了将请求头中的token解析成user和admin解析后将气保存在域对象中，等需要鉴权时，直接通过获取这个域对象的值来分别是user还是admin @Componentpublic class JwtInterceptor implements HandlerInterceptor { @Autowired private JwtUtil jwtUtil; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //无论如何都放行，具体能不能操作要在具体的操作中去判断 //拦截器只是负责把请求头中包含的token令牌解析成user和admin String header=request.getHeader(\"Authorization\"); if(header!=null&amp;&amp;header.startsWith(\"Bearer \")){ String token=header.substring(7); try { Claims claims = jwtUtil.parseJWT(token); if(claims!=null){ if(\"admin\".equals(claims.get(\"roles\"))){ request.setAttribute(\"admin_claims\",token); } if(\"user\".equals(claims.get(\"roles\"))){ request.setAttribute(\"user_claims\",token); } } }catch (Exception e){ //过期 throw new RuntimeException(\"token错误\"); } } return true; }} 注册拦截器当然不用拦截登陆请求了 @Configurationpublic class InterceptorConfig extends WebMvcConfigurationSupport { @Autowired private JwtInterceptor jwtInterceptor; @Override protected void addInterceptors(InterceptorRegistry registry) { //注册拦截器要声明的拦截器对象和要拦截的请求 registry.addInterceptor(jwtInterceptor) .addPathPatterns(\"/**\") .excludePathPatterns(\"/**/login\"); }} 管理员删除用户直接从域对象中获取admin_claims，如果有则说明该登陆用户为管理员，则可以删除用户，否则提示权限不足 @Autowired private HttpServletRequest request;public void deleteById(String id) { String token = (String) request.getAttribute(\"admin_claims\"); if(token==null||\"\".equals(token)){ throw new RuntimeException(\"权限不足\"); } userDao.deleteById(id);} 当header中的token无法解析时 当header中的token正确时 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"Spring Security","slug":"Spring-Security","permalink":"https://xulilei.github.io/tags/Spring-Security/"},{"name":"BCryptPasswordEncoder","slug":"BCryptPasswordEncoder","permalink":"https://xulilei.github.io/tags/BCryptPasswordEncoder/"},{"name":"JWT","slug":"JWT","permalink":"https://xulilei.github.io/tags/JWT/"},{"name":"鉴权","slug":"鉴权","permalink":"https://xulilei.github.io/tags/%E9%89%B4%E6%9D%83/"},{"name":"密码加密","slug":"密码加密","permalink":"https://xulilei.github.io/tags/%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86/"}]},{"title":"Spring Security加密与JWT鉴权","date":"2020-06-18T02:26:39.000Z","path":"2020/06/18/SpringSecurity加密与JWT鉴权/","text":"SpringSecurity加密与JWT鉴权Spring Security的BCryptPasswordEncoder使用过程引入依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置类如果只是使用BCryptPasswordEncoder，这个配置可以直接拿来用 @Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter{ @Override protected void configure(HttpSecurity http) throws Exception { //authorizeRequests是所有security全注解配置实现的开端 //需要的权限分两部分，第一部分是拦截的路径，第二部分是访问该路径需要的权限 //antMatchers，表示拦截的路径，permitAll表示任何权限都可以访问，直接放行所有 //这里主要是用security的加密功能，拦截功能用的是jwt //anyRequest()任何的请求，authenticated()认证后访问 //and().csrf().disable()表示使csrf攻击失效 http .authorizeRequests() .antMatchers(\"/**\").permitAll() .anyRequest().authenticated() .and().csrf().disable(); }} 配置BCryptPasswordEncoder交给容器@Beanpublic BCryptPasswordEncoder bCryptPasswordEncoder(){ return new BCryptPasswordEncoder();} 密码加密service层 public void add(User user) { user.setId( idWorker.nextId()+\"\" ); //密码加密 user.setPassword(encoder.encode(user.getPassword())); userDao.save(user);} 密码验证service层 public User login(String mobile,String password) { //先通过前台传过来的电话查询出user User user=userDao.findByMobile(mobile); //再比对user的密码，用encoder.match(原密码,加密后的密码) if(user!=null&amp;&amp;encoder.matches(password,user.getPassword())){ return user; } return null;} JWT鉴权常见的鉴权方式Cookie认证Cookie认证机制就是为一次请求认证在服务端创建一个Session对象，同时在客户端 的浏览器端创建了一个Cookie对象；通过客户端带上来Cookie对象来与服务器端的 session对象匹配来实现状态管理的。 Token认证使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是 这样的： 客户端使用用户名跟密码请求登录 服务端收到请求，去验证用户名与密码 验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端 客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里 客户端每次向服务端请求资源的时候需要带着服务端签发的 Token 服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向 客户端返回请求的数据 两者对比Token的优势 支持跨域访问: Cookie是不允许垮域访问的，这一点对Token机制是不存在的，前提 是传输的用户认证信息通过HTTP头传输. 无状态:Token机制在服务端不需要存储session信息，因为 Token 自身包含了所有登录用户的信息，只需要在客户端的cookie或本地介质存储状态信息. 去耦: 不需要绑定到一个特定的身份验证方案。Token可以在任何地方生成，只要在 你的API被调用的时候，你可以进行Token生成调用即可. 一次网络往返时间（通过数据库查询session信息）总比做一次HMACSHA256计算的Token验证和解析要费时得多. 基于标准化:你的API可以采用标准化的 JSON Web Token (JWT) JWT介绍一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名，且生成后都会采用base64进行编码。 头部（Header）头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。这也可以 被表示成一个JSON对象，如下指明了采用了JWT的算法为HS256 {\"typ\":\"JWT\",\"alg\":\"HS256\"} base64编码后：eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 载荷（playload）一般包含ID，用户SUB，身份roles，比如 {\"id\":\"1234567890\",\"sub\":\"John Doe\",\"roles\":\"admin\"} 会再次进行base64编码 签证（signature）包含头部，载荷，以及定义的salt，同样进行base编码 最终JWT会将三部分连接成一个字符串，以.连接 eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6I kpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ JJWT：Java JWT添加依赖&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.6.0&lt;/version&gt;&lt;/dependency&gt; 在common包下的util包中创建JWT工具类这个工具类，需要提供ID,SUB,ROLE作为claims @ConfigurationProperties(\"jwt.config\")public class JwtUtil { private String key ; private long ttl ;//一个小时 public String getKey() { return key; } public void setKey(String key) { this.key = key; } public long getTtl() { return ttl; } public void setTtl(long ttl) { this.ttl = ttl; } /** * 生成JWT * @param id * @param subject * @return */ public String createJWT(String id, String subject, String roles) { long nowMillis = System.currentTimeMillis(); Date now = new Date(nowMillis); JwtBuilder builder = Jwts.builder().setId(id) .setSubject(subject) .setIssuedAt(now) .signWith(SignatureAlgorithm.HS256, key).claim(\"roles\", roles); if (ttl &gt; 0) { builder.setExpiration( new Date( nowMillis + ttl)); } return builder.compact(); } /** * 解析JWT * @param jwtStr * @return */ public Claims parseJWT(String jwtStr){ return Jwts.parser() .setSigningKey(key) .parseClaimsJws(jwtStr) .getBody(); }} jwt.config哪里用到了这个工具类，哪里的application.yml添加jwt定义，哪里传入jwtUtil @Bean public JwtUtil jwtUtil(){ return new util.JwtUtil(); } jwt: config: key: itcast ttl: 360000 以admin的登陆与删除鉴权为例详见：https://xulilei.github.io/2020/06/18/%E5%8D%81%E6%AC%A1%E6%96%B9daySix/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"https://xulilei.github.io/tags/Spring-Security/"},{"name":"BCryptPasswordEncoder","slug":"BCryptPasswordEncoder","permalink":"https://xulilei.github.io/tags/BCryptPasswordEncoder/"},{"name":"JWT","slug":"JWT","permalink":"https://xulilei.github.io/tags/JWT/"},{"name":"鉴权","slug":"鉴权","permalink":"https://xulilei.github.io/tags/%E9%89%B4%E6%9D%83/"},{"name":"密码加密","slug":"密码加密","permalink":"https://xulilei.github.io/tags/%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86/"}]},{"title":"dayFive-rabbitmq","date":"2020-06-15T10:53:31.000Z","path":"2020/06/15/十次方dayFive/","text":"用户注册模块搭建在user模块添加发送短信业务service层public void sendMsg(String mobile) { //生成六位随机数 String checkCode = RandomStringUtils.randomNumeric(6); //向缓存中放一份 redisTemplate.opsForValue().set(\"checkCode\"+mobile,checkCode,6, TimeUnit.HOURS); //给用户发一份，先存放至rabbitmq中 Map&lt;String,String&gt;map=new HashMap&lt;&gt;(); map.put(\"mobile\",mobile); map.put(\"checkCode\",checkCode); rabbitTemplate.convertAndSend(\"sms\",map);} controller层@RequestMapping(value =\"/sendsms/{mobile}\",method = RequestMethod.POST)public Result sendMsg(@PathVariable String mobile){ userService.sendMsg(mobile); return new Result(true,StatusCode.OK,\"发送成功\");} 在rabbitmq短信监听模块通过阿里云实施发送短信导入阿里云依赖&lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;4.5.0&lt;/version&gt;&lt;/dependency&gt; 根据阿里云官网API创建工具类@Componentpublic class SmsUtil { private static final String accessKeyId=\"LTAI4GCjWSbTHQzGTaavF**\"; private static final String accessKeySecret=\"sDiW0PSXaAKXfNfwCI8vaG4spE4**\"; private static final String signName=\"******\"; private static final String templateCode=\"SMS_1932477**\"; public void sendSms(String mobile,String checkCode) { DefaultProfile profile = DefaultProfile.getProfile(\"default\", accessKeyId, accessKeySecret); IAcsClient client = new DefaultAcsClient(profile); CommonRequest request = new CommonRequest(); request.setSysMethod(MethodType.POST); request.setSysDomain(\"dysmsapi.aliyuncs.com\"); request.setSysVersion(\"2017-05-25\"); request.setSysAction(\"SendSms\"); request.putQueryParameter(\"PhoneNumbers\", mobile); request.putQueryParameter(\"SignName\", signName); request.putQueryParameter(\"TemplateCode\", templateCode); //这里使用通配符，code要与在阿里云注册的模版相同 request.putQueryParameter(\"TemplateParam\", \"{\\\"code\\\":\"+checkCode+\"}\"); try { CommonResponse response = client.getCommonResponse(request); System.out.println(response.getData()); } catch (ServerException e) { e.printStackTrace(); } catch (ClientException e) { e.printStackTrace(); } }} 创建rabbitmq监听器类@Component@RabbitListener(queues = \"sms\")public class SmsListener { @Autowired private SmsUtil smsUtil; @RabbitHandler public void executeSms(Map&lt;String,String&gt; map){ String mobile = map.get(\"mobile\"); String checkCode = map.get(\"checkCode\"); smsUtil.sendSms(mobile,checkCode); }} 自此短信功能部署成功 用户注册业务@RequestMapping(value =\"/register/{code}\",method = RequestMethod.POST)public Result register(@PathVariable String code,@RequestBody User user){ //先从缓存中拿到先前发送短信时存放的数据 String checkCodeRedis= (String) redisTemplate.opsForValue().get(\"checkCode\"+user.getMobile()); //比对数据 if(checkCodeRedis.isEmpty()){ return new Result(false,StatusCode.ERROR,\"未发送验证码\"); } if(!checkCodeRedis.equals(code)){ return new Result(false,StatusCode.ERROR,\"验证码错误\"); } //比对成功，注册用户 userService.add(user); return new Result(true,StatusCode.OK,\"注册成功\");} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://xulilei.github.io/tags/rabbitmq/"},{"name":"短信验证","slug":"短信验证","permalink":"https://xulilei.github.io/tags/%E7%9F%AD%E4%BF%A1%E9%AA%8C%E8%AF%81/"},{"name":"用户注册","slug":"用户注册","permalink":"https://xulilei.github.io/tags/%E7%94%A8%E6%88%B7%E6%B3%A8%E5%86%8C/"}]},{"title":"RabbitMQ入门","date":"2020-06-15T10:53:09.000Z","path":"2020/06/15/RabbitMQ/","text":"消息中间件RabbitMQRabbitMQ简介消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋和消息通讯等问题，实现高性能，高可用，可伸缩和最终一致性的架构 架构图通过交换机再进入到队列中 主要概念RabbitMQ Server也叫broker server，它是一种传输服务。 他的角色就是维护一条 从Producer到Consumer的路线，保证数据能够按照指定的方式进行传输。 Producer消息生产者，如图A、B、C，数据的发送方。消息生产者连接RabbitMQ服 务器然后将消息投递到Exchange。 Consumer消息消费者，如图1、2、3，数据的接收方。消息消费者订阅队列， RabbitMQ将Queue中的消息发送到消息消费者。 Exchange生产者将消息发送到Exchange（交换器），由Exchange将消息路由到一个 或多个Queue中（或者丢弃）。Exchange并不存储消息。RabbitMQ中的Exchange有 direct、fanout、topic、headers四种类型，每种类型对应不同的路由规则。 Queue队列是RabbitMQ的内部对象，用于存储消息。消息消费者就是通过订阅 队列来获取消息的，RabbitMQ中的消息都只能存储在Queue中，生产者生产消息并最终 投递到Queue中，消费者可以从Queue中获取消息并消费。多个消费者可以订阅同一个 Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者 都收到所有的消息并处理。 RoutingKey生产者在将消息发送给Exchange的时候，一般会指定一个routing key， 来指定这个消息的路由规则，而这个routing key需要与Exchange Type及binding key联 合使用才能最终生效。在Exchange Type与binding key固定的情况下（在正常使用时一 般这些内容都是固定配置好的），我们的生产者就可以在发送消息给Exchange时，通过 指定routing key来决定消息流向哪里。 Docker安装需要注意的是要配置多个接口 docker run ‐di ‐‐name=tensquare_rabbitmq ‐p 5671:5617 ‐p 5672:5672 ‐p 4369:4369 ‐p 15671:15671 ‐p 15672:15672 ‐p 25672:25672 rabbitmq:management 主要知识点Exchange类型direct模式 1、将消息发给唯一一个节点时使用这种模式，这是最简单的一种形式 2、这种模式下不需要将Exchange进行任何绑定(binding)操作 3、消息传递时需要一个“RouteKey”，可以简单的理解为要发送到的队列名字 首先创建一个test队列 以direct模式发送 @RunWith(SpringRunner.class)@SpringBootTest(classes = RabApplication.class)public class ProductTest { @Autowired private RabbitTemplate rabbitTemplate; @Test public void sendMsg(){ //这里的test就是queue的名字 rabbitTemplate.convertAndSend(\"test\",\"测试直接模式\"); }} 创建消费者接受 @Component@RabbitListener(queues = \"test\")public class Customer { @RabbitHandler public void getMsg(String msg){ System.out.println(\"直接模式消费消息\"+msg); }} 运行结果 该模式下，默认采用了负载均衡，即消费者从队列获取消息是均衡的 分列模式 任何发送到Fanout Exchange的消息都会被转发到与该Exchange绑定(Binding)的所有 Queue上。 1、这种模式不需要RouteKey 2、这种模式需要提前将Exchange与Queue进行绑定，一个Exchange可以绑定多个 Queue，一个Queue可以同多个Exchange进行绑定。 3、如果接受到消息的Exchange没有与任何Queue绑定，则消息会被抛弃。+ 主题模式 任何发送到Topic Exchange的消息都会被转发到所有关心RouteKey中指定话题的 Queue上 1、这种模式较为复杂，简单来说，就是每个队列都有其关心的主题，所有的消息都带有一 个“标题”(RouteKey)，Exchange会将消息转发到所有关注主题能与RouteKey模糊匹配的 队列。 2、这种模式需要RouteKey，也许要提前绑定Exchange与Queue。 3、在进行绑定时，要提供一个该队列关心的主题，如“#.log.#”表示该队列关心所有涉及 log的消息(一个RouteKey为”MQ.log.error”的消息会被转发到该队列)。 4、“#”表示0个或若干个关键字，“”表示一个关键字。如“log.”能与“log.warn”匹配，无法 与“log.warn.timeout”匹配；但是“log.#”能与上述两者匹配。 5、同样，如果Exchange没有发现能够与RouteKey匹配的Queue，则会抛弃此消息 配合阿里云实现发送短信功能详见 https://xulilei.github.io/2020/06/15/%E5%8D%81%E6%AC%A1%E6%96%B9dayFive/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://xulilei.github.io/tags/rabbitmq/"},{"name":"短信验证","slug":"短信验证","permalink":"https://xulilei.github.io/tags/%E7%9F%AD%E4%BF%A1%E9%AA%8C%E8%AF%81/"}]},{"title":"DayFour-elasticsearch","date":"2020-06-14T10:34:44.000Z","path":"2020/06/14/十次方DayFour/","text":"搜索微服务搭建使用spring-data-elasticsearch操作导入依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-elasticsearch&lt;/artifactId&gt;&lt;/dependency&gt; Pojo实体类@Document(indexName = \"articleindex\",type = \"article\")public class Article implements Serializable { @Id private String id; //是否能被搜索到 //是否分词，整体匹配还是分词匹配 //是否在页面上显示，即数据库中在该实体类中的字段，就是要显示的,比如该例中的id title content state //analyzer,分词 //searchAnalyzer，搜索 @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String title; @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String content; private String state;} Dao层public interface ArticleDao extends ElasticsearchRepository&lt;Article,String&gt; { public Page&lt;Article&gt; findByTitleOrContentLike(String title, String content, Pageable pageable);} Service层@Servicepublic class ArticleService { @Autowired private ArticleDao articleDao; @Autowired private IdWorker idWorker; public void save(Article article){ articleDao.save(article); } //springdata系列分页的写法都是这个 public Page&lt;Article&gt; findByKey(String key, int page, int size) { Pageable pageable= PageRequest.of(page-1,size); return articleDao.findByTitleOrContentLike(key,key,pageable); }} controller层@RestController@RequestMapping(\"/article\")@CrossOriginpublic class ArticleController { @Autowired private ArticleService articleService; @RequestMapping(method = RequestMethod.POST) public Result save(@RequestBody Article article){ articleService.save(article); return new Result(true, StatusCode.OK,\"存储成功\"); } @RequestMapping(value = \"/{key}/{page}/{size}\",method = RequestMethod.GET) public Result findByKey(@PathVariable String key,@PathVariable int page,@PathVariable int size){ Page&lt;Article&gt;pageData=articleService.findByKey(key,page,size); return new Result(true,StatusCode.OK,\"搜索成功\",new PageResult&lt;Article&gt;(pageData.getTotalElements(),pageData.getContent())); }} docker部署elasticsearchhttps://xulilei.github.io/2020/06/12/elasticSearch%E5%85%A5%E9%97%A8/ 连接服务器，并测试存储到服务器的索引库application.yml配置server: port: 9007spring: application: name: tensquare-search data: elasticsearch: cluster-nodes: 192.168.152.128:9300 postMan测试成功 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://xulilei.github.io/tags/elasticsearch/"},{"name":"搜索功能","slug":"搜索功能","permalink":"https://xulilei.github.io/tags/%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD/"}]},{"title":"ElasticSearch从认识到发布","date":"2020-06-12T07:54:05.000Z","path":"2020/06/12/elasticSearch入门/","text":"分布式搜索引擎ElasticSearch概念与mysql数据库对比 Elasticsearch 关系型数据库Mysql 索引(index) 数据库(databases) 类型(type) 表(table) 文档(document) 行(row) restful风格操作ElasticSearch新建索引如果需要创建一个叫articleindex的索引 ,就以put方式提交 http://127.0.0.1:9200/articleindex/ 新建文档新建类型，在索引后追加类型： 以post方式提交 http://127.0.0.1:9200/articleindex/article 查询文档查询全部_search，以get方式请求 http://127.0.0.1:9200/articleindex/article/_search 按ID查询以GET方式请求 http://127.0.0.1:9200/articleindex/article/1 匹配查询根据title=aa进行查询，get方式提交下列地址： http://127.0.0.1:9200/articleindex/article/_search?q=title:aa 模糊查询以*用代表任意字符： http://192.168.184.134:9200/articleindex/article/_search?q=title:*s* 修改以put形式提交以下地址,如果ID存在则修改，否则添加 http://127.0.0.1:9200/articleindex/article/1 删除文档根据ID删除文档,删除ID为1的文档 DELETE方式提交 http://192.168.184.134:9200/articleindex/article/1 head插件操作ElasticSearch安装步骤步骤1： 下载head插件：https://github.com/mobz/elasticsearch-head 步骤2： 将grunt安装为全局命令npm install ‐g grunt‐cli 步骤3：解决跨域问题修改elasticsearch配置文件：elasticsearch.yml，增加以下两句命令： http.cors.enabled: true http.cors.allow‐origin: \"*\" 步骤4： 安装依赖并启动cnpm installgrunt server 图形化界面 Logstash概念Logstash是一款轻量级的日志搜集处理框架，可以方便的把分散的、多样化的日志搜集 起来，并进行自定义的处理，然后传输到指定的位置，比如某个服务器或者文件。 基本用法命令行参数: -e ：执行（很少用） -f：路径，后跟参数类型可以是一个字符串的配置或全路径文件名或全路径 如：/etc/logstash.d/，logstash会自动读取/etc/logstash.d/目录下所有*.conf 的文 本文件，然后在自己内存里拼接成一个完整的大配置文件再去执行 使用Logstash将数据库的内容同步到索引库模版，用到时直接填写input { jdbc { # mysql jdbc connection string to our backup databse jdbc_connection_string =&gt; \"jdbc:mysql://192.168.xx.xx:3306/aaaaa?characterEncoding=UTF8\" # the user we wish to excute our statement as jdbc_user =&gt; \"root\" jdbc_password =&gt; \"root\" # the path to our downloaded jdbc driver jdbc_driver_library =&gt; \"C:\\Users\\xu\\Desktop\\tensquare\\logstash-5.6.8\\mysqletc\\mysql-connector-java-5.1.46.jar\" # the name of the driver class for mysql jdbc_driver_class =&gt; \"com.mysql.jdbc.Driver\" jdbc_paging_enabled =&gt; \"true\" jdbc_page_size =&gt; \"50\" #以下对应着要执行的sql的绝对路径。 #statement_filepath =&gt; \"\" #这个是要直接执行的sql语句 statement =&gt; \"\"select id,title,content,state from tb_article\" #定时字段 各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新（测试结果，不同的话请留言指出） schedule =&gt; \"* * * * *\" }}output { elasticsearch { #ESIP地址与端口 hosts =&gt; \"127.0.0.1:9200\" #ES索引名称（自己定义的） index =&gt; \"articleindex\" #自增ID编号 document_id =&gt; \"%{id}\" document_type =&gt; \"article\" } stdout { #以JSON格式输出 codec =&gt; json_lines }} 再通过一下命令执行该文件logstash ‐f ../mysqletc/mysql.conf 结果返回{\"@version\":\"1\",\"id\":\"1\",\"state\":\"1\",\"@timestamp\":\"2020-06-15T03:35:00.106Z\",\"title\":\"xu测试\",\"content\":\"测试\"}{\"@version\":\"1\",\"id\":\"1\",\"state\":\"1\",\"@timestamp\":\"2020-06-15T03:34:01.671Z\",\"title\":\"xu测试\",\"content\":\"测试\"} 注意事项删除数据库中的文件并不会导致索引库中的数据删除，可以约定一个state，当需要删除的时候更改state的值，在索引库中，查询约定state的值即可实现 docker安装ES安装ES容器第一步，安装容器docker run ‐di ‐‐name=tensquare_elasticsearch ‐p 9200:9200 ‐p 9300:9300 elasticsearch:5.6.8 第二步，允许其他ip地址访问#进入elasticsearch容器的目录docker exec ‐it tensquare_elasticsearch /bin/bash#拷贝容器中的配置文件到宿主机docker cp tensquare_elasticsearch:/usr/share/elasticsearch/config/elasticsearch.yml /usr/share/elasticsearch.yml#停止删除原来的容器docker stop tensquare_elasticsearch docker rm tensquare_elasticsearch#重新安装容器，并挂载配置文件为/usr/share/elasticsearch.ymldocker run ‐di ‐‐name=tensquare_elasticsearch ‐p 9200:9200 ‐p 9300:9300 ‐v /usr/share/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch .yml elasticsearch:5.6.8#修改/usr/share/elasticsearch.yml 将#transport.host:0.0.0.0前的#去掉后保存文件退出。其作用是允许任何ip地址访问elasticsearch，并指定可以跨域transport.host:0.0.0.0http.cors.enabled: true http.cors.allow‐origin: \"*\"#重启容器docker restart tensquare_elasticsearch 第三部，如果遇到容器启动自动关闭，则需要优化配置(每个机器不同优化也不同)可以参考 https://blog.csdn.net/qq_34756221/article/details/105550037 https://www.cnblogs.com/jasonzeng/p/11584754.html 安装ik分词器先通过xftp将ik分词文件传送至服务器，再拷贝至es容器目录的plugins中 docker cp ik tensquare_elasticsearch:/usr/share/elasticsearch/plugins/ 安装headerdocker run ‐di ‐‐name=myhead ‐p 9100:9100 docker pull mobz/elasticsearch‐ head:5 成功页面展示head插件展示 ik分词器展示 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://xulilei.github.io/tags/ElasticSearch/"},{"name":"Logstash","slug":"Logstash","permalink":"https://xulilei.github.io/tags/Logstash/"},{"name":"ik分词器","slug":"ik分词器","permalink":"https://xulilei.github.io/tags/ik%E5%88%86%E8%AF%8D%E5%99%A8/"},{"name":"docker","slug":"docker","permalink":"https://xulilei.github.io/tags/docker/"}]},{"title":"DayThree-mongoDB","date":"2020-06-09T08:25:22.000Z","path":"2020/06/09/十次方项目第三天/","text":"Day03什么是MongoDB​ MongoDB 是一个跨平台的，面向文档的数据库，是当前 NoSQL 数据库产品中最热 门 的一种。它介于关系数据库和非关系数据库之间，是非关系数据库当中功能最丰富，最像关系数据库的产品。它支持的数据结构非常松散，是类似 JSON 的 BSON 格式，因此可以存储比较复杂的数据类型。 MongoDB适用场景​ 适用于场景数据量大，数据价值相对低的情况 MongoDB体系结构（1）MongoDB 的文档（document），相当于关系数据库中的一行记录。 （2）多个文档组成一个集合（collection），相当于关系数据库的表。 （3）多个集合（collection），逻辑上组织在一起，就是数据库（database）。 服务器创建Docker MongoDB容器[root@pinyoyougou-docker ~]# docker run -di --name=tensquare_mongo -p 27017:27017 mongo MongoDB语法创建表use 数据库名称//如果不存在则自动创建 插入数据db.集合名称.insert(数据);//插入文档的语法格式比如db.spit.insert({content:\"听说十次方课程很给力呀\",userid:\"1011\",nickname:\"小雅\",visits:NumberInt(902)}) 查询数据db.集合名称.find()//查询所有db.spit.find().limit(3)//限定返回3条db.spit.find({userid:'1013'})//查询userid=1013的文档 修改与删除数据db.集合名称.update(条件,修改后的数据)//如果我们想修改_id为1的记录，浏览量为1000，输入以下语句：db.spit.update({_id:\"1\"},{visits:NumberInt(1000)})执行后，我们会发现，这条文档除了visits字段其它字段都不见了，为了解决这个问题，我们需要使用修改器$set来实现，命令如下：db.spit.update({_id:\"2\"},{$set:{visits:NumberInt(2000)}})//删除指定文档db.集合名称.remove(条件) 模糊查询MongoDB的模糊查询是通过正则表达式的方式实现的格式为：db.集合名称.find({content:/aaa/})例如，我要查询吐槽内容包含“流量”的所有文档，代码如下：db.spit.find({content:/流量/})如果要查询吐槽内容中以“加班”开头的，代码如下：db.spit.find({content:/^加班/}) 大于 小于 不等于db.集合名称.find({ \"field\" : { $gt: value }}) // 大于: field &gt; valuedb.集合名称.find({ \"field\" : { $lt: value }}) // 小于: field &lt; valuedb.集合名称.find({ \"field\" : { $gte: value }}) // 大于等于: field &gt;= valuedb.集合名称.find({ \"field\" : { $lte: value }}) // 小于等于: field &lt;= valuedb.集合名称.find({ \"field\" : { $ne: value }}) // 不等于: field != value 包含与不包含包含使用$in操作符。示例：查询吐槽集合中userid字段包含1013和1014的文档db.spit.find({userid:{$in:[\"1013\",\"1014\"]}})不包含使用$nin操作符。示例：查询吐槽集合中userid字段不包含1013和1014的文档db.spit.find({userid:{$nin:[\"1013\",\"1014\"]}}) 条件连接我们如果需要查询同时满足两个以上条件，需要使用$and操作符将条件进行关联。（相当于SQL的and）格式为：$and:[{ },{ },{ }]示例：查询吐槽集合中visits大于等于1000 并且小于2000的文档db.spit.find({$and:[ {visits:{$gte:1000}} ,{visits:{$lt:2000}}]})如果两个以上条件之间是或者的关系，我们使用 操作符进行关联，与前面and的使用方式相同格式为：$or:[{ },{ },{ }]示例：查询吐槽集合中userid为1013，或者浏览量小于2000的文档记录db.spit.find({$or:[ {userid:\"1013\"} ,{visits:{$lt:2000} }]}) 列值增长如果我们想实现对某列值在原有值的基础上进行增加或减少，可以使用$inc运算符来实现db.spit.update({_id:\"2\"},{$inc:{visits:NumberInt(1)}}) JAVA操作MongoDBpublic class MongoDemo { public static void main(String[] args) { MongoClient client=new MongoClient(\"192.168.184.134\");//创建连接 MongoDatabase spitdb = client.getDatabase(\"spitdb\");//打开数据库 MongoCollection&lt;Document&gt; spit = spitdb.getCollection(\"spit\");//获取集合 //条件查询 //BasicDBObject bson=new BasicDBObject(\"userid\",\"1013\");// 构建查询条件 //BasicDBObject bson=new BasicDBObject(\"visits\",newBasicDBObject(\"$gt\",1000) ); //FindIterable&lt;Document&gt; documents = spit.find(bson);//查询记录获取结果集合 FindIterable&lt;Document&gt; documents = spit.find();//查询记录获取文档集合 for(Document document:documents){ // System.out.println(\"内容：\"+ document.getString(\"content\")); System.out.println(\"用户ID:\"+document.getString(\"userid\")); System.out.println(\"浏览量：\"+document.getInteger(\"visits\")); } //插入数据 Map&lt;String,Object&gt; map=new HashMap(); map.put(\"content\",\"我要吐槽\"); map.put(\"userid\",\"9999\"); map.put(\"visits\",123); map.put(\"publishtime\",new Date()); Document document=new Document(map); spit.insertOne(document); client.close();//关闭连接 }} SpringDataMongoDB增删改查与SpringDataJPA几乎一样，详细用法参考https://xulilei.github.io/2020/06/08/%E5%8D%81%E6%AC%A1%E6%96%B9%E9%A1%B9%E7%9B%AEDay2/ 通过MongoTemplate原生方式实现数据自增public void thumbUp(String id){ //方式一,与数据库多次交互性能较低 Spit spit=spitDao.findById(id).get(); spit.setThumbup((spit.getThumbup()==null?0:spit.getThumbup())+1); spitDao.save(spit); //相当于使用原生mongo命令实现自增：db.spit.update({\"_id\":\"1\"},{$inc:{thumbup:NumberInt(1)}}) Query query=new Query(); query.addCriteria(Criteria.where(\"_id\").is(\"id\")); Update update=new Update(); update.inc(\"thumbup\",1); mongoTemplate.updateFirst(query,update,\"spit\"); } document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://xulilei.github.io/tags/MongoDB/"},{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"DayTwo-SpringDataJpa","date":"2020-06-08T07:23:13.000Z","path":"2020/06/08/十次方项目Day2/","text":"SpringDataJpa通过new Specification实现条件查询//service层public List&lt;Label&gt; findSearch(Label label) { return labelDao.findAll(new Specification&lt;Label&gt;() { /** * 采用内部类，方式实现 * @param root 根对象，也就是说要把条件封装到哪个对象中去 * @param query 查询关键字，比如groupBy，orderBy等 * @param cb 用来封装条件对象的 * @return 如果返回null，则代表不需要任何条件 */ @Override public Predicate toPredicate(Root&lt;Label&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; list=new ArrayList&lt;&gt;(); //相当于 where labelname like \"%小明%\" if(label.getLabelname()!=null&amp;&amp;!\"\".equals(label.getLabelname())){ Predicate predicate = cb.like(root.get(\"labelname\").as(String.class), \"%\" + label.getLabelname() + \"%\"); list.add(predicate); } if(label.getState()!=null&amp;&amp;!\"\".equals(label.getState())){ Predicate predicate = cb.equal(root.get(\"state\").as(String.class), label.getState()); list.add(predicate); } Predicate[] parr=new Predicate[list.size()]; list.toArray(parr); //相当于查询where condition A and condition B return cb.and(parr); } }); }//controller层 @RequestMapping(value = \"/search\",method = RequestMethod.POST) public Result findSearch(@RequestBody Label label){ List&lt;Label&gt;list=labelService.findSearch(label); return new Result(true,StatusCode.OK,\"查询成功\",list); } 分页与条件查询//service层public Page&lt;Label&gt; findSearchAndPageQuery(Label label, int page, int size) { //封装一个分页对象 Pageable pageable=PageRequest.of(page-1,size); return labelDao.findAll(new Specification&lt;Label&gt;() { /** * * @param root 根对象，也就是说要把条件封装到哪个对象中去 * @param query 查询关键字，比如groupBy，orderBy等 * @param cb 用来封装条件对象的 * @return 如果返回null，则代表不需要任何条件 */ @Override public Predicate toPredicate(Root&lt;Label&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; list=new ArrayList&lt;&gt;(); //相当于 where labelname like \"%小明%\" if(label.getLabelname()!=null&amp;&amp;!\"\".equals(label.getLabelname())){ Predicate predicate = cb.like(root.get(\"labelname\").as(String.class), \"%\" + label.getLabelname() + \"%\"); list.add(predicate); } if(label.getState()!=null&amp;&amp;!\"\".equals(label.getState())){ Predicate predicate = cb.equal(root.get(\"state\").as(String.class), label.getState()); list.add(predicate); } Predicate[] parr=new Predicate[list.size()]; list.toArray(parr); return cb.and(parr); } },pageable); }//controller层 @RequestMapping(value = \"/search/{page}/{size}\",method = RequestMethod.POST) public Result findSearchAndPageQuery(@RequestBody Label label,@PathVariable int page,@PathVariable int size){ Page&lt;Label&gt; pageData=labelService.findSearchAndPageQuery(label,page,size); return new Result(true,StatusCode.OK,\"查询成功\",new PageResult&lt;Label&gt;(pageData.getTotalElements(),pageData.getContent())); }//用来封装pageResult的类public class PageResult&lt;T&gt; { private long total; private List&lt;T&gt; rows; public long getTotal() { return total; } public void setTotal(long total) { this.total = total; } public List&lt;T&gt; getRows() { return rows; } public void setRows(List&lt;T&gt; rows) { this.rows = rows; } public PageResult() { } public PageResult(long total, List&lt;T&gt; rows) { this.total = total; this.rows = rows; }} 在Dao层通过方法命名方式生成sql语句public interface EnterpriseDao extends JpaRepository&lt;Enterprise,String&gt;,JpaSpecificationExecutor&lt;Enterprise&gt;{ //相当于where ishot=? public List&lt;Enterprise&gt; findByIshot(String ishot); }public interface RecruitDao extends JpaRepository&lt;Recruit,String&gt;,JpaSpecificationExecutor&lt;Recruit&gt;{ //相当于where state=？ order by Createtime，并且取前6个 public List&lt;Recruit&gt; findTop6ByStateOrderByCreatetimeDesc(String state); //相当于where state！=？order by createtime。并且取前6个 public List&lt;Recruit&gt; findTop6ByStateNotOrderByCreatetimeDesc(String state);} 具体命名规则参考https://www.cnblogs.com/oxygenG/p/10057525.html。 处理多对多关系在数据库端处理多对多的关系，必须需要借助中间表。而在java端，只需要在一个对象中放入另一个对象的list集合即可。如果不创建实体类，则需要通过原生的sql语句执行 //通过这个查询语句，才能够实现pageable的分页功能@Query(value=\"SELECT * FROM tb_problem,tb_pl WHERE id=problemid AND labelid=:labelid ORDER BY ?#{#pageable}\", countQuery = \"select count(*) from tb_problem ,tb_pl where id=problemid AND labelid=:labelid\",nativeQuery = true)public Page&lt;Problem&gt; newList(@Param(\"labelid\") String labelid, Pageable pageable); 参考：https://blog.csdn.net/tt____tt/article/details/81027269?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase 事务支持1、Dao层，在可能产生线程问题的语句上添加@Modifying @Modifying@Query(value = \"update tb_article set state='1' where id=?1\",nativeQuery = true)public void updateState(String id); 2、Service层开启注解支持@Transactional @Service@Transactionalpublic class ArticleService {} 缓存的应用Redis–有过期时间限制1、添加SpringDataRedis依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2、服务端Docker开启Redis镜像，生成redis容器 [root@pinyoyougou-docker ~]# docker run -di --name=tensquare_redis -p 6379:6379 redis 3、application.ymal配置host redis: host: 192.168.*.* 4、业务逻辑调用 public class ArticleService { @Autowired private ArticleDao articleDao; @Autowired private RedisTemplate redisTemplate; public Article findById(String id) { //先从缓存中查询当前对象 Article article= (Article) redisTemplate.opsForValue().get(\"article_\"+id); //如果没有渠道 if(article==null){ article = articleDao.findById(id).get(); //存入缓存 redisTemplate.opsForValue().set(\"article_\"+id,article); } return article; } public void deleteById(String id) { //删除缓存 redisTemplate.delete(\"article_\"+id); articleDao.deleteById(id); }} redisTemplate用法 stringRedisTemplate.opsForValue().set(\"test\", \"100\",60*10,TimeUnit.SECONDS);//向redis里存入数据和设置缓存时间stringRedisTemplate.opsForValue().get(\"test\")//根据key获取缓存中的valstringRedisTemplate.delete(\"test\");//根据key删除缓存stringRedisTemplate.hasKey(\"546545\");//检查key是否存在，返回boolean值 SpringCache–无过期时间限制1、SpringApplication开启SpringCache @SpringBootApplication@EnableCachingpublic class GatApplication {} 2、业务层调用，@Cacheable为存，@CacheEvict为删 @Cacheable(value = \"gathering\",key = \"#id\")public Gathering findById(String id) { return gatheringDao.findById(id).get();}@CacheEvict(value = \"gathering\",key = \"#gathering.id\")public void update(Gathering gathering) { gatheringDao.save(gathering);} 第二天总结掌握了条件与分页查询，Dao层方法命名规则，事务支持，缓存 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"SpringDataJPA","slug":"SpringDataJPA","permalink":"https://xulilei.github.io/tags/SpringDataJPA/"},{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"Docker入门篇","date":"2020-06-05T07:57:43.000Z","path":"2020/06/05/Docker入门/","text":"Docker入门Dokcer为什么会出现？一款产品从开发到上线，一般都需要两套环境。而环境的配置十分麻烦，Docker给出了解决方案 步骤：java–jar（环境）–打包项目带上环境（即Docker镜像）–Docker仓库–下载我们发布的镜像–直接运行即可。 虚拟机技术特点1、资源占用十分多 2、冗余步骤多 3、启动很慢 如下图所示，多个APP共享一个lib环境，可能会造成端口冲突等环境冲突的问题 容器化技术如下图所示，每个模块拥有独属于自己运行的环境，各个模块之间相互隔离 Docker的相关概念Docker架构图 docker内部如何通信？bridge：docker为容器创建独立的网络环境，实现宿主和容器、容器与容器之间的网络隔离，但是可以通过docker0网桥实现容器之间，容器与宿主机之间的网络通信 host：这种模式下，容器与宿主机之间共享IP地 相关术语镜像：images​ 通过这个模版来创建容器服务，比如Mysql镜像–通过Docker运行后，便成为了一个提供服务的容器,一个镜像可以创建多个容器 容器：container​ 提供服务，可以启动、停止、删除等，可类比为一个简单的linux系统 仓库：repository​ 存放镜像的地方，分为共有仓库和私有仓库 Docker安装Nginx1、search：可在命令行和dockerHub上搜索对应版本 2、pull：拉去下载该镜像 3、docker images：查看本机上的镜像 3、运行该镜像 docker run -d --name nginx01 -p 3344:80 nginx #新建一个名字为nginx01的nginx镜像，公网访问地址为3344，内部地址为80，并运行该镜像#-d 后台运行、--name 命名、-p 端口号 4、内部测试 ​ curl localhost:3344 容器数据卷结构示意图如下 防止容器删除后数据丢失，通过实现容器间数据共享，并将产生的数据备份到linux的文件系统上 总结一句话就是：容器的持久化和容器间的同步操作。 使用数据卷​ -v 主机目录:容器内目录 —&gt;映射容器内的目录到主机上 ​ 参考https://xulilei.github.io/2020/06/12/elasticSearch%E5%85%A5%E9%97%A8/","tags":[{"name":"Docker","slug":"Docker","permalink":"https://xulilei.github.io/tags/Docker/"}]},{"title":"DayOne-架构","date":"2020-06-02T11:02:13.000Z","path":"2020/06/02/十次方社交平台项目/","text":"DayOne系统架构SpringBoot+SpringCloud+SpringMVC+SpringData，也称这种架构模式为spring全家桶 系统模块不再采取按dao，service层划分模块，而是基于每个微服务，再将每个模块封装成一个镜像，再通过springCloud连接起来。因此在每个微服务中便不需要再写接口，因为每个微服务就是最小模块 开发API通过swagger封装，Nginx代理，形成的API开发文档 Restful开发风格我们在项目中经常用到增删改查：get/post/put/delete四种方法，安全：操作不会出现脏读、幻读等操作。幂等：查询成功后不会对数据库造成影响 Get查询是安全且幂等的 Post是不安全且不幂等的 Put改是不安全且幂等的 Delete删是不安全且幂等的 主要工作Mysql环境搭建创建虚拟机，安装docker，下载Mysql镜像，在服务器(192.168.152.128)运行并从本地连接完成建表 创建父工程主要是一些子模块都需要的依赖配置在这里 &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; &lt;!--SpringCloud全家桶父工程推荐默认配置--&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; 模块搭建公共模块搭建，根据swagger约定，封装数据传输到前端。其中utils包下的idWoker根据雪花算法，可以生成不同的ID，吞吐量为20W+。 基础模块搭建，数据的CRUD操作 import com.tensquare.base.pojo.Label;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.data.jpa.repository.JpaSpecificationExecutor;//SpringDataJpa封装了CRUD操作，以及一些复杂的条件查询public interface LabelDao extends JpaRepository&lt;Label,String&gt;, JpaSpecificationExecutor&lt;Label&gt; {} Day01总结在服务器端，通过Docker创建了Mysql镜像 通过本地IDEA的DataSource连接上去。 通过PostMan检查当天的CRUD操作 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]}]