[{"title":"秋招复习redis之高级应用","date":"2020-07-21T10:59:31.000Z","path":"2020/07/21/秋招复习redis之高级应用/","text":"秋招复习redis之高级应用redis分布式锁普通分布式锁为什么不能用Syncronized？在分布式架构下，存在多个web容器时，由于一个web容器对应一个jvm，syncronized是虚拟机级别的锁，因此会失败 分布式锁 set命令要用set key value px milliseconds nx； value要具有唯一性； 释放锁时要验证value值，不能误解锁 String key;//try是为了防止逻辑代码出现异常，导致无法删除keytry{ //如果有则返回false，如果没有则set并返回false Boolean result=redisTemplate.opsForValue().setIfAbsent(key,value,timeout); //result为false说明没有key，则获得该锁，此时其他进程返回true，无法获得该锁 if(!result){ 逻辑代码段 } }finally{ redisTemplate.delete(\"key\");} 问题一：无法保证互斥性已经超过过期时间，key已经被删除了，但是逻辑代码没有执行完成，导致其他进程进来，使得互斥性失效 解决方案使用redisson框架提供的lock； public void redissonLock(){ String key; Rlock lock=redisson.getLock(key); //try是为了防止逻辑代码出现异常，导致无法删除key try{ //60秒后删除key lock.lock(60，TimeUint.SECENDS); 逻辑代码段 }finally{ lock.unlock(); }} 原因如果加锁成功后，每隔1/3锁过期时间，就检查是否还持有锁，如果有就延长锁的时间，直到锁自己释放，这样就保证了互斥性。其他线程无法获得锁会原地等待锁的释放 问题二：主从模式，锁丢失在主节点向从节点写入lock key时，如果主节点挂掉，会替换上一个新的主节点，但该主节点没有lock key，也就导致其他进程仍然可以获得该锁 解决方案redisson的red lock算法 Redlock为了解决单个master的问题，需要多个（大于2）的master节点，多个master节点互相独立 获取当前Unix时间，以毫秒为单位。 依次尝试从n个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该大大小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。 客户端使用当前时间减去开始获取锁时间，就得到获取锁使用的时间。当且仅当从大多数（N/2+1）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。 如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。 缓存雪崩缓存穿透缓存与数据库一致性 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[]},{"title":"秋招复习redis之基础知识","date":"2020-07-19T10:27:57.000Z","path":"2020/07/19/秋招复习redis之基础/","text":"秋招复习之redis概念redis数据类型String：包括数字，主要用于统计数据 Hash：一个string类型的field和value的表结构，适合存储对象，比如用户信息，订单信息等 List：双向链表，比如消息列表，还可以做分页 Set：不重复，自然序的列表数据，可判断一个成员是否在一个set内，比如好友列表 Sorted Set：按照一个权重参数score进行有序排列，多用于自定义的排行列表 redis缓存与cache缓存的区别1、多实例情况下，每个实例对应一份本地缓存，共享redis缓存，即redis缓存具有一致性 2、本地缓存需要自己实现过期功能，生命周期与JVM相同，而redis的数据过期由其本身实现 3、本地缓存无法提供丰富的数据结构只能存object类型的value，redis可以存放很多类型 redis数据过期删除策略其实有三种不同的删除策略： 立即删除立即删除能保证内存中数据的最大新鲜度，因为它保证过期键值会在过期后马上被删除，其所占用的内存也会随之释放。但是立即删除对cpu是最不友好的。因为删除操作会占用cpu的时间，如果刚好碰上了cpu很忙的时候，会给cpu造成额外的压力,所以并不适合用来处理大量的时间事件。 惰性删除惰性删除是指，某个键值过期后，此键值不会马上被删除，而是等到下次被使用的时候，才会被检查到过期，此时才能得到删除。所以惰性删除的缺点很明显:浪费内存。 定时删除从上面分析来看，立即删除会短时间内占用大量cpu，惰性删除会在一段时间内浪费内存，所以定时删除是一个折中的办法。定时删除是：每隔一段时间执行一次删除操作，并通过限制删除操作执行的时长和频率，来减少删除操作对cpu的影响。另一方面定时删除也有效的减少了因惰性删除带来的内存浪费。 redis内存淘汰机制删除策略总会导致内存越来越大，此时就有了redis内存淘汰机制 主要有以下几种volatile-lru：从已设置过期时间中，淘汰最近最少使用的 volatile-lfu：从已设置过期时间中，淘汰最不经常的数据 allkeys-lru：当内存不足，在键空间中，淘汰最近最少使用的key allkeys-lfu：当内存不足，在键空间中，淘汰最不经常使用的key redis持久化机制RDB通过创建快照来获得存储在内存里面的数据在某个时间点上的副本，RDB持久化的是数据 留在本地以便重启服务器的时候使用 可以对快照进行备份，复制到其他服务器上，以创建相同的数据副本（主从复制） 由于存储的是某个时间点的数据，在复制过程中新的数据不会被记录 触发方式 save 900 1：900秒后，至少一个key发生变化 save 300 10：300秒后，至少10个key发生变化 save 60 10000：60秒后，10000个key发生变化 AOF与RDB相比，AOF持久化是保存的是操作redis的命令，实时性更好，需要时，通过这些操作来恢复数据 通过appendonly yes打开AOF 触发方式 appendfsync always ：每次有数据修改发生就写入，会降低redis的数据 appendfsync everysec ：每秒钟同步一次，即使出现崩溃，最多丢失一秒的数据 appendfsync no ：交由操作系统决定 AOF重写重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据用命令的方式重写了一个新的aof文件，与原来的数据状态一样，体积更小 过程：在开启重写时，reids会维护一个AOF缓冲区，会在子进程创建新AOF期间，记录服务器执行的所有操作。当子进程完成创建新AOF文件的工作后，会将缓冲区的记录追加到新AOF文件的末尾，使得数据状态一致 混合持久化重写时，这一刻的内存rdb快照数据和AOF修改命令日志文件存在一起，都写入新的aof文件，快速加载的同时，避免丢失过多的数据 由于AOF文件中不单是AOF格式还有RDB的部分，因此可读性较差 AOF/RDB对比 RDB AOF 内容 全量备份所有数据 增量备份修改命令 体积 小 大 恢复速度 快 慢 安全性 丢失数据 根据策略，every sec可能会丢失一秒数据 redis线程模型单线程多路复用模型多个套接字、IO多路复用程序、文件事件分派器、事件处理器 消息处理流程 通过epoll多路复用程序来同时监听多个套接字 当被监听的套接字准备好执行连接应答(accept)、读取(read)、写入(write)、关闭(close)等操作时，与操作相对应的文件事件就会产生 尽管多个文件事件可能会并发地出现，但redis会将所有产生事件的套接字都推到一个有序队列里面 然后通过这个队列，以有序、同步、每次一个套接字的方式向文件事件分派器传送套接字，当上一个套接字产生的事件被处理完毕之后才会继续向文件事件分派器传送下一个套接字 单线程高性能的原因 纯内存访问：数据存放在内存中，不涉及磁盘I/O 非阻塞I/O：Redis采用epoll作为I/O多路复用技术的实现 单线程避免了多线程切换和竞争产生的消耗。 redis工作模式主从模式写入数据的命令发送给主机执行，而读取数据的命令发送给不同的从机执行，从而达到读写分离的目的 相关概念Redis的主从结构可以采用一主多从或者级联结构，多个从服务器也可以连接到一个从服务器 Redis主从复制不阻塞主服务器端，也不阻塞从服务器端。当从服务器进行初始同步时，它使用旧版本的数据来应对查询请求 从Redis 2.6开始，从服务器支持只读模式，并且是默认模式 Redis主从同步策略主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。 过程 从服务器连接主服务器，发送SYNC命令； 主服务器接收到SYNC命名后，开始RDB存储快照文件并使用缓冲区记录此后执行的所有写命令； 主服务器RDB执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 从服务器收到快照文件后可以使用旧数据继续应答，并载入收到的快照（全量同步）； 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 从服务器完成对快照的载入，丢弃旧数据，开始接收命令请求，并执行来自主服务器缓冲区的写命令（增量同步）； 注意点如果多个Slave断线了，需要重启的时候，因为只要Slave启动，就会发送sync请求和主机全量同步，当多个同时出现的时候，可能会导致Master IO剧增宕机 哨兵模式哨兵是一个独立的进程，也是一个redis服务器，但是不提供数据服务，通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。当哨兵监测到master宕机，会自动将slave切换成master，然后通知其他的从服务器，实行自动故障转移 哨兵主要工作监测第一个哨兵获取master的状态，包括master属性，所属slave的信息，再获取从master获得的slave信息去连接slave 第二个哨兵和第一个哨兵步骤一样，但是多获得了第一个哨兵的信息，此时哨兵2和哨兵1会建立连接，之后会互相监测是否在线 第三个哨兵以此类推 通知第一步监测，完成了哨兵的相互连接，在某一个哨兵获取到被监控的服务器状态后，会向其他哨兵发送通知 自动故障转移当其中一个哨兵认为master挂了后，会告知其他哨兵，并将服务器状态设置为s_down。此时其他哨兵会去确认该服务器是否真的挂了，并将获得的信息传给其他哨兵。当半数以上的哨兵发现服务器挂了，那么就会将服务器的状态改为o_down，下线这台服务器 断开master与slave的连接，选取一个响应快的 slave作为master，将其他slave连接到新的master 集群模式分布式集群即使使用哨兵，redis每个实例也是全量存储，每个redis存储的内容都是完整的数据，浪费内存且有木桶效应。 为了最大化利用内存，可以采用集群，就是分布式存储，即每台redis存储不同的内容 Hash槽Redis 集群中有 16384 个散列槽，为了计算给定密钥的散列槽，Redis 对 key 采用 CRC16 算法，目的是使数据均匀的存储在诸多节点中。这点类似于 HashMap 中的桶(bucket)。 集群至少需要3主3从，每一个节点都存有这个集群所有主节点以及从节点的信息 容错它们之间通过互相的ping-pong判断是否节点可以连接上。如果有一半以上的节点去ping一个节点的时候没有回应，集群就认为这个节点宕机了，然后去连接它的备用节点 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"redis","slug":"redis","permalink":"https://xulilei.github.io/tags/redis/"}]},{"title":"秋招复习mysql之底层原理","date":"2020-07-18T05:41:17.000Z","path":"2020/07/18/秋招复习mysql之底层原理/","text":"秋招复习mysql之底层原理存储引擎InnoDB支持事务和行级锁，外键，采用密集索引 MyISAM不支持事务和行级锁，采用稀疏索引，不支持外键，不支持MVCC，强调性能 索引相关概念密集索引主键索引的data域存储了完整的数据记录包括其他叶子节点的信息，决定了叶子节点的物理排列顺序，因此一个表只能创建一个密集索引，辅助索引则存储了对应的主键 具体过程为：在根据主键索引搜索时，直接找到key所在的节点即可取出数据，在根据辅助索引查找时，先取出主键索引的值，再走一遍主键索引 稀疏索引稀疏索引的data域只存储了主键和数据地址等部分信息 过程为，根据索引取出data域的数据保存的地址，再根据地址读取相应的数据 为什么要使用索引避免全表扫描，提升查询效率 什么样的信息能够成为索引主键，唯一键等 索引的数据结构有哪些B+Tree索引，hash索引 hash索引的缺点1、仅能满足“=”，“in” 不能使用范围查询 2、不能避免全表扫描 3、当哈希值大量相同时，效率会退化 为什么使用B+树作为索引二叉查找树左子树的值小于根的值，右子树的值大于根的值，这种会遇到退化成链表的情况，时间复杂度由O（logN）变为O（n） 二叉平衡树满足二叉查找树的条件，且任何节点的左右子树的高度差最大为1，控制时间复杂度为O（logN），但是其添加删除数据的操作会频繁的涉及到左旋右旋，因此也不适合作为索引 B-treeInnoDB是以页为存储单位读取数据的，每个页都有索引有助于快速定位数据的位置，但B-tree每个节点都包含data值，由此导致页存储的索引数量受限，可能造成树的深度过深，查找到最终数据经历的I/O次数太多，并且数据的删除与添加也很不便 B+tree是B-tree的一种优化，相较于B-tree，B+tree主要有以下几点不同： 1、非叶子节点只存储定位索引的信息 2、所有数据都存储在叶子节点上 3、叶子节点之间存在链指针 这样的改进可以帮助非叶子节点存储更多的索引定位信息，大大降低树的高度，减少磁盘IO的次数，且由于所有的信息都存储在叶子节点且通过链指针相连，数据的增删效率也大大增加 联合索引联合索引是指对表上的多个列进行索引，顺序不同索引不同，根据联合索引树找到主键值，再从主键树上查找数据 最左前缀原则命中索引时一直向左匹配直到遇到范围查询，范围查询后面的索引失效，如果前面的索引没有命中，那么后面的索引是无效的 因此在联合索引中将选择性最高的列放在索引最前面，依次降低 索引命中规则索引命中规则详解： t这张表 a,b,c 三个字段组成组合索引select * from t where a=? and b=? and c=? 全命中select * from t where c=? and b=? and a=? 全命中 解析MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引select * from t where a=? 命中a 解析:最左前缀匹配select * from t where a=? and b=? 命中a和b 解析:最左前缀匹配select * from t where a=? or b=? 一个没命中 解析or无法命中select * from t where a=? and c=? 命中a 解析:最左前缀匹配，中间没有则无法使用索引 select * from t where a=? and b in ( x, y, z) and c=? 全部命中 in精确匹配可以使用索引 select * from t where b=? 一个没命中 解析:最左前缀匹配原则 select * from t where b=? and c=? 一个没命中 解析:最左前缀匹配原则 select * from t where a=? and b like 'xxx%' 命中a select * from t where a=? and b like '%xxx' 命中a和b select * from t where a&lt;? and b=? 命中a 解析这个是范围查找 select * from t where a between ? and ? and b=? 命中a和b 解析BETWEEN相当于in操作是精确匹配 select * from t where a between ? and ? and b=? and c and between ? and ? 全部命解析中同上 select * from where a-1=? 函数和表达式无法命中索引 如何定位并优化慢查询1、根据慢日志定位到慢查询sql 2、使用explain工具分析sql，字段type：index表示走索引，all表示走的全表 3、修改sql，或者让sql尽量走更多的索引 索引类型 TYPE 类型 ALL 全表扫描 index 走索引树的全表扫描 range 扫描部分索引，开始于索引的某一个点，结束另一个点 ref 使用非唯一索引或非唯一索引前缀进行的查找 const 使用=比较主键索引或者唯一索引 事务四大特性原子性：不可分割的操作，要么成功要么失败 隔离性：操作间不能相互影响 一致性：从某种一致性的状态转换到另一个一致性的状态 持久性：永久保存 事务：保证原子性、一致性、隔离性、持久性的数据操作称为一个事务 隔离性导致的问题脏读：一个事务读到了另一个事务没有提交的操作 不可重复读：同一个事务两次读取的数据不一样 幻读：一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的数据行 隔离性 脏读 不可重复读 幻读 读未提交 会发生 会发生 会发生 读已提交 不会发生 会发生 会发生 可重复度 不会发生 不会发生 mysql下不会发生 串行化 不会发生 不会发生 不会发生 MVCC多版本并发控制InnoDB行格式除了保存数据和其他字段外，还保存了三个字段。第一个是row_id，其次是trx_id，指的是数据改动的版本，还有一个point_id用于事务间的回滚，这样就形成了一个数据的版本链 InnoDB控制并发操作，用的就是MVCC和锁相结合的方式，相较于单一锁机制，该种机制可以提升系统性能 read viewreadView是MVCC多版本并发控制的一个实现手段，就是在事务开启的时候创建一个事务列表集合，在不同的隔离级别下，看到的事务列表集合可能也不同 读已提交隔离级别使用MVCC避免脏读原理在这种隔离级别下，readview事务列表集合存储的是仍处于活跃状态的事务，即未提交的失误，每当事务提交，则重新生成。读取数据时，会从当前最新的版本开始，按照版本链的顺序，根据readview事务列表，找到最近的不活跃的版本中的数据。如此一来，就避免了读取到未提交事务的操作 可重复度隔离级别使用MVCC避免不可重复读原理在RR隔离级别下，readview用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。但是之后，这个事务执行期间，其他事务的更新（数据版本）对它不可见。当查询数据时，会按照启动时的版本链找到最近的不活跃的版本数据 锁机制按操作数据类型来分S锁读锁：只给读不给写，称共享锁、S锁 select … in share mode：将查找的数据加一个S锁，允许其他事务继续获得该记录的S锁，不能获取X锁 场景：读取数据时，其他事务不能修改，自己也不一定能修改，因为其他事务可能也加了读锁 X锁写锁：不给其他事务读，也不给写，线程阻塞，称排它锁、X锁 select … for update：将查找的数据加一个X锁，不允许其他事务获得该记录的S锁、X锁，不能获取X锁 场景：当前事务可以读写，其他事物不能读写，update、delete、insert都会默认加写锁 按锁的粒度划分行锁访问数据库的时候，锁定整个行数据，防止并发错误。 InnoDB存储引擎默认使用行锁 表锁访问数据库的时候，锁定整个表数据，防止并发错误。 MyISAM存储引擎使用表锁 表锁和行锁时机行级锁都是基于索引的，如果一条SQL语句用不到索引则会使用表级锁 按上锁的行为划分悲观锁每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁 乐观锁每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制 快照读和当前读快照读：简单的select操作，属于快照读，不加锁。select * from table where ? 当前读：s锁，X锁，insert/delete/update等操作，加锁 RR级别下解决幻读的原理在快照读读情况下，mysql通过mvcc来避免幻读在RR隔离级别下，readview用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。但是之后，这个事务执行期间，其他事务的更新（数据版本）对它不可见。当查询数据时，会按照启动时的MVCC版本链找到最近的不活跃的版本数据。 在当前读读情况下，mysql通过next-key来避免幻读record lock：单个行记录上的锁 Gap lock：间隙锁，锁定一个范围，不包括记录本身 next-key lock：行锁(record lock)+间隙锁(gap lock)，锁定一个范围，包含记录本身 1、当通过主键索引或者唯一索引查询数据，此时的next-key锁会降级成行锁，是由于其他事务的操作不会对本次查询造成影响 2、当通过非唯一索引查询数据时，此时会添加next-key锁，锁住包含当前记录的一个范围，这样其他事务就无法在这个范围内添加数据 数据库优化大表优化当mysql单表记录数过大时，数据库的crud性能会明显下降 1、限定数据查询范围禁止不带任何限制条件的查询 2、主从复制、读/写分离（分库）Mysql的主从复制和mysql的读写分离两者有紧密的联系，首先要部署主从复制，只有主从复制完成了，才能再此基础上进行数据的读写分离 主库负责写，从库负责读 3、垂直水平分区（分表）垂直分区：即根据数据的相关性，将多列的表拆分成少列多张表 优点：列数据变小，减小IO次数，简化表结构，易于维护 缺点：会出现数据冗余，并且会出现JOIN操作，导致事务变得复杂 水平分区：保持数据结构不变，将存储数据分片，再存储到不同的表或库中 优点：支持非常大数据的存储，且应用端改造少 缺点：拆分会给服务端带来逻辑，部署，运维的各种难度，因此不建议对数据进行分片 分库分表后，id主键如何处理分成多个表后，不应让每个表的id从1开始累加，而应该控制全局唯一ID支持 SQL注入sql注入，简单来说就是用户在前端web页面输入恶意的sql语句用来欺骗后端服务器去执行恶意的sql代码，从而导致数据库数据泄露或者遭受攻击。 方案java防SQL注入,最简单的办法是杜绝SQL拼接,SQL注入攻击能得逞是因为在原有SQL语句中加入了新的逻辑 如果使用PreparedStatement来代替Statement来执行SQL语句，其后只是输入参数，SQL注入攻击手段将无效 在WEB层我们可以过滤用户的输入来防止SQL注入比如用Filter来过滤全局的表单参数 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"mysql","slug":"mysql","permalink":"https://xulilei.github.io/tags/mysql/"}]},{"title":"秋招复习mysql之sql语句","date":"2020-07-17T10:58:31.000Z","path":"2020/07/17/秋招复习mysql之sql语句/","text":"秋招复习mysql之sql语句基础语句SELECT 语句SELECT 列名称 FROM 表名称SELECT * FROM 表名称例子:SELECT LastName,FirstName FROM Persons WHERE条件限定如需有条件地从表中选取数据，可将 WHERE 子句添加到 SELECT 语句。 SELECT 列名称 FROM 表名称 WHERE 列 运算符 值SELECT * FROM Persons WHERE City='Beijing'表中选取居住在不包含 \"lon\" 的城市里的人：SELECT * FROM Persons WHERE City NOT LIKE '%lon%' 运算符 操作符 描述 = 等于 != 不等于 &gt; 大于 &lt; 小于 &gt;= 大于等于 &lt;= 小于等于 BETWEEN 在某个范围内 LIKE 搜索某种模式 IN 操作符IN 操作符允许我们在 WHERE 子句中规定多个值 从Persons表中选取姓氏为 Adams 和 Carter 的人：SELECT * FROM Persons WHERE LastName IN ('Adams','Carter')等同于SELECT * FROM Persons WHERE LastName ='Adams' or LastName ='Carter' BETWEEN 操作符操作符 BETWEEN … AND… （左闭右开）会选取介于两个值之间的数据范围。这些值可以是数值、文本或者日期。 以字母顺序显示介于 \"Adams\"（包括）和 \"Carter\"（不包括）之间的人，请使用下面的 SQL：SELECT * FROM Persons WHERE LastName BETWEEN 'Adams' AND 'Carter' TOP语句现在，我们希望从上面的 \"Persons\" 表中选取头两条记录SELECT TOP 2 * FROM Persons现在，我们希望从上面的 \"Persons\" 表中选取 50% 的记录SELECT TOP 50 PERCENT * FROM Persons DISTINCT关键词 DISTINCT 用于返回唯一不同的值。SELECT DISTINCT 列名称 FROM 表名称 AND 和 OR 运算符AND 和 OR 可在 WHERE 子语句中把两个或多个条件结合起来 如果第一个条件和第二个条件都成立，则AND位true 如果第一个条件和第二个条件中只要有一个成立，则OR为true 使用 AND 来显示所有姓为 \"Carter\" 并且名为 \"Thomas\" 的人：SELECT * FROM Persons WHERE FirstName='Thomas' AND LastName='Carter'使用 OR 来显示所有姓为 \"Carter\" 或者名为 \"Thomas\" 的人：SELECT * FROM Persons WHERE firstname='Thomas' OR lastname='Carter' ORDER BY 语句ORDER BY 语句用于根据指定的列对结果集进行排序。 ORDER BY 语句默认按照升序对记录进行排序，如果望按照降序对记录进行排序，可以使用 DESC 关键字。 以逆字母顺序显示公司名称，在公司名称相同的情况下以数字顺序显示顺序号：SELECT Company, OrderNumber FROM Orders ORDER BY Company DESC, OrderNumber ASC INSERT INTO语句INSERT INTO 语句用于向表格中插入新的行。 语法INSERT INTO 表名称 VALUES (值1, 值2,....)INSERT INTO Persons VALUES ('Gates', 'Bill', 'Xuanwumen 10', 'Beijing')也可以指定所要插入数据的列：INSERT INTO table_name (列1, 列2,...) VALUES (值1, 值2,....)INSERT INTO Persons (LastName, Address) VALUES ('Wilson', 'Champs-Elysees') Update 语句Update 语句用于修改表中的数据 语法：UPDATE 表名称 SET 列名称 = 新值 WHERE 列名称 = 某值修改地址address，城市名称city当LastName为WilsonUPDATE Person SET Address = 'Zhongshan 23', City = 'Nanjing' WHERE LastName = 'Wilson' DELETE 语句DELETE 语句用于删除表中的行 \"Fred Wilson\" 会被删除：DELETE FROM Person WHERE LastName = 'Wilson' 可以在不删除表的情况下删除所有的行。这意味着表的结构、属性和索引都是完整的：DELETE FROM table_name或者：DELETE * FROM table_name 高级语句CREATE TABLECREATE TABLE Persons(列名称 数据类型Id_P int,Name varchar(255),Address varchar(255),City varchar(255)) 数据类型（data_type）规定了列可容纳何种数据类型。下面的表格包含了SQL中最常用的数据类型： 数据类型 描述 integer(size)、int(size)、smallint(size)、 tinyint(size) 仅容纳整数。在括号内规定数字的最大位数。 decimal(size,d) 、numeric(size,d) 容纳带有小数的数字。”size” 规定数字的最大位数。”d” 规定小数点右侧的最大位数。 char(size) 容纳固定长度的字符串（可容纳字母、数字以及特殊字符）。在括号中规定字符串的长度。 varchar(size) 容纳可变长度的字符串（可容纳字母、数字以及特殊的字符）。在括号中规定字符串的最大长度。 date(yyyymmdd) 容纳日期。 SQL 约束约束用于限制加入表的数据的类型。 可以在创建表时规定约束（通过 CREATE TABLE 语句），或者在表创建之后也可以（通过 ALTER TABLE 语句）。 CREATE TABLE Persons(Id_P int NOT NULL PRIMARY KEY)或者ALTER TABLE Personsadd PRIMARY KEY(id_p)drop PRIMARY KEY 添加外键，要指明指向的是哪个表的逐渐ALTER TABLE ordersadd CONSTRAINT aliasFOREIGN KEY(id_p)REFERENCES persons(id_p)删除外键ALTER TABLE ordersDROP FOREIGN KEY alias 在已经存在表的情况下，添加default约束ALTER TABLE PersonsALTER City SET DEFAULT 'SANDNES'或者删除default约束ALTER City DROP DEFAULT ALTER table personsadd CONSTRAINT aliasCHECK(id_p&gt;0 and city='beijing') 我们将主要探讨以下几种约束： 约束名 含义 NOT NULL 约束强制列不接受 NULL 值 UNIQUE 唯一标识数据库表中的每条记录，可以有多个 PRIMARY KEY 唯一标识数据库表中的每条记录，每个表都应该有且仅有一个主键 FOREIGN KEY 用于预防破坏表之间连接的动作，防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一 DEFAULT 如果没有规定其他的值，那么会将默认值添加到所有的新记录 CHECK 此约束会在特定的列中对值进行限制 sql通配符SQL 通配符必须与 LIKE 运算符一起使用 通配符 描述 % 替代一个或多个字符 _ 仅替代一个字符 [charlist] 字符列中的任何单一字符 [^charlist]或者[!charlist] 不在字符列中的任何单一字符 使用 % 通配符从 \"Persons\" 表中选取居住在以 \"Ne\" 开始的城市里的人：SELECT * FROM Persons WHERE City LIKE 'Ne%'使用 _ 通配符从 \"Persons\" 表中选取名字的第一个字符之后是 \"eorge\" 的人：SELECT * FROM Persons WHERE FirstName LIKE '_eorge'使用 [charlist] 通配符从 \"Persons\" 表中选取居住的城市以 \"A\" 或 \"L\" 或 \"N\" 开头的人：SELECT * FROM Persons WHERE City LIKE '[ALN]%'从 \"Persons\" 表中选取居住的城市不以 \"A\" 或 \"L\" 或 \"N\" 开头的人：SELECT * FROM Persons WHERE City LIKE '[!ALN]%' sql别名可以通过as为列名称和表名称指定别名（Alias） 查询出来的code表的codeid显示为cid，role表的roleid显示为ridSELECT c.codeid as cid,r.roleid as ridcode表起名c，role表起名rFROM code AS c,role as rcode表的userid为1和role表rolename为userwhere c.userid=1 and r.rolename='user' sql JOINWHERE子句中使用的连接语句，在数据库语言中，被称为隐性连接。INNER JOIN……ON子句产生的连接称为显性连接。（其他JOIN参数也是显性连接） WHERE和INNER JOIN产生的连接关系，没有本质区别，结果也一样。 inner joinSELECT p.username,o.orderNoFROM persons as p,orders as owhere p.id_p=o.id_p等价于内连接SELECT p.username,o.orderNoFROM persons as pINNER JOIN orders as oon p.id_p=o.id_p三表连接SELECT p.username,o.orderNo,t.addressfrom(persons as pinner joinorders as oon p.id_p=o.id_p)inner joinTMD as ton p.id_p=t.id_p outer joinleft join：理解为“有左显示”，比如on a.field=b.field，则显示a表中存在的全部数据及a、b中都有的数据，a中有、b中没有的数据以null显示right join：理解为“有右显示”，比如on a.field=b.field，则显示b表中存在的全部数据及a、b中都有的数据，b中有、a中没有的数据以null显示 SQL UNIONUNION 操作符用于合并两个或多个 SELECT 语句的结果集，UNION 内部的 SELECT 语句必须拥有相同数量的列，列也必须拥有相似的数据类型。 INSERT INTOINSERT INTO 语句从一个表中选取数据，然后把数据插入另一个表中， 将select查询的数据插入已存在的表orderinfo，当表不存在时，通过将insert into改为create table INSERT into orderinfoSELECT p.username,o.orderNoFROM persons as pINNER JOIN orders as oon p.id_p=o.id_p SQL CREATE INDEX在表中创建索引，以便更加快速高效地查询数据。用户无法看到索引，它们只能被用来加速搜索/查询 CREATE UNIQUE INDEX PersonIndexON Person (LastName, FirstName)删除ALTER TABLE PersonDROP INDEX PersonIndex SQL ALTER TABLE用于在已有的表中添加、修改或删除列 在表 \"Persons\" 中添加一个名为 \"Birthday\"类型为“DATE”的新列。ALTER TABLE PersonsADD Birthday date 改变 \"Persons\" 表中 \"Birthday\" 列的数据类型为“year”。ALTER TABLE PersonsMODIFY COLUMN Birthday year 删除 \"Person\" 表中的 \"Birthday\" 列：ALTER TABLE PersonDROP COLUMN Birthday SQL AUTO INCREMENT在每次插入新记录时，自动地为主键字段创建一个唯一的值 CREATE TABLE Persons(P_Id int NOT NULL AUTO_INCREMENT,PRIMARY KEY (P_Id)) SQL VIEW视图是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据 作用1、提高了重用性。如果要频繁获取user的name和goods的name，则可以通过视图将其保存起来，而不用创建新的中间表 2、对数据库重构，却不影响程序的运行 3、让数据更加清晰。想要什么样的数据，就创建什么样的视图 创建视图create view other as select a.name as username, b.name as goodsname from user as a, goods as b, ug as c where a.id=c.userid and c.goodsid=b.id;、创建好视图后，可以直接从view中查询select * from other删除视图DROP VIEW view_name SQL DATE下面的表格列出了 MySQL 中最重要的内建日期函数： 函数 描述 NOW() 返回当前的日期和时间 CURDATE() 返回当前的日期 CURTIME() 返回当前的时间 DATE() 提取日期或日期/时间表达式的日期部分 EXTRACT() 返回日期/时间的单独部分 DATE_ADD() 给日期添加指定的时间间隔 DATE_SUB() 从日期减去指定的时间间隔 DATEDIFF() 返回两个日期之间的天数 DATE_FORMAT() 用不同的格式显示日期/时间 SQL NULL对于可选列，当插入一条可选列无值的数据，会以NULL值保存 无法使用比较运算符来测试 NULL 值，比如 =, &lt;, 或者 &lt;&gt;， 必须使用 IS NULL 和 IS NOT NULL 操作符。 SELECT LastName,FirstName,Address FROM PersonsWHERE Address IS NOT NULL 涉及到计算时通过IFNULL(VALUE,0),COALSCE(VALUE,0) SELECT ProductName,COALESCE(OrderNo,0)FROM Products SQL函数常见sql函数，详见https://blog.csdn.net/zeng_ll/article/details/87706409 函数名 作用 avg(数值列) 返回数值列的平均值。NULL 值不包括在计算中 abs(数值列) 返回数值列的绝对值 count(字段名) 返回匹配指定条件的行数 first(字段名)/last(字段名) 函数返回指定的字段中第一个/最后一个记录的值 max(字段名)/min(字段名) 返回一列中的最大值/最小值 ucase(字段名)/lcase(字段名) 字段值转换为大写/小写 len(字段名) 文本字段中值的长度 ROUND(字段名，小数位数) 把数值字段舍入为指定的小数位数 IF(expr,v1,v2） 如果表达式 expr 成立，返回结果 v1；否则，返回结果 v2 GROUP BYGROUP BY 语句根据一个或多个列对结果集进行分组，在分组的列上我们可以使用 COUNT, SUM, AVG等合计函数 SELECT Customer,SUM(OrderPrice) FROM OrdersGROUP BY Customer HAVING在 SQL 中增加 HAVING 子句原因是，WHERE 关键字无法与合计函数一起使用 HAVING SUM(OrderPrice)&lt;2000中的“SUM(OrderPrice)&lt;2000”即为合计函数 SELECT Customer,SUM(OrderPrice) FROM OrdersGROUP BY CustomerHAVING SUM(OrderPrice)&lt;2000 找到客户BUSH或者ADAMS中订单超过1500的金额SELECT Customer,SUM(OrderPrice) FROM OrdersWHERE Customer='Bush' OR Customer='Adams'GROUP BY CustomerHAVING SUM(OrderPrice)&gt;1500 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"mysql","slug":"mysql","permalink":"https://xulilei.github.io/tags/mysql/"}]},{"title":"秋招复习之操作系统","date":"2020-07-15T07:39:07.000Z","path":"2020/07/15/秋招复习之操作系统/","text":"秋招复习之操作系统进程进程间的通信方式1、匿名管道：用于具有亲缘关系的父子进程或者兄弟进程之间的通信，存放于内存中 2、有命管道：匿名管道由于没有名字，只能用于亲缘关系进程之间的通信。有名管道以磁盘文件方式存在，可以实现本机任意两个进程通信，遵守先进先出 3、信号：用于通知接收进程某个事件已经发生 4、消息队列：是消息的链表，具有特定的格式，存放在内存中并有消息队列标识符标识，可以实现消息的随机查询，不一定按照FIFO的顺序，可以按照消息的类型读取 5、信号量：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步，主要用于解决与同步相关的问题，并避免竞争条件 6、共享内存：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享数据的更新，但需依赖互斥锁，信号量等，是最有用的线程间通信方式 7、套接字：用于客户端进程和服务器之间通过网络进行通信 线程间的同步方式1、互斥量：即某一时刻，互斥对象中只有一个能够访问公共资源，比如java中的Syncronized 2、信号量：它允许同一时刻多个线程访问同一资源 3、事件：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。比如在某些网络应用程序中，一个线程如A负责侦听通信端口，另外一个线程B负责更新用户数据，利用事件机制，则线程A可以通知线程B何时更新用户数据。 进程调度算法1、先到先服务：从就绪队列选择一个最早进入队列的进程，为该资源分配进程立即执行 2、短作业优先：从就绪队列选择一个估计运行时间最短的进程，为该资源分配进程立即执行 3、时间片轮转：每个进程被分配一个时间段，称作它的时间片，即该线程允许运行的时间 4、优先级：为每个进程分配优先级，高优先级先执行，相同优先级先到先执行 5、多级反馈队列：既保证高优先级进程得到响应，又能使短作业进程快速完成 内存操作系统内存管理做了什么主要负责内存的分配与回收，以及讲逻辑地址映射成响应的物理地址 常见的内存管理机制连续分配管理：为一个进程分配一个连续的内存空间，如块式管理，如果进程只需很小的空间的话，会造成浪费 非连续分配管理：允许一个程序使用的内存分布在离散的内存中 页式管理：将主存分为大小相等且固定的一页一页的形式，粒度更小，通过页表对应物理和逻辑地址 段式管理：将主存分为一段一段，每个段赋予了逻辑信息，通过段表对应物理和逻辑地址 段页式管理机制：结合了段式和页式管理的优点，先将主存分成若干段，再将每个段分配成若干页 段页机制的共同点与区别相同点1、分页机制和分段机制都是为了提高内存利用率，减少内存碎片 2、页和段都是离散存储的，但是段和页内的内存是连续的 不同点1、页大小固定，段大小根据运行的程序 2、分页是为了满足操作系统内存管理的需求，而段是具有逻辑信息的，体现为代码段，数据段等 多级页表和快表快表为了解决虚拟地址到物理地址的转换速度，使用页表后转换流程 1、根据虚拟地址中的页号查快表 2、如果该页在快表中，则直接从快表中读取相应的物理地址 3、如果不在快表中，则访问页表，得到物理地址后，映射一份到快表中，以备下次转换 4、快表满后，则根据淘汰策略淘汰一页 多级页表避免把全部页表一直放在内存中占用过多空间，多级页表通过一个顶级页表为真正有用的页表提供索引，这样一些不需要的页表就不用一直存储在内存中了，只需要通过顶级页表索引查询到具体的页表即可，是一种时间换空间的做法 虚拟(逻辑)地址与物理地址程序产生的与段相关的偏移地址，而物理地址则是代表真实物理内存中的地址 CPUcpu寻址cpu通过虚拟寻址将虚拟地址翻译成物理地址，这样才能访问到真正的物理内存 虚拟地址空间没有虚拟地址空间的时候，程序直接访问和操作的都是物理内存会造成以下问题 1、用户程序可以随意访问任意内存，很容易破坏系统 2、运行多个程序不便，比如A程序分配了1XX的内存地址，当另一个程序也分配到这里的时候会造成覆盖 使用虚拟地址空间： 1、用户可以使用相邻的虚拟地址访问物理地址不相邻的内存 2、不同程序之间虚拟地址被隔离，保护了系统，以及运行的程序 局部性原理表现为以下两个方面：时间局部性：如果程序中的某条指令一旦执行，则不久之后该指令可能再次被执行；如果某数据被访问，则不久之后该数据可能再次被访问。 空间局部性：是指一旦程序访问了某个存储单元，则不久之后，其附近的存储单元也将被访问。 CPU对应的做法时间局部性：如果一个信息项正在被访问，数据在寄存器被计算完成后，将会放入高速缓存中。 空间局部性：在读取内存的时候将该内存附近的内存也读进缓存中。 虚拟内存虚拟内存可以让程序拥有超过物理内存大小的可用内存空间，定义了一个连续的虚拟地址空间，并把内存扩展到硬盘空间 虚拟内存的实现1、在载入程序的时候，装入程序的一部分，而另一部分留在外寸 2、缺页中断：当程序执行过程中，访问信息不在内存中时（成为缺页缺段），再将需要的部分读入内存，继续执行程序 3、虚拟地址空间：逻辑地址到物理地址的转换 页面置换算法地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断，如果当前内存中没有空闲的页面，操作系统就必须在内存选择一个页面将其一出内存，这就涉及到了页面置换算法 LFU页面置换算法：系统会维护一个按最近一次访问时间排序的页面链表，链表首节点最近刚刚使用过的页面，链表尾节点是最久未使用的，缺页时，置换链表尾节点的页面。也就是说，内存使用越频繁的页面，保留的时间也越长 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://xulilei.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"秋招复习之IO","date":"2020-07-14T06:07:52.000Z","path":"2020/07/14/秋招复习之IO/","text":"秋招基础复习之IO模型基本四个：InputStream，outputStream，reader，writer 字节流和字符流的区别1、字节流是最小单元，但是在字符与字节流的转化过程中，可能会造成乱码，因此提供了直接操作字符的工具 2、字节流在操作时本身不会用到缓冲区（内存），是文件本身直接操作的；而字符流在操作时使用了缓冲区，通过缓冲区再操作文件。 什么是缓冲区？有什么作用？缓冲区就是一段特殊的内存区域，很多情况下当程序需要频繁地操作一个资源（如文件或数据库）则性能会很低，所以为了提升性能就可以将一部分数据暂时读写到缓存区，以后直接从此区域中读写数据即可，这样就显著提升了性能。 缓冲和缓存的区别缓存（cache）是在读取硬盘中的数据时，把最常用的数据保存在内存的缓存区中，再次读取该数据时，就不去硬盘中读取了，而在缓存中读取。缓冲（buffer）是在向硬盘写入数据时，先把数据放入缓冲区,然后再一起向硬盘写入，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。 BIO/NIO/AIOBIO两个阻塞点：Socket socket=serverSocket.accept()处理请求的时候，另一个是InputStream is=socket.getInputStream()处理io流的时候 优点是：一个线程为一个客户端服务，质量好。 缺点是：并发量大的时候性能差 NIO相关概念Selector(通道的管理器，选择器)：下面两种事件会注册到Selector上 ServerSocketChannel（相对于BIO的ServerSocket，关心accept事件） SocketChannel（相当于BIO的Socket，关心IO操作） SelectionKey事件集合 具体实现1、创建ServerSocketChannel，配置其为非阻塞模式 2、创建Selector，将之前创建的ServerSocket注册到Selector上，监听accept事件 3、Selector对象进行死循环监听每一个Channel通道的事件，轮询就绪的Channel 4、从Selector中获取所有的SelectorKey（这个就可以看成是不同的事件），如果SelectorKey是处于 OP_ACCEPT 状态，说明是新的客户端接入 5、然后对这个把这个接受的新客户端的Channel通道注册到ServerSocketChannel上，并且把之前的OP_ACCEPT 状态改为SelectionKey.OP_READ读取事件状态，开始读取机制，并且设置为非阻塞的，然后把当前的这个SelectorKey给移除掉，说明这个事件完成了 I/O多路复用机制多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉。当有一个或多个流有 I/O事件时，就从阻塞态中唤醒，依次顺序的处理就绪的流，这种做法就避免了大量的无用操作 多路复用流程用户态将文件描述符传入内核 select/poll：将用户态文件拷贝到内核中，监听IO操作。其中select有fd数量限制，默认是1024。 epoll：会在内核的中建立一颗红黑树以及就绪链表。每一个用户态文件描述符会对应红黑树的一个节点，同时注册回调函数。 内核态检测文件描述符读写状态 select/poll：采用轮询方式，遍历所有fd，找到就绪的fd。 epoll：采用回调机制。内核在检测到事件时会调用回调函数，该回调函数会将就绪的事件放在就绪链表中。 找到就绪的文件描述符并传递给用户态 select/poll：将之前传入的就绪fd拷贝到用户态。 epoll：epoll_wait只用观察就绪链表中有无数据依次处理即可。 多路复用优点用select/epoll的优势在于，它可以同时处理很多个连接。与一条线程维护一个连接相比，系统不必创建线程，也不必维护这些线程，从而大大减小了系统的开销。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"IO","slug":"IO","permalink":"https://xulilei.github.io/tags/IO/"}]},{"title":"秋招复习之java基础","date":"2020-07-12T08:15:47.000Z","path":"2020/07/12/秋招复习之java基础/","text":"秋招复习之java基础1、面对对象的理解面向对象易维护，易复用，易扩展。因为面向对象有封装、继承、多态三大特性，所以基于面对对象思想构建的程序具有低耦合、更灵活、易维护等特点 封装、继承、多态封装：也就是把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。 继承：是指可以让某个类型的对象获得另一个类型的对象的属性的方法。 所态：就是指一个类实例的相同方法在不同情形有不同表现形式 2、JVM、JRE、JDKJVM：被称为java虚拟机，是运行java字节码的虚拟机 JRE：java运行时环境，包括JVM，Java类库，Java命令和其他一些基础组件 JDK：拥有JRE所拥有的一切，还有java编译器javac和工具 3、基本数据类型 4、重载、重写与重构的区别重载：发生在同一个类中，方法名必须相同，参数类型，个数，顺序，返回值类型，访问修饰符等都可以不同 重写：是子类对父类允许访问的方法的实现过程进行重新编写，发生在子类中，方法名、参数列表必须相同，返回值范围小于等于父类，访问修饰符范围大于等于父类，如果父类是private修饰的就不能重写该方法。也就是说方法提供的行为改变，而方法的外貌并没有改变 重构：是重写的一种特殊方式，子类与父类的成员方法的返回值、方法名称、参数类型及个数完全相同，唯一不同的是方法实现内容，这种特殊重写方式被称为重构。 5、StringBuffer、StringBuilder、StringString：由final关键字修饰，即String对象是不可变的，线程安全 StringBuffer：对象可变，线程安全 StringBuilder：对象可变，线程不安全 6、自动装箱与拆箱装箱：将基本数据类型用他们对应的引用类型包装起来 拆箱：将包装类型转换为基本数据类型 一种机制，使得这些基本类型在一般的编程中被当作非对象的简单类型处理，在另一些场合，又允许它们被视作是一个对象 7、静态方法和非静态方法的区别一、静态方法是使用static关键字修饰的方法，又叫类方法。属于类的，不属于对象，在实例化对象之前就可以通过类名.方法名调用静态方法。A.在静态方法中，可以调用静态方法。B.在静态方法中，不能调用非静态方法。C.在静态方法中，可以引用类变量（即，static修饰的变量）。D.在静态方法中，不能引用成员变量（即，没有static修饰的变量）。E.在静态方法中，不能使用super和this关键字 二、非静态方法是不含有static关键字修饰的普通方法，又称为实例方法，成员方法。属于对象的，不属于类的。成员方法是属于对象的，必须通过new关键字创建对象后，再通过对象调用A.在普通方法中，可以调用普通方法。B.在普通方法中，可以调用静态方法C.在普通方法中，可以引用类变量和成员变量D.在普通方法中，可以使用super和this关键字 静态方法和非静态方法的区别（生命周期不同）静态方法的生命周期跟相应的类一样长，静态方法和静态变量会随着类的定义而被分配和装载入内存中。一直到线程结束，静态属性和方法才会被销毁。（也就是静态方法属于类）非静态方法的生命周期和类的实例化对象一样长，只有当类实例化了一个对象，非静态方法才会被创建，而当这个对象被销毁时，非静态方法也马上被销毁。（也就是非静态方法属于对象） 8、空构造函数的作用构造函数的作用：当new一个对象的时候，调用构造函数完成对象的初始化 在类中如果没有参构造函数，系统会默认一个无参构造函数，此时写不写空构造没有影响。但如果父类只定义了有参构造，在子类的构造函数中，又没有通过super()来调用父类特定有参构造函数的情况下，将会发生编译错误。 9、接口和抽象类抽象类：抽象类不能实例化，即不能使用new关键字来实例化对象；抽象类可以含有抽象方法，也可以不包含抽象方法，抽象类中可以有具体的方法；抽象类中的抽象方法只有方法体，没有具体实现； 接口：接口不能被实例化；一个类只能继承一个类，但是可以实现多个接口；接口中方法可以为抽象方法，java8后接口也可以定义静态方法，可以直接通过接口名.方法调用 10、静态变量、成员变量和局部变量的区别一、静态变量和成员变量的区别：(1)所属不同： 静态变量：属于类，也称为类变量。 成员变量：属于对象，也称为对象变量或实例变量。(2)在内存中的位置不同： 静态变量：存储于方法区/元空间。 成员变量：存储于堆内存。(3)生命周期不同： 静态变量：静态变量是随着类的加载而加载，随着类的消失而消失。 成员变量：成员变量是随着对象的创建而存在，随着对象的消失而消失。(4)调用不同： 静态变量：可以通过对象名调用，也可以通过类名调用。 成员变量：只能通过对象名调用。 二、成员变量和局部变量的区别：(1)在类中的位置不同： 成员变量：在类中方法外。 局部变量：在方法定义中或者方法声明上(即形参)。(2)在内存中的位置不同： 成员变量：在堆中。 局部变量：在栈中。(3)生命周期不同： 成员变量：随着对象的创建而存在，随着对象的消失而消失。 局部变量：随着方法的调用而存在，随着方法的调用完毕而消失。(4)初始化值不同： 成员变量：有默认值。 局部变量：没有默认值，必须定义，赋值，然后才能使用。 12、直接引用与符号引用符号引用：在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。 直接引用：直接引用可以是直接指向目标的指针 11、==与equals方法==：判断两个对象的地址是不是相等，即判断两个对象是不是同一个对象，基本数据类型比较的是值，引用数据类型比较的是内存地址 equals：若没有重写equals方法，则比较对象时，等价于“==”，若重写了equals，则等价于重写的相等的逻辑 public class Main{ public static void main(String[] args) { String a = new String(\"ab\"); // a 为⼀个引⽤ String b = new String(\"ab\"); // b为另⼀个引⽤,对象的内容⼀样 String aa = \"ab\"; // 放在常量池中 String bb = \"ab\"; // 从常量池中查找 //true，同一对象 System.out.println(aa==bb); //false，非同一对象 System.out.println(a == b); //String对equals方法进行了重写，a的值与b的值相等 System.out.println(a.equals(b))； }} 12、重写equals方法为什么要重写hashcode()equals方法在没有被重写前，比较的是对象的内存地址，而重写后，可能不是同一对象的equals方法也相等 hashcode的作用是为了获取hash码，定位哈希表中索引的位置，是一个基于内存地址的int整数，而当重写了equals方法后，即使equals方法相等，hashcode也极大概率不等，这时如果我们用重写了equals方法的object作为hash表的key，那么会造成一个从hash表中取值为null的现象，因此需要重写equals方法，使得两者保持一致性 13、java复制为什么说java只有值传递Java程序设计语言总是采用按值调用。也就是说，方法得到的是所有参数值的一个拷贝，方法不能修改传递给它的任何参数变量的内容。 值调用表示方法接收的是调用者提供的值，这种情况下方法引用的是该值的副本，在方法形成的栈中进行相关操作，而按引用调用表示方法接收的是被调用对象的地址的副本，对该副本的修改由于指向了原对象的地址，因此可以修改原对象的内容，但其本质仍然是操作副本，对副本进行的修改 浅拷贝对基本数据类型进行值传递；如果该字段是引用类型的话，则复制引用但不复制引用的对象 ，因此原始对象及其副本引用同一个对象 深拷贝对基本数据类型进行值传递；如果该字段是引用类型的话，则创建一个新的对象，并复制其内容，返回这个新的对象 14、final关键字修饰变量：如果是基本数据类型，则其数值一旦在初始化后就不能更改；如果是引用类型的变量，则对齐初始化后边不能再指向另一个对象 修饰类：表明这个类不能被继承 修饰方法：防止该方法被继承，private方法都隐式都指定为final 15、java异常体系 如果某个方法不能按照正常的途径完成任务，就可以通过另一种路径退出方法。在这种情况下会抛出一个封装了错误信息的对象。此时，这个方法会立刻退出同时不返回任何值。另外，调用这个方法的其他代码也无法继续执行，异常处理机制会将代码执行交给异常处理器 异常分类Error：类是指 java 运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果出现了这样的错误，除了告知用户，剩下的就是尽力使程序安全的终止。Exception（RuntimeException、 CheckedException）：RuntimeException 如 ： NullPointerException、ClassCastException； 一个是检查异常CheckedException，如 I/O 错误导致的 IOException、 SQLException。 处理方式抛出异常有三种形式，一是 throw,一个 throws，还有一种系统自动抛异常 ： throws 用在函数上，后面跟的是异常类，可以跟多个； 而 throw 用在函数内，后面跟的是异常对象 try-catchtry块：用于捕获异常，其后可跟0或多个catch块，如果没有catch块，则必须跟一个finally块 catch块：用于处理try捕获到的异常 finally块：无论是否捕获到或者处理了异常，finally块里的语句都会被执行,弱try或者catch语句有return语句时，finally中的语句会被执行，若有返回值会覆盖原始的返回值，如下例子，最终返回0 public static int f(int value) { try { return value * value; } finally { if (value == 2) { return 0; } }} 16、java语言的反射机制指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法；并且对于任意一个对象，都能够调用它的任意一个方法；这种动态获取信息以及动态调用对象方法的功能称为 Java 语言的反射机制 获取calss对象的三种方法//1、调用某个对象的getClass()方法： Person p=new Person(); Class clazz=p.getClass();//2、调用某个类的 class 属性来获取该类对应的 Class 对象：如 Class clazz=Person.class;//3、使用 Class 类中的 forName()静态方法(最安全/性能最好/最常用) ：如 Class clazz=Class.forName(\"类的全路径\"); 获取类方法属性信息//Field 类：Java.lang.reflec 包中的类，表示类的成员变量，可以用来获取和设置类之中的属性值Field[] field=clazz.getDeclaredFields(); for(Field f:field){ System.out.println(f.toString());}//Method 类：Java.lang.reflec 包中的类，表示类的方法，它可以用来获取类中的方法信息或者执行方法Method[] method=clazz.getDeclaredMethods();for(Method m:method){ System.out.println(m.toString()); }//Constructor 类：Java.lang.reflec 包中的类，表示类的构造方法Constructor[] constructor=clazz.getDeclaredConstructors(); for(Constructor c:constructor){ System.out.println(c.toString()); } 通过反射创建对象的方法//1、使用 Class 对象的 newInstance()方法来创建该 Class 对象对应类的实例，但是这种方法要求 该 Class 对象对应的类有默认的空构造器Person p=(Person) clazz.newInstance();//2、先使用 Class 对象获取指定的 Constructor 对象，再调用 Constructor 对象的 newInstance() 方法来创建 Class 对象对应类的实例Constructor c=clazz.getDeclaredConstructor(String.class,String.class,int.class);Person p1=(Person) c.newInstance(\"李四\",\"男\",20); 17、对象的序列化和反序列化序列化：把对象转换为字节序列的过程称为对象的序列化。保存(持久化)指定的对象，并在将来重新读取被保存的对象。 反序列化：把字节序列恢复为对象的过程称为对象的反序列化 对于不想序列化的变量，使用transient关键词修饰 18、java泛型泛型，即“参数化类型”。就是将类型由原来的具体的类型参数化 19、访问修饰符 类内部 本包 子类 外部包 public 可以 可以 可以 可以 protected 可以 可以 可以 不可以 default 可以 可以 不可以 不可以 private 可以 不可以 不可以 不可以 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"java基础","slug":"java基础","permalink":"https://xulilei.github.io/tags/java%E5%9F%BA%E7%A1%80/"}]},{"title":"秋招复习之多线程（二）","date":"2020-07-11T07:32:32.000Z","path":"2020/07/11/秋招复习之多线程2/","text":"秋招基础复习之多线程（二）AQSAQS（AbstractQueuedSynchronizer 类）是一个用来构建锁和同步器的框架，各种 Lock 包中的锁（常用的有 ReentrantLock、 ReadWriteLock，countdownlatch、cyclicbarrier）都是基于 AQS 来构建 AQS 工作原理AQS的核心思想是，如果被请求的资源空闲，则将当前请求的线程设置为工作线程，并将该资源设置为锁定状态。如果被请求的资源已经被占用，那么就需要一套线程阻塞等待以及唤醒时锁分配的机制，而这个机制是通过CLH队列锁实现的，即将分配不到锁的线程加入到队列中 CLH锁CLH队列是一个虚拟的双向队列，即不存在队列的实例，仅存在节点之间的关联关系，AQS将请求线程封装成CLH队列的一个Node节点，是一个FIFO的过程 AQS工作步骤AQS 在内部定义了一个 volatile int state 变量，表示同步状态：当线程调用 lock 方法时，会通过tryAcquire()独占该锁 ，如果 state=0，说明没有任何线程占有共享资源的锁，可以获得锁并将 state=1；如果 state不为0，先判断是否属于重入的情况，不是的话，则说明有线程目前正在使用共享变量，则该线程必须加入同步队列（CLH）的队尾进行等待，直到占有资源的线程通过tryRelease()对state进行减一操作释放锁到state=0，其他线程才能够去获取该锁。 AQS公平锁非公平锁 公平锁：在获取锁时，增加了一个当前线程是否为head结点的判断，当且仅当等待队列为空或者当前线程是等待队列的head结点时才会获取该锁 非公平锁：那些尝试获取锁且尚未进入等待队列的线程会和等待队列的head节点的线程发生竞争 AQS组件ReentrantLock与Synchronized 相比，可重入锁ReentrantLock其实现原理有什么不同？实现方式角度：synchronized操作Mark Word，lock调用AQS的state和FIFO队列来控制加锁 Synchronized 通过在对象头中设置标记实现了这一目的，是一种 JVM 原生的锁实现方式 而 ReentrantLock 以及所有的基于 Lock 接口的实现类，都是通过用一个 volitile 修饰的 int 型变量，并保证每个线程都能拥有对该 int 的可见性和原子修改， 其本质是基于 AQS 框架。 从锁释放角度 Synchronized 在 JVM 层面上实现的，不但可以通过一些监控工具监控 Synchronized 的锁定，而且在代码执行出现异常时，JVM 会自动释放锁定； Lock 是通过代码实现的，需要通过 unLock() 来释放锁 从功能角度，ReentrantLock 比 Synchronized 的同步操作更精细 如等待可中断：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，对处理执行时间非常长的同步块很有用。 带超时的获取锁尝试：在指定的时间范围内获取锁，如果时间到了仍然无法获取则返回。 可以判断是否有线程在排队等待获取锁，以及是否获取成功。 可以实现公平锁。 ReadWriteLock虽然 ReentrantLock 和 Synchronized 简单实用，但是行为上有一定局限性，要么不占，要么独占。实际应用场景中， 有时候不需要大量竞争的写操作，而是以并发读取为主，为了进一步优化并发操作的粒度，Java 提供了读写锁。 读写锁基于的原理是多个读操作不需要互斥，如果读锁试图锁定时，写锁是被某个线程持有，读锁将无法获得，而只好等待对方操作结束， 这样就可以自动保证不会读取到有争议的数据 CountDownLatch CyclicBarrierCyclicBarrier 叫循环栅栏，它实现让一组线程等待至某个状态之后再全部同时执行，而且当所有等待线程被释放后，CyclicBarrier 可以被重复使用。 SemaphoreSemaphore是一个计数信号量，它的本质是一个共享锁。 信号量维护了一个信号量许可集。线程可以通过调用acquire()来获取信号量的许可；当信号量中有可用的许可时，线程能获取该许可；否则线程必须等待，直到有可用的许可为止。 线程可以通过release()来释放它所持有的信号量许可。 线程池1：降低线程切换所带来的资源消耗 2：解耦作用：线程的创建于执行分开，方便维护 3：便于其他线程的复用 实现原理 在 Java 中，所谓的线程池中的“线程”，其实是被抽象为了一个静态内部类 Worker，它基于 AQS 实现，存放在线程池 的HashSet workers 成员变量中； 需要执行的任务则存放在BlockingQueue workQueue中。 这样，整个线程池实现的基本思想就是：从workQueue 中不断取出需要执行的任务，放在 Workers 中进行处理。 创建线程池阿里的开发手册不允许使用Executors去创建线程池，而是通过ThreadPoolExecutor ？通过Executors创建的线程池，通过内部构造方法生成的线程池的初始参数会导致OOM FixedThreadPool 和SingleThreadExecutor：初始化请求队列的长度为Integer.MAX_VALUE，可能会堆积大量请求，导致OOM CachedThreadPool和ScheduledThreadPool：允许创建线程池的数量为Integer.MAX_VALUE，可能会创建大量线程导致OOM ThreadPoolExecutor类分析常见参数corePoolSize：线程池的核心线程数。 在刚创建线程池时线程不会立即启动，到有任务提交时才开始创建线程并逐步线程数目达到corePoolSize maximumPoolSize：线程池允许的最大线程数。 当核心线程满，且阻塞队列也满时，才会判断当前线程数是否小于最大线程数，才决定是否创建新线程 keepAliveTime：超过核心线程数时闲置线程的存活时间。workQueue：任务执行前保存任务的队列，保存由 execute 方法提交的 Runnable 任务。handler：线程池允许的最大线程数。 线程池中的线程已经用完了，无法继续为新任务服务，等待队列也已经排满了，再也塞不下新任务了，这时候我们就需要拒绝策略机制合理的处理这个问题。 线程池种类SingleThreadExecutor 线程池 这个线程池只有一个核心线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束， 那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 FixedThreadPool 线程池 固定大小的线程池，只有核心线程。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。 线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 CachedThreadPool 线程池 无界线程池，如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60 秒不执行任务）线程， 当任务数增加时，此线程池又可以智能的添加新线程来处理任务。 ScheduledThreadPool 线程池 核心线程池固定，大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 ThreadPoolExecutor handler拒绝策略AbortPolicy ： 直接抛出异常，阻止系统正常运行 CallerRunsPolicy ： 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。 DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。 DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。 执行execute()⽅法和submit()方法的区别是什么呢？execute()：用于提交不需要返回值的任务，所以通常传入Runnable对象 submit()： 用于提交需要返回值的任务，线程池会返回一个Futrue类型的对象，通过get获取返回值，因此通常传入Callable对象 创建线程池过程 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务； 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列； 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务； 如果等待队列满了的同时，正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会执行拒绝策略。 当一个线程完成任务时，它会从队列中取下一个任务来执行。 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断。 如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。 ThreadLocalThreadLocal，线程本地存储， ThreadLocal 的作用是提供线程内的局部变量， 这种变量只在本线程的生命周期内起作用 实现原理ThreadLocal类中有一个静态内部类ThreadLocalMap，相当于一个哈希表，用private Entry[ ] table来存储数据，其中Entry是一个实现了弱引用（下次GC会被回收）的内部类，它的key为弱引用，目的是为了在GC时防止内存泄漏。而value是强引用，GC是会产生key为null，值为value无法回收的内存，造成内存泄露，ThreadLocalMap会在key回收时，自动清理掉key为null的记录 原子类以AtomicInteger为例 public final int get() //获取当前的值public final int getAndSet(int newValue)//获取当前的值，并设置新的值public final int getAndIncrement()//获取当前的值，并⾃增public final int getAndDecrement() //获取当前的值，并⾃减public final int getAndAdd(int delta) //获取当前的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输⼊的数值等于预期值，则以原⼦⽅式将该值设置为输⼊值（update） AtomicInteger原理AtomicInteger主要利用CAS+Volatile+Native方法来保证原子操作，通过本地方法objectFieldO!set()拿到原来值的内存地址，再拿到Volatile修饰的value，最后再通过CAS来进行最终更新值的操作，足以保证在任何时刻任何线程拿到的都是该变量的最新值 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"多线程","slug":"多线程","permalink":"https://xulilei.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"秋招复习之多线程（一）","date":"2020-07-10T07:16:32.000Z","path":"2020/07/10/秋招复习之多线程/","text":"秋招基础复习之多线程（一）线程线程和进程的区别？进程是系统资源分配的最小单位，线程是CPU调度的基本单位 线程不能看成独立应用，而进程可以 进程有独立的地址空间，相互不影响，而线程没有独立的地址空间，只是进程的不同执行路径 进程的切换开销比线程大 Java进程和线程的关系运行一个程序会产生一个进程，一个进程至少一个线程 每个进程对应一个JVM实例，多个线程共享JVM的堆 线程的状态(6种)初始(NEW)：新创建了一个线程对象，但还没有调用start()方法。 运行(RUNNABLE)：Java线程中将就绪（ready）和运行中（running）两种状态笼统的称为“运行”。 阻塞(BLOCKED)：表示线程阻塞于锁。 等待(WAITING)：进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断)不会被分配CPU执行时间，由Object.wait()和Thread.join()导致 超时等待(TIMED_WAITING)：该状态不同于WAITING，它可以在指定的时间后自行返回。 终止(TERMINATED)：表示该线程已经执行完毕 start和run方法的区别run()方法只是Thread的一个普通方法的调用，会继续使用当前线程执行该方法 start()方法会创建一个新的子线程并启动,start()方法会调用JVM的StartThread方法创建一个子线程，并且通过thread_entry方法取调用子线程中的run方法 Thread类和Runnable接口是什么关系?Thread是实现了Runnable接口的类，使得run支持多线程 因为类的单一继承性，推荐多使用Runnable接口 Runnable需要通过构造:Thread t = new Thread(new Runnable())启动 如何实现处理线程的返回值1：主线程等待法(缺点是需要自己实现循环的等待方法，变量多的话代码臃肿) 2：使用Thread类的join()阻塞当前线程以等待子线程处理完毕，缺点是不能更精细的处理，只能等待join()线程全部执行完毕 3：通过Callable接口实现：FutureTask和线程池获取 利用FutureTask获取: FutureTask&lt;&gt; task = new FutureTask&lt;&gt;(new MyCallable())，这里的MyCallable必须实现Callable接口,然后new Thread(task).start()开启新线程，调用task.get();可以或者返回值 利用线程池获取: ExecutorService newCachedThreadPool = Executors.newCachedThreadPool(); 然后调用线程池的提交方法Future future = newCachedThreadPool.submit(new MyCallable()); 返回一个Future，调用future.get()获取返回值 sleep()和wait()的区别sleep是Thread类的方法，wait是Object类中定义的方法，也是native中的方法 sleep()方法可以在任何地方使用，而wait()方法只能在synchionized方法或synchronized块中使用 最本质区别： Thread.sleep只会让出CPU，不会导致锁行为的改变 Object.wait()不仅让出CPU，还会释放已经占有的同步资源锁，并进入等待池中，不会再竞争锁，需要通过notify或者notifyAll()唤醒 锁池和等待池的区别锁池：假设某个线程想进入一个对象的synchronized方法，而这个对象锁却被其他线程所占有，该线程就会进入一个地方取等待锁的释放，这个地方就是锁池 等待池：假设线程A调用了某个对象的wait方法，线程A就会释放该对象的锁，同时进入该对象的等待池中，进入到等待池中的线程不会取竞争该对象的锁，除非被 notify唤醒 notify()和notifyAll()的区别 notify只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会 notifyAll会让所有处于等待池的线程全部进入锁池去竞争获取锁的机会 interrupt()调用interrupt()，通知线程应该中断了 1：如果线程处于被阻塞状态，那么线程将立即退出被阻塞状态，并且抛出一个InterruptedException异常。 2：如果线程处于正常活动状态，那么会将线程的中断标志设置为true，设置中断标志的线程将继续正常运行，不受影响,在运行任务时，我们已经经常检查本线程的中断标志位，如果被设置了中断标志，就自行停止线程 调用stop()，是让线程强制执行，已经不再推荐使用 死锁线程死锁和进程死锁线程死锁：线程A想要持有线程B持有的资源1，线程B想要持有线程A持有的资源2，互相等待，造成死锁 进程死锁的四大条件 互斥条件：即任意时刻，一个资源只能有一个线程持有 请求与保持：在一个线程请求资源而阻塞的时候，不会释放自己已经持有的资源 不可剥夺：线程已经获得的资源不能被其他线程强行剥夺，只能等待自己释放 循环等待：若干进程之间形成一种头尾相接的循环等待的关系 如何避免死锁破坏进程死锁的四大条件 互斥条件：这个做不到 请求与保持：一次性申请所有用到的资源，申请不到线程不工作 不可剥夺：申请其他资源时，如果一段时间申请不到则主动释放已持有的资源 循环等待：破坏循环等待 synchronized线程安全的主要诱因 1：存在共享数据（也成临界资源） 2：存在多条线程共同操作这些共享数据 解决线程安全问题的根本方法 同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再对共享数据进行操作 互斥锁的特性 互斥性：在同一时间只允许一个线程持有某个对象锁 可见性：必须确保在锁被释放之前，对共享变量所做的修改，对于随后获得该锁的另一线程是可见的 什么是可重入性 ，为什么说 Synchronized是可重入锁？ 从互斥性的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁时，将会处于阻塞状态，但当一个线程再次请求自己持有对象的锁时，这种情况属于重入。可重入性是锁的一个基本要求，如果不能够重入，会发生自己锁死自己的情况。 获取对象锁的两种用法 同步代码块，synchronized(this)，锁的是括号中的实例对象，代码块的外面，方法的里面还是异步的。 同步非静态方法（synchronized method），锁的是当前对象的实例对象，方法整个都是同步的，需要获得当前对象的锁 获取类锁的两种用法 同步代码块 synchronized(类.class) 锁的是小括号()中的类对象(Class对象) 同步静态方法 synchronized static method 锁的是当前对象的类对象(Class对象) 底层实现 Java对象在内存中由三部分组成，对象头，实例数据，对齐填充，其中对象头的是synchronized的核心，其中的Mark Word部分存储着锁信息，包括锁的类型，状态标志，通过在对象头设置标记，从而达到了获取锁和释放锁的目的 monitor:每个java对象天生自带了一把看不见的锁,就是monitor锁，在java虚拟机中，monitor是由ObjectMonitor(在JVM中由C++)实现的，查看JVM中ObjectMonitor源码，里面有一个count_计数器 sychronized方法：生成的字节码文件中会多一个ACC_SYNCHRONIZED标志位，当一个线程访问方法时，会先取检查是否存在ACC_SYNCHRONIZED标志，如果存在，执行线程将先获取monitor，获取成功后才能执行方法体，方法执行完后再释放monitor。方法执行期间，其他任何线程都无法再获得同一个monitor对象 synchronized代码块：加了synchronized关键字的代码段，生成的字节码文件中会多出monitorenter和monitorexit两条指令，每个monitor维护着一个记录着次数的计数器_count，未被拥有的monitor的该计数器为0，当一个线程执行monitorenter指令，当前线程试图获取对象锁，如果此时的monitor的count计数器为0，线程成功获得monitor，计算器加1，当同一个线程执行了monitorexit指令，计算器减1，当计算器为0时，monitor便被释放. JDK6以后对于synchronized的优化自旋锁和自适应自旋锁 许多情况下，共享数据的锁定状态持续时间较短，切换线程不值得，通过让线程执行忙循环等待锁的释放，不让出CPU、 缺点：若锁被其他线程长时间占用，会带来许多性能上的开销 自适应自旋锁：自旋的次数不再固定，由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定 锁消除 如果某个锁不可能被其他线程引用，比如局部变量，由于栈私有，JVM会自动消除内部对象的锁 锁粗化 如果检测到一连串的操作都是对同一个对象加锁，JVM会将锁的范围粗化到这一连串操作的外部 synchronized锁的四种状态以及升级过程过程 无锁–偏向锁–轻量级锁–重量级锁 偏向锁: 如果一个线程获得了锁，那么锁就进入偏向模式，Mark Word结构也变为了偏向锁结构，当该线程再次请求锁时，只需要检查Mark Word的锁标记位为偏向锁以及当前线程的ID等于Mark Work 的ThreadID即可。 不适用于锁竞争比较激烈的多线程场合 轻量级锁 轻量级锁由偏向锁升级来的，当第二个线程加入锁的争用时，偏向锁会升级为轻量级锁 每个线程都有自己的栈针，会在栈针中生成一个LockRecord指针，通过CAS去争夺这个锁，LR修改成功的线程获得该锁，而另一个线程会自动进入循环CAS获取这个锁的过程，该过程被称为自旋，因此轻量级锁也被称为自旋锁 重量级锁 轻量级锁自旋锁由于一直处于循环CAS的过程，会占据一定量的系统资源，自JDK6后JVM会自适应控制自选次数，当自选次数超过该阈值，则会自动升级为重量级锁。 升级成重量级锁后，会形成一个队列，没有竞争到锁的线程会进入该队列，且不消耗系统资源 三种锁的优缺点以及使用场景 偏向锁的优缺点以及使用场景 优点：加锁和解锁不需要CAS操作，没有额外的性能消耗，和非同步方法相比性能差距较小 缺点：如果线程间存在锁竞争，会带来额外的锁撤销的消耗 使用场景：只有一个线程访问同步块或者同步方法 轻量级锁的优缺点以及使用场景 优点：竞争的线程不会阻塞，提高了响应速度 缺点：若线程长时间抢不到锁，自旋会消耗CPU性能 使用场景：线程交替执行同步块或者同步方法的场景 重量级锁的优缺点以及使用场景 优点：线程竞争不适用自旋，不会消耗CPU 缺点：线程阻塞，相应时间缓慢，在多线程下，频繁的获取释放锁，会带来巨大的性能消耗 使用场景：追求吞吐量，同步块或同步方法执行时间较长的场景 Volatile指令重排序指令重排序是编译器和处理器为了高效对程序进行优化的手段，它只能保证程序执行的结果时正确的，但是无法保证程序的操作顺序与代码顺序一致。这在单线程中不会构成问题，但是在多线程中就会出现问题。 指令重排序需要满足的条件 在单线程环境下不能改变程序运行的结果 不存在数据依赖关系的 不满足happens-before原则 Java内存模型JMM JMM中的主内存（main memory） 存储Java实例对象 包括成员变量，类信息，常量，静态变量 属于数据共享的区域，多线程并发操作会引发线程安全问题 JMM中的工作内存（L1,L2,L3） 存储当前方法的局部变量信息，局部变量对其他线程不可见 字节码行号指示器，Native方法信息 属于线程私有的数据区域，不存在线程安全问题 读写过程 将主存中的数据加载到工作内存中 CPU对工作内存中的数据进行修改 将每个线程工作内存中修改后的值刷新到主内存中 Volatile原理关键字 volatile 是 Java 虚拟机提供的最轻量级的同步机制。当一个变量被定义成 volatile 之后，具备两种特性： 1.保证此变量对所有线程的可见性。当一条线程修改了这个变量的值，新值对于其他线程是可以立即得知的。 2.禁止指令重排序。普通变量仅仅能保证在该方法执行过程中，得到正确结果，但是不保证程序代码的执行顺序。 如何实现上述两种特性？ 线程可见性：主要通过缓存一致性协议和总线锁两种方式实现 立即将线程中工作内存的数据写会到主内存中 其他处理器数据监测判断自己线程工作区内存中的值是不是过期了，如果过期了，就会将对应的数据置为无效。而当处理器对这个数据进行修改时，会重新从内存中把数据读取到缓存中进行处理。 禁止指令重排序： 代码级别：对变量加上volatile修饰 字节码级别：会生成ACC_volatile指令 JVM级别：通过JVM的内存屏障禁止内存屏障前后的指令执行重排序优化 DCL单例模式需不需要volatile指令？需要，因为在new一个对象的过程中对象并不是刚被创建就会将构造函数中的参数赋值给变量，而是会有一个半初始化的状态，此时如果发生指令重排序会使得别的线程拿到这个半初始化的对象，造成BUG，因此需要双重检测（对象创建的过程见https://xulilei.github.io/2020/07/06/%E7%A7%8B%E6%8B%9B%E5%A4%8D%E4%B9%A0%E4%B9%8BJVM/） //单例模式public class Singleton{ private Volatile static Singleton instance; private Singleton(){}; public static Singleton getInstance(){ //第一次检测 if(instance==null){ synchronized(Singleton.class){ //第二次检测 if(instance==null){ instance=new Singleton(); } } } return instance; }} Syncronized和volatile对比 volatile本质是告诉JVM当前变量在工作内存中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住直到该线程完成变量操作为止。 volatile仅能使用在变量上；synchronized则可以使用在变量，方法和类级别 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞 volatile仅能实现变量的修改的可见性，不能保持原子性；而synchronized则可以保证变量修改的可见性和原子性 CAS 实现过程 底层通过Unsafe类实现原子性操作，包括三个操作数——内存地址V，预期原值A和新值B 将内存地址的值与预期原值进行比较，如果匹配，那么处理器将该位置的值，自动更新为新值，否则会进行自旋，然后再重新以当前的值为原值再次比较，这也是自旋锁实现的基础 乐观锁悲观锁 悲观锁Syncronized：是典型的悲观锁，总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。 乐观锁CAS：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据 CAS缺点（乐观锁的缺点） 如果自旋时间长，则CPU资源开销很大 只能保证一个共享变量的原子操作 ABA问题 如果内存地址V初次读取的值为A，并且在准备赋值的时候检查到也为A，如果它曾经被改为了B，但是后来又被改成了A，那么CAS就会误认为它从来没被改变过 解决：给值加上一个版本号每当修改一次将值加1，或者使用AtomicStampedReference（ 版本戳） document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"多线程","slug":"多线程","permalink":"https://xulilei.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"秋招复习之集合","date":"2020-07-08T04:59:33.000Z","path":"2020/07/08/秋招复习之集合/","text":"秋招基础复习之集合 集合类存放于 Java.util 包中， 主要有 3 种： set(集）、 list(列表包含 Queue）和 map(映射)。Collection： Collection 是集合 List、 Set、 Queue 的最基本的接口。Iterator：迭代器，可以通过迭代器遍历集合中的数据。Map：是映射表的基础接口 。 Collection对比 ListArrayList（数组，线程不安全）ArrayList 是最常用的 List 实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数组的缺点是每个元素之间不能有间隔， 当数组大小不满足时需要增加存储能力，就要将已经有数组的数据复制到新的存储空间（1.5倍扩容）中。 当从 ArrayList 的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。 Vector（ 数组，线程安全）Vector 与 ArrayList 一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写 Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问 ArrayList 慢。 LinkList（链表，线程不安全）LinkedList 是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较慢。 SetHashSet（Hash表）哈希表边存放的是哈希值。 HashSet 存储元素的顺序并不是按照存入时的顺序（和 List 显然不同） 而是按照哈希值来存的所以取数据也是按照哈希值取得。元素的哈希值是通过元素的hashcode 方法来获取的, HashSet 首先判断两个元素的哈希值，如果哈希值一样，接着会比较equals 方法 如果 equls 结果为 true ， HashSet 就视为同一个元素。如果 equals 为 false 就不是同一个元素。HashSet 通过 hashCode 值来确定元素在内存中的位置。 一个 hashCode 位置上可以存放多个元素。 TreeSet（二叉树）TreeSet()是使用二叉树的原理对新添加的对象按照指定的顺序排序（升序、降序），每增加一个对象都会进行排序，将对象插入的二叉树指定的位置。Integer 和 String 对象都可以进行默认的 TreeSet 排序，而自定义类的对象是不可以的， 自己定义的类必须实现 Comparable 接口，才可以正常使用。 LinkHashSet（ HashSet+LinkedHashMap）对于 LinkedHashSet 而言，它继承与 HashSet、又基于 LinkedHashMap 来实现的。由于底层使用 LinkedHashMap 来保存所有元素 ，因此可以通过双向链表来记录插入的顺序 Map HashMap底层实现JDK1.7实现数组+链表 HashMap 的主干是一个数组，然后数组中每个元素是一个单向链表。上图中，每个绿色的实体是嵌套类 Entry 的实例， Entry 包含四个属性： key, value, hash 值和用于单向链表的 next。 //默认大小static final int DEFAULT_INITIAL_CAPACITY = 16;//最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//默认负载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;//存储元素的数组transient Entry[] table;//键值对数量transient int size;//阈值，size大于阈值触发扩容int threshold;//负载因子默认是0.75final float loadFactor;//修改次数transient volatile int modCount; Put的过程public V put(K key, V value) { //容器为空时，调用初始化方法，找到大于threshold的最小二次幂数 if (table == EMPTY_TABLE) { inflateTable(threshold); } //键为空则存放入数组第0个元素，如果之前有key为null的元素，则新元素将旧元素替换返回，否则创建新的元素并返回null，来看一下创建新元素的逻辑： if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); //弱key存在，则用新value覆盖oldvalue，并返回覆盖后的值 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(hash, key, value, i); return null;} 主要实现方法 //addEntry过程 void addEntry(int hash, K key, V value, int bucketIndex) { if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) { resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex); }//在数组下标为bucketIndex的位置创建节点，并将之前的头结点作为新结点的next结点，实现了链表头部插入元素，这样做的好处很明显，节省了插入的效率 void createEntry(int hash, K key, V value, int bucketIndex) { Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++; } //h（hash）与数组长度-1进行按位与操作，这个操作就保证了插入元素一定是在数组内部 static int indexFor(int h, int length) { // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return h &amp; (length-1); } resize过程 void resize(int newCapacity){ Entry[] oldTable = table; int oldCapacity = oldTable.length; ...... //创建一个新的Hash Table Entry[] newTable = new Entry[newCapacity]; //将Old Hash Table上的数据迁移到New Hash Table上 transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);}//resize()方法中的transfer()，采用头插法 void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) { while(null != e) { Entry&lt;K,V&gt; next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } } } 造成死循环的原因在扩容的过程中，将原来hashMap数组中的链表转移到新的hashmap中时，采用的是头插法进行指针操作，会将原hashmap的链表顺序反转，但如果此时再进来一个线程，会导致next指针指向一个环，形成死循环 JDK1.8实现数组+链表+红黑树，当链表中的元素超过了 8 个以后，会将链表转换为红黑树 put过程public V put(K key, V value) { return putVal(hash(key), key, value, false, true); }final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //初始化时，map中还没有key-value if ((tab = table) == null || (n = tab.length) == 0) //利用resize生成对应的tab[]数组 n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) //当前桶无元素 tab[i] = newNode(hash, key, value, null); else {//桶内有元素 Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //桶内第一个元素的key等于待放入的key，用 e = p; else if (p instanceof TreeNode) //如果此时桶内已经树化 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else {//桶内还是一个链表，则插入链尾（尾插） for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //变成红黑树 treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } //检查是否应该扩容 ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; } 示意图 resize过程采用尾插法，容量扩充为原来的两倍，再对每个节点重新计算hash值 HashMap面试问题总结1、为什么hashmap的长度是2的幂次方？首先不可能直接用散列化后的值直接作为数组下标，而是需要对长度进行取模运算，再得到下标。这个数组下标的计算方法为（n-1）&amp;hash。之所以使用与操作是因为与操作的性能优于取余。而当length是2的幂次方时，hash%length==hash&amp;（length-1），因此长度是2的幂次方。 2、hashmap1.7与1.8的区别(1)结构不同，1.7采用数组+链表，1.8采用数组+链表+红黑树 (2)插入位置不同，JDK1.7用的是头插法，而JDK1.8及之后使用的都是尾插法，因为JDK1.7是用单链表进行的纵向延伸，当采用头插法时可以避免遍历链表造成的性能损失，但是会容易出现逆序及多线程下环形链表死循环问题。但是在JDK1.8之后因为加入了红黑树使用尾插法，插入效率提升，且能够避免出现逆序和链表死循环的情况 (3)扩容数据存储位置的计算方式不一样，1.7通过扰动之后的hash&amp;（length-1）得到数组下标，1.8在扩容中只用判断原来的 hash 值与数组长度左移动的一位(扩大一倍)按位与操作是 0 或 1 就行，0 的话索引就不变，1 的话索引变成原索引加上扩容前数组 (4)扩容时数据的插入时机，1.7是先扩容后插入，1.8是先插入后扩容 3、为什么HashMap是线程不安全的，实际会如何体现第一，如果多个线程同时使用put方法添加元素:假设正好存在两个put的key发生了碰撞(hash值一样)，那么根据HashMap的实现，这两个key会添加到数组的同一个位置，这样最终就会发生其中一个线程的put的数据被覆盖 第二、hashmap1.7在扩容时，由于采取头插法会导致死循环 ConCurrentHashMap底层实现hashTable实现 JDK1.7实现首先将数据分为一段一段的存储，然后给每一段分配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据仍然能够被访问 JDK1.8实现1.8的ConcurrentHashMap取消了分段锁，采用CAS和syncronized来保证并发安全，syncronized只锁定一个node链表的首节点 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"集合","slug":"集合","permalink":"https://xulilei.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"秋招复习之JVM","date":"2020-07-06T07:07:16.000Z","path":"2020/07/06/秋招复习之JVM/","text":"秋招基础复习之JVMJVM内存模型 JVM-GC垃圾回收知识点概览 判断对象可回收引用计数法（JVM中不用）给对象添加一个计数器，每当有一个地方引用计数器+1，反之失效-1，当计数器为0的时候，则代表该对象不太可能会被继续用到，则判断该对象为可回收对象，但是会出现循环引用的问题 可达性分析算法为了解决引用计数法的循环引用问题， Java 使用了可达性分析的方法。通过一系列的“GC roots”对象作为起点搜索。如果在“GC roots”和一个对象之间没有可达路径，则称该对象是不可达的。 GC roots：类加载器，Thread，虚拟机栈的局部变量表，static成员，本地方法栈等 强软弱虚引用强引用在 Java 中最常见的就是强引用， 把一个对象赋给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它处于可达状态，它是不可能被垃圾回收机制回收的，即使该对象以后永远都不会被用到 JVM 也不会回收。因此强引用是造成 Java 内存泄漏的主要原因之一。 软引用软引用需要用 SoftReference 类来实现，对于只有软引用的对象来说，当系统内存足够时它不会被回收，当系统内存空间不足时它会被回收。软引用通常用在对内存敏感的程序中。 弱引用弱引用需要用 WeakReference 类来实现，它比软引用的生存期更短，对于只有弱引用的对象来说，只要垃圾回收机制一运行，不管 JVM 的内存空间是否足够，总会回收该对象占用的内存。 虚引用不能单独使用，必须和引用队列联合使用。 虚引用的主要作用是跟踪对象被垃圾回收的状态。 垃圾收集算法分代收集算法新生代的复制算法eden、survivorFrom SurvicorTo按照8比1比1划分新生代 1：eden、 survivorFrom 复制到 SurvivorTo，年龄+1首先，把 Eden 和 survivorFrom 区域中存活的对象复制到 SurvivorTo 区域（如果有对象的年龄以及达到了老年的标准15，则赋值到老年代区），同时把这些对象的年龄+1（如果 SurvivorTo 不够位置了就放到老年区）； 2：清空 eden、 survivorFrom然后，清空 Eden 和 survivorFrom 中的对象 3： SurvivorTo和 ServicorFrom 互换最后， SurvivorTo 和 survivorFrom互换，原 SurvivorTo 成为下一次 GC 时的 survivorFrom区。 老年代的标记-整理算法首先扫描一次所有老年代，标记出存活的对象，让所有存活对象都向一端移动，然后直接清理掉端边界以外的内存 分区收集算法分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的好处是可以控制一次回收多少个小区间 , 根据目标停顿时间, 每次合理地回收若干个小区间(而不是整个堆), 从而减少一次 GC 所产生的停顿。 垃圾收集器 新生代Serial：单线程收集器，采用复制算法它不但只会使用一个 CPU 或一条线程去完成垃圾收集工作，并且在进行垃圾收集的同时，必须暂停其他所有的工作线程，直到垃圾收集结束。它简单高效，对于限定单个 CPU 环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此 Serial垃圾收集器依然是 java 虚拟机运行在 Client 模式下默认的新生代垃圾收集器。 Parnew：serial收集器的多线程版本，采用复制算法除了使用多线程进行垃圾收集之外，其余的行为和 Serial 收集器完全一样， ParNew 垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程，ParNew垃圾收集器是很多 java虚拟机运行在 Server 模式下新生代的默认垃圾收集 Parallel Scavenge：复制算法，可控制吞吐量的收集器该收集器关注的重点在吞吐量，对用户等待的时间不那么关注，因而适用于在后台运算而不需要太多交互的任务 老年代Serial Old：serial收集器的老年代版本，使用标记-整理算法工作时会暂停用户线程 Parallel Old：Parallel Scavenge收集器的老年代版本，多线程，标记-整理算法工作时会暂停用户线程 CMS：采用标记-清除算法由于耗时最长的并发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作， 所以总体上来看CMS 收集器的内存回收和用户线程是一起并发地执行。 第一步-初始标记只是标记一下 GC Roots 能直接关联的对象，速度很快，仍然需要暂停所有的工作线程。 第二步-并发标记进行 GC Roots 跟踪的过程，和用户线程一起工作，不需要暂停工作线程 第三步-重新标记为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。 第四步-并发清除清除 GC Roots 不可达对象，和用户线程一起工作，不需要暂停工作线程。 Garbage first： 分区收集以及采用标记-整理算法基于标记-整理算法，不产生内存碎片。可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。 G1 收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间， 优先回收垃圾最多的区域。区域划分和优先级区域回收机制，确保 G1 收集器可以在有限时间获得最高的垃圾收集效率。 JVM类加载机制类加载过程 加载加载是类加载过程中的一个阶段， 这个阶段会在内存中生成一个代表这个类的 java.lang.Class 对象 验证这一阶段的主要目的是为了确保 Class 文件的字节流中包含的信息语法符合当前虚拟机的要求 准备准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。 解析解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。 符号引用符号引用就是 class 文件中的： CONSTANT_Class_info、 CONSTANT_Field_info、 CONSTANT_Method_info 等类型的常量，在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。 直接引用直接引用可以是指向目标的指针。如果有了直接引用，那引用的目标必定已经在内存中存在 初始化初始化阶段是类加载最后一个阶段，前面的类加载阶段由 JVM 主导。到了初始化阶段，才开始真正执行类中定义的 Java 程序代码 类加载器类加载器的种类 启动类加载器(Bootstrap ClassLoader)：负责加载核心库java.*，由C++编写。 扩展类加载器(Extension ClassLoader)：负责加载扩展库，由java编写。 应用程序类加载器(Application ClassLoader)：负责加载程序所在目录，java编写。 以及自定义加载器。 双亲委派机制与全盘委派机制1、双亲委派机制：先自下而上的委托父类加载目标类，只有当父类加载器反馈自己无法完成这个请求的时候，子类加载器会自上而下的会尝试自己去加载 2、全盘委派机制：该类所依赖的类都由该类的类加载器加载 类加载方式new 隐式加载，支持传参，loadclass与forname显式加载，不支持传参。springioc可以懒加载 对象创建的步骤区别于类加载的过程1、虚拟机遇到new命令时，首先检查这个对应的类能否在常量池定位到一个符号引用 2、判断这个类是否已经被加载解析（解析让符号引用变成直接引用）和初始化，如果没有则进行相应的类加载过程 3、为新生对象在java堆中分配内存空间，这一步是半初始化（单例的双重检测机制就是为了防止半初始化） 4、设置对象头相关数据（GC分代年龄、对象的哈希吗、锁等元数据信息）–java对象模型 5、执行init方法，赋值 对象分配流程1、首先尝试栈上分配，即如果该对象的作用域不会逃逸出该方法之外，则可以将其分配在栈上，随着方法的结束而销毁，不用通过GC收集 2、若失败则采用tlab分配，会先构造一种线程私有的堆空间，哪怕这块堆空间特别小，但是只要有，就可以每个线程在分配对象到堆空间时，先分配到自己所属的那一块堆空间中，避免同步带来的效率问题，从而提高分配效率 3、若还是失败，则正常的分配至eden区，若太大则直接进入老年代 JVM核心参数-Xms：最小堆 -Xmx：最大堆 -Xmn：新生代内存 -Xss：栈大小 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"JVM","slug":"JVM","permalink":"https://xulilei.github.io/tags/JVM/"}]},{"title":"秋招复习之计网","date":"2020-07-05T07:39:30.000Z","path":"2020/07/05/秋招复习之计网/","text":"秋招基础复习之计网7 层模型主要包括： 物理层：设备之间的比特流传输。 数据链路层：主要将从物理层接收的数据进行 MAC 地址（网卡的地址）的封装与解封装。在这一层工作的设备是交换机，数据通过交换机来传输。 主要协议为ARP协议，提供IP 地址到对应的硬件地址提供动态映射 网络层：主要将从下层接收到的数据进行 IP 地址（例 192.168.0.1)的封装与解封装。在这一层工作的设备是路由器，常把这一层的数据叫做数据包。 传输层：定义了一些传输数据的协议和端口号（WWW 端口 80 等），如：TCP，UDP协议。 主要是将从下层接收的数据进行分段进行传输，到达目的地址后在进行重组。 常常把这一层数据叫做段。 会话层：通过传输层（端口号：传输端口与接收端口）建立数据传输的通路。主要在你的系统之间发起会话或或者接受会话请求（设备之间需要互相认识可以是IP也可以是 MAC 或者是主机名） 表示层：主要是进行对接收的数据进行解释、加密与解密、压缩与解压缩等（也就是把计算机能够 识别的东西转换成人能够能识别的东西（如图片、声音等）） 应用层：主要是一些终端的应用，比如说FTP（各种文件下载），WEB（IE浏览），QQ之类的（你 就把它理解成我们在电脑屏幕上可以看到的东西．就 是终端应用）。 TCP/IP协议TCP三次握手四次挥手三次握手 过程第一次握手：主机 A 发送位码为 syn＝1,随机产生seq序列号的数据包到服务器，第二次握手：主机B收到请求后要确认联机信息，同样向A发送syn=1，以及确认请求ACK=1，B的seq序列号，以及A的序列号+1的确认号，第三次握手：主机A收到后检查返回的确认号是否正确以及确认请求ACK是否为1，若正确，主机A会再发送确认请求ACK=1以及服务器B的序列号+1的确认号，主机B收到后确认确认序列号值与确认请求 Ack=1 则连接建立成功。 为什么要三次握手？即为什么A还要发送一次确认请求给服务器B，这是为了防止已经失效的连接请求突然又传送到了B。存在这样的一种情况，当A发送连接请求给B，此时由于网络拥堵造成服务器B没有及时收到连接请求，因此A又重新发送了一个请求给B，正常建立连接后，拥堵的第一次请求又传送到了服务器B，如果不采用三次握手，那么B又会发送确认连接的请求给B，又会建立一个新的连接，会浪费许多资源 syn攻击在第一次握手后，服务器向客户端发送确认请求信息后需要等待客户端的再次确认信息，如果此时客户端掉线，服务器会一直尝试发送5次请求信息，会浪费大量资源，可能导致正常的syn请求无法完成。 那么如何防护呢？ 当syn队列满后，通过tcp_syncookies参数回发syn_cookie给客户端，如果正常连接，客户端会回发这个syn_cookie给服务器，此时即使syn队列满了，依然可以正常建立连接 建立连接后客户端出现问题怎么办？服务器会发送保持会话报文，若一直没有响应一定次数，服务器会中断此次会话 四次挥手 过程首先由客户端发送一个FIN=1，以及seq=a的请求码给服务器，此时客户端进入等待关闭状态1，服务器收到客户端的关闭请求后，会立即发送一个确认关闭的ACK=1，以及a+1的确认码，和seq=b的序列号给客户端，告诉客户端我收到你关闭的请求了，客户端收到请求后会进入等待关闭状态2，当服务器传送玩最后的数据给客户端后，会发送一个确认关闭FIN=1，确认请求ACK=1确认序列a+1的确认号给客户端，意思是我传送玩所有的数据了，你可以关闭了。客户端在收到服务器第二次关闭请求后回回发最终确认ACK=1，以及第二次的确认序列+1的确认号给服务器，服务器收到后关闭连接，客户端在2MSL时间后关闭连接。 为什么要四次挥手？因为TCP是全双工的，客户端给服务器发送信息的同时，服务器也可以给客户端发送，之所以需要四次挥手，是因为在客户端发送结束请求后，可能服务器的数据还没有传输完毕，因此需要2个等待关闭的状态确保所有数据传输完毕，因此需要四次挥手 为什么客户端还要等待2msl？因为服务器给客户端发送的第二次FIN请求后，客户端回发给服务器的最终确认可能丢失，如果服务器没有收到最终确认，则会再次发送FIN请求给客户端，那么在客户端等待关闭的这2MSL里再次收到请求后，会再次发送最终请求，使得服务器能够正常准确的关闭 如何理解IP协议的不可靠和无连接？不可靠：指的是不能保证数据报能成功地到达目的地。 发生错误时候，丢弃该数据包，发送 ICMP 消息给信源端，可靠性由上层提供。 无状态：IP 不维护关于后续数据报的状态信息。 体现在，IP 数据可以不按顺序发送和接收。A 发送连续的数据报，到达B不一定是连续的， 来回路由选择可能不一样，路线也不一样，到达先后顺序也不一样。 TCP如何保证可靠性？1） 确认机制，发送报文后，等待确认。 2） 重发机制，没有收到确认，将重发数据段。 3） 拥塞控制：慢启动（逐渐增大窗口）、快速重传（收到失序报文立刻重传）、快速恢复（收到重复确认可能没有拥堵，因此不执行慢启动而是快速恢复）、拥塞避免（门限设为一般后开始慢启动算法） 4） 排序，有专门的序列号字段 5） 流量控制，通过滑动窗口实现 TCP与UDP区别 tcp对应的协议有：FTP、HTTP udp对应的协议有：DNS HTTP协议http请求报文和响应报文http请求报文由请求行（get/post方法，url的path路径，http版本）、请求头（键值对）、请求体（body） get/post区别1、get请求是通过URL传参，而post请求被放在请求体中，因此决定了get不能代替post发送大量数据 2、get请求的安全性不如post，是由于get请求在url中会被看到 3、get请求是幂等的，post不幂等（幂等就是多次操作结果一样，get查询多次肯定一样，post是改肯定不一样） http响应报文由状态码（Status Code）、HTTP头部（编码格式，过期时间）、响应体（响应的内容） 状态码1XX：请求已接受一部分，正等待剩余部分 2XX：正常接收 3XX：重定向，进一步操作 4XX：客户端请求出错 5XX：服务端出错 http请求过程1、DNS域名解析器解析出IP地址 2、TCP连接（三次握手） 3、浏览器发送HTTP请求 4、服务器处理请求并返回HTTP响应 5、浏览器解析渲染页面 6、释放连接（四次挥手） http长连接，短连接，无状态，HTTP/1.0，HTTP/1.1，HTTP/2.0无状态无状态：HTTP 协议是无状态的，指的是协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。也就是说，打开一个服务器上的网页和上一次打开这个服务器上的网 页之间没有任何联系。HTTP 是一个无状态的面向连接的协议，无状态不代表 HTTP 不能保 持 TCP 连接，更不能代表 HTTP 使用的是 UDP 协议（无连接）。 长短连接HTTP/1.0 短连接：客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。适用于而像 WEB 网站的http服务 HTTP/1.1 默认使用长连接：在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据 的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。适用于于操作频繁，点对点的通讯，而且连接数不能太多情况。 HTTP/1.1和HTTP/2.0区别1.1管道传输与HTTP/1.1使用管道传输，即客户端与服务器建立连接后不用每次等待服务器响应就可发送新的请求，但是服务器仍然会顺序响应。如果某一请求出现问题，那么后面的请求都无法加载，这就会出现队头阻塞的问题。 在HTTP/2.0中通过多路复用解决了这个问题，即将一个TCP连接分为若干个流（Stream），每个流中可以传输若干消息（Message），这样即使一个请求被阻塞了，也不会影响其他请求 头部数据压缩在HTTP1.1中，消息主体都会经过gzip压缩，但状态行和头部却没有经过任何压缩，直接以纯文本传输。 HTTP2.0对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。 传输格式2.0采用二进制格式而非文本格式 HTTP和HTTPS的区别1、HTTP是超文本传输协议，是明文传输，而HTTPS则是具有安全协议SSL的加密传输 2、http是无状态的，而https是有可以进行加密传输，身份认证的 cookie和session的区别1、cookie 是一种发送到客户浏览器的文本串句柄，并保存在客户机硬盘上，可以用来在 某个 WEB 站点会话间持久的保持数据 2、session 其实指的就是访问者从到达某个特定主页到离开为止的那段时间。 Session 其 实是利用 Cookie 进行信息处理的，当用户首先进行了请求后，服务端就在用户浏览器 上创建了一个 Cookie，当这个 Session 结束时，其实就是意味着这个 Cookie 就过期 了 3、cookie 数据保存在客户端只能存储string类型的对象，session 数据保存在服务器端，可以存储任意类型的对象 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xulilei.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"十次方微服务复习","date":"2020-07-01T08:17:02.000Z","path":"2020/07/01/十次方微服务复习/","text":"利用SpringDataJPA完成问答、文章、招聘、交友、吐槽、用户、管理员的增删改以及模糊分页查询1、IdWorker：采用推特开源的雪花算法工具类，每秒能产生26W的id，而不产生id碰撞 SpringDataJpa用法：Dao层接口继承JpaRepository,JpaSpecifationExecutor（复杂查询使用）接口 模糊分页查询 实现条件查询： ​ 3种方式 ：一种是通过在dao层通过nativeQuery编写模糊查询语句，第二种是在dao层通过findBy**Like 另一种通过service层new Specification构造动态查询语句 public List&lt;Label&gt; findSearch(Label label) { return labelDao.findAll(new Specification&lt;Label&gt;() { @Override public Predicate toPredicate(Root&lt;Label&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; list=new ArrayList&lt;&gt;(); //相当于 ****** where labelname like \"%label.getLabelname()%\" if(label.getLabelname()!=null&amp;&amp;!\"\".equals(label.getLabelname())){ //通过root拿到字段名 Predicate predicate = cb.like(root.get(\"labelname\").as(String.class), \"%\" + label.getLabelname() + \"%\"); //一个条件，添加到cb中 list.add(predicate); } //将条件链表转化为数组 Predicate[] parr=new Predicate[list.size()]; list.toArray(parr); //合并所有条件，一起查询 return cb.and(parr); }); } 实现分页查询 dao层构建查询方法时传入pageable对象 service层调用JPA封装的方法时传入page和size，通过PageRequest生成Pgeable对象，service层返回Page对象 controller调用service方法，并通过之前定义好的分页类，返回给前端 //dao层public Page&lt;Label&gt; findAll(Pagealbe pageable){}//service层public Page&lt;Label&gt; findAll(int page,int size){ Pageable pageable=PageRequest.of(page-1,size); return labelDao.findAll(pageable);}//controller@RequestMapping(value = \"/{page}/{size}\",method = RequestMethod.GET) public Result findAll(@PathVariable int page,@PathVariable int size){ Page&lt;Label&gt; all = labelService.findAll(page,size); return new Result(true, StatusCode.OK,\"查询成功\",new PageResult&lt;&gt;(all.getTotalElements(),all.getContent())); }//pageResult类public class PageResult&lt;T&gt; { private long total; private List&lt;T&gt; rows; public long getTotal() { return total; } public void setTotal(long total) { this.total = total; } public List&lt;T&gt; getRows() { return rows; } public void setRows(List&lt;T&gt; rows) { this.rows = rows; } public PageResult() { } public PageResult(long total, List&lt;T&gt; rows) { this.total = total; this.rows = rows; }} 问答模块主要业务主要包含两个个表问题表，回答表 问题表包含：问题id，问题标题，内容，发布日期，最新回复时间、最新回复人，发布人id，点赞数，是否解决 回答表包含：回答id，问题id，回答内容，回答日期，回答人id等 完成的主要业务有 1、最新回答列表：最新回复的问题显示在上方， 按回复时间降序排序 2、热门回答列表：按回复数降序排序 3、等待回答列表： 回复数为0按时间升序排序 在问题展示，会将每个问题的回复通过分页查询的形式返回给前端 招聘模块主要业务招聘微服务主要有两块：企业信息和招聘信息 企业表包含：id，name，summary，address，ishot等字段 招聘信息表包含：jobid，jobname，salary，企业id，发布日期，截止日期，状态（0表关闭，1表开启，2表推荐），关注人数等字段 完成的主要业务有 1、展示热门企业列表（通过findByIshot查询） 2、推荐职业列表（通过findTop4ByStateOrderByCreatetimeDesc：查询状态为2并以创建日期降序排序，查询前4条记录） 3、最新职位列表（findTop12ByStateNotOrderByCreatetimeDesc：查询状态不为0并以创建日期降序排序，查询前12条记录） 文章模块主要业务文章表包含：文章id，类别，用户id，文章标题，内容，发布日期，审核状态（0，1），点赞数，是否热门等 完成的主要业务有 1、管理员审核文章：状态改为1 2、用户对文章进行评论 3、通过springdataredis对热门文章缓存,可设置缓存时间 public Article findById(String id) { //先从缓存中查询当前对象 Article article= (Article) redisTemplate.opsForValue().get(\"article_\"+id); //如果没有渠道 if(article==null){ article = articleDao.findById(id).get(); //如果热门存入缓存 if(article.getIshot()==1){ redisTemplate.opsForValue().set(\"article_\"+id,article); } } return article;} 4、利用Elasticsearch和ik分词器完成文章的搜索功能，利用logstash同步mysql至elasticsearch //创建新的实体类，这里只需要一些必须的字段@Document(indexName = \"articleindex\",type = \"article\")public class Article implements Serializable { @Id private String id; //@Field注解作用 //是否能被搜索到 //是否分词，整体匹配还是分词匹配 //是否在页面上显示，即数据库中在该实体类中的字段，就是要显示的 //analyzer,分词 //searchAnalyzer，搜索 @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String title; @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String content; public String getId() { return id; } public void setId(String id) { this.id = id; } public String getTitle() { return title; } public void setTitle(String title) { this.title = title; } public String getContent() { return content; } public void setContent(String content) { this.content = content; }}//dao层public interface ArticleDao extends ElasticsearchRepository&lt;Article,String&gt; { public Page&lt;Article&gt; findByTitleOrContentLike(String title, String content, Pageable pageable);}//service层 public Page&lt;Article&gt; findByKey(String key, int page, int size) { Pageable pageable= PageRequest.of(page-1,size); return articleDao.findByTitleOrContentLike(key,key,pageable); }//controller层@RequestMapping(value = \"/{key}/{page}/{size}\",method = RequestMethod.GET) public Result findByKey(@PathVariable String key,@PathVariable int page,@PathVariable int size){ Page&lt;Article&gt;pageData=articleService.findByKey(key,page,size); return new Result(true,StatusCode.OK,\"搜索成功\",new PageResult&lt;Article&gt;(pageData.getTotalElements(),pageData.getContent())); } 吐槽模块吐槽表：_id，内容content，发布时间，用户id，点赞数，上级吐槽id 使用springdataMongoDB完成的主要业务有 1、发布吐槽，如果是在别人下面吐槽需要将上级吐槽回复数加1 if(spit.getParentid()!=null&amp;&amp;!\"\".equals(spit.getParentid())){//表示是在别人下面回复 Query query=new Query(); query.addCriteria(Criteria.where(\"_id\").is(spit.getParentid())); Update update=new Update(); update.inc(\"thumbup\",1); mongoTemplate.updateFirst(query,update,\"spit\");} 2、根据上级id查询吐槽列表 3、吐槽点赞，并通过redis使其不能重复点赞 //使用mongoDB原生方式实现自增public void thumbUp(String id){ //方式一,与数据库多次交互性能较低 //Spit spit=spitDao.findById(id).get(); //spit.setThumbup((spit.getThumbup()==null?0:spit.getThumbup())+1); //spitDao.save(spit); //相当于使用原生mongo命令实现自增：db.spit.update({\"_id\":\"1\"},{$inc:{thumbup:NumberInt(1)}}) Query query=new Query(); query.addCriteria(Criteria.where(\"_id\").is(\"id\")); Update update=new Update(); update.inc(\"thumbup\",1); mongoTemplate.updateFirst(query,update,\"spit\"); }@RequestMapping(value = \"/thumbup/{spitId}\",method = RequestMethod.PUT)public Result thumbUp(@PathVariable String spitId){ //由于没有做登陆认证，因此暂时写死ID，实现一个用户只能点赞一次 String userid=\"111\"; if(redisTemplate.opsForValue().get(\"thumbup_\"+userid)!=null){ return new Result(false,StatusCode.REPERROR,\"不能重复点赞\"); }; spitService.thumbUp(spitId); redisTemplate.opsForValue().set(\"thumbup_\"+userid,1); return new Result(true,StatusCode.OK,\"点赞成功\");} 管理员模块管理员登陆，JWT鉴权，在完成鉴权后通过feign可以操作其他模块的业务 1、在招聘模块对关注人数超过一定值的招聘信息可以设置为推荐，删除超过截止日期的招聘信息 2、手动设置热门企业 3、对用户进行管理 4、审核为通过审核文章，删除违规的文章 用户中心模块用户登陆，JWT鉴权，在完成鉴权后通过feign可以操作其他模块的业务 完成的主要业务有 1、用户注册：本地生成6位验证码，redis缓存一份，向rabbitmq发送一份，在处理短信的模块中，监听mq的短信队列拿到想换验证码和手机号，通过阿里云的短信API实现发送短信的功能（处理短信的模块是自动完成的，只需向mq发送相关信息即可） 2、用户登录：通过spring security的BCryptPasswordEncoder实现密码的加密解密，完成用户登录，登录成功通过JWT向用户发送token，以后请求服务需要在头信息中添加token信息 交友模块分为好友表和非好友表 好友表包含：用户id，朋友id，islike（0表单向喜欢，1表双向喜欢） 非好友表包含：用户id，朋友id 完成的业务： 1、当A点击喜欢B，好友表增加记录，非好友表删除A不喜欢B，当B喜欢A，修改islike为1 2、当A点击拉黑B，非好友表增加记录，好友表删除A-B的记录，若B喜欢A，则修改为单向喜欢 3、于此同时，A喜欢B，A的关注数加1，B的粉丝数加1 public int addFriend(String userid, String friendid) { //先判断userid到friendid是否有数据，有就是重复添加好友，返回0 Friend friend=friendDao.findByUseridAndFriendid(userid,friendid); if(friend!=null){ return 0; } //再判断以前是否不喜欢 if(noFriendDao.findByUseridAndFriendid(userid, friendid)!=null){ noFriendDao.deleteByUseridAndFriendid(userid,friendid); } //直接添加好友，让好友表中的userid到friendid方向的type为0 friend=new Friend(); friend.setUserid(userid); friend.setFriendid(friendid); friend.setIslike(\"0\"); friendDao.save(friend); //再判断friendid到userid是否有数据，如果有则把双方的状态都改为1 if(friendDao.findByUseridAndFriendid(friendid,userid)!=null){ //把双方islike都改为1 friendDao.updateIslike(\"1\",userid,friendid); friendDao.updateIslike(\"1\",friendid,userid); }; return 1;}public int addNoFriend(String userid,String friendid) { //先判断是否已经是非好友 NoFriend noFriend=noFriendDao.findByUseridAndFriendid(userid, friendid); if(noFriend!=null){ return 0; } //如果之前是好友，现在单方面删除 if(friendDao.findByUseridAndFriendid(userid,friendid)!=null){ friendDao.deleteByUseridAndFriendid(userid,friendid); if(friendDao.findByUseridAndFriendid(friendid,userid)!=null) friendDao.updateIslike(\"0\",friendid,userid); } //删完再添加到noFriend表 noFriend=new NoFriend(); noFriend.setUserid(userid); noFriend.setFriendid(friendid); noFriendDao.save(noFriend); return 1; } 完成项目的微服务化 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[]},{"title":"使用jekins完成项目部署于Docker容器","date":"2020-06-30T07:52:28.000Z","path":"2020/06/30/使用jekins完成项目部署/","text":"使用jekins完成项目部署于Docker容器创建Docker私有仓库创建私有仓库容器拉去镜像，创建容器docker pull registrydocker run ‐di ‐‐name=registry ‐p 5000:5000 registry 打开浏览器 输入地址http://192.168.xxx.xxx:5000/v2/_catalog 看到 {“repositories”:[]} 表示私有仓库搭建成功并且内容为空 修改daemon.json让docker信任私有仓库 vi /etc/docker/daemon.json{\"insecure‐registries\":[\"192.168.xxx.xxx:5000\"]} maven插件自动部署修改宿主机docker配置使其可以远程访问vi /lib/systemd/system/docker.service其中ExecStart=后添加配置 ‐H tcp://0.0.0.0:2375 ‐H unix:///var/run/docker.sock 发布的项目pom文件引入插件&lt;build&gt; &lt;finalName&gt;tensquare_config&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!--docker的maven插件，官网： https://github.com/spotify/docker‐maven‐plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;!--上传私有仓库--&gt; &lt;imageName&gt;192.168.152.xx:5000/${project.artifactId}:${project.version}&lt;/imageName&gt; &lt;!--基础镜像，意味着docker容器中已经存在jdk8的镜像--&gt; &lt;baseImage&gt;jdk8&lt;/baseImage&gt; &lt;!--打包命令--&gt; &lt;entryPoint&gt;[\"java\", \"-jar\", \"/${project.build.finalName}.jar\"]&lt;/entryPoint&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory} &lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;dockerHost&gt;http://192.168.152.xx:2375&lt;/dockerHost&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 进入该工程所在目录执行命令mvn clean package docker:build -DpushImage 代码管理服务gogs安装gogsdocker pull gogs/gogsdocker run -d --name=gogs -p 10022:22 -p 3000:3000 -v /var/gogsdata:/data gogs/gogs 配置gogs在地址栏输入http://192.168.xxx.xxx:3000 会进入首次运行安装程序页面，我们可以选择一种数据库作为gogs数据的存储，最简单的是选择SQLite3。如果对于规模较大的公司，可以选择MySQL 页面展示idea上传至gogs仓库 jekins持续继承配置jekins下载安装完后需要配置用户和端口号JENKINS_USER=\"root\"JENKINS_PORT=\"8888\" 首次进入，安装插件主要的插件有两个一个是maven一个是git 全局工具配置服务器安装maven，JDK JDK配置git配置（一般服务器都已经安装）maven配置持续继承创建一个maven项目 源码管理选gitURL填写gogs仓库的地址 Buildpom要填写生成容器的子项目 执行任务 结果展示docker镜像 私有仓库 运行后可以成功展示！ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"jekins","slug":"jekins","permalink":"https://xulilei.github.io/tags/jekins/"},{"name":"gogs","slug":"gogs","permalink":"https://xulilei.github.io/tags/gogs/"}]},{"title":"集中配置组件SpringCloudConfig","date":"2020-06-26T07:58:27.000Z","path":"2020/06/26/集中配置组件SpringCloudConfig/","text":"集中配置组件SpringCloudConfigSpring Cloud Config简介在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所 以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库 中。在spring cloud config 组件中，分两个角色，一是config server，二是config client。 config server它用于集中管理应用程序各个 环境下的配置，默认使用Git存储配置文件内容 导入config-server依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 启动类添加@EnableConfigServer@SpringBootApplication@EnableConfigServerpublic class ConfigApplication { public static void main(String[] args) { SpringApplication.run(ConfigApplication.class); }} 修改配置文件这里如果uri使用的是http，则会出现不能clone仓库内容的错误，因此要换成ssh，并添加private-key，该配置文件不需要上传至云端 server: port: 12000spring: application: name: tensquare-config rabbitmq: host: 192.168.152.** cloud: config: server: git: uri: git@gitee.com:***/tensquare.git ignore-local-ssh-settings: true private-key: | -----BEGIN RSA PRIVATE KEY----- MIIEowIBAAKCAQEAxawgOKaig29oj/OqSVY9njJMnIYmedq4A7wvKEpg3Q/wYRl0 DO1QOl13ilyj20MyXUEUKON4dKWoBl+2/zhTtyI5cCDhcnISYAp9JSkYSzm8DTDp E+1Zwmq2yYE68mr5/UaRbhOHBPGr1GwrTNuraqnOtNDjUXm25E4HiCmHoc395RpA -----END RSA PRIVATE KEY----- config clientConfig Client是Config Server的客户端，用于操作存储在Config Server中的配置内容。 微服务在启动时会请求Config Server获取配置文件的内容，请求到后再启动容器。 导入config client依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 上传配置文件application.yml至gitee文件命名规则： {application}-{profile}.yml或{application}-{profile}.properties 其中application为应用名称，profile指的开发环境（用于区分开发环境，测试环境、生产环境等） 更换配置文件为bootstrap.ymlspring: cloud: config: #这个对应gitee配置文件的命名规则 name: base profile: dev label: master uri: http://127.0.0.1:12000 消息总线组件SpringCloudBusSpringCloudBus简介当云端修改配置文件后，本地不用修改和再次编译，只需向消息中间件发送一条修改提醒即可使得配置文件即时生效 配置服务端config-server导入SpringCloudBus和rabbitmq依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-bus&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 修改配置文件spring: rabbitmq: host: 192.168.152.128#暴露触发消息总线的地址，management: endpoints: web: exposure: include: bus-refresh 配置客户端功能子模块导入依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-bus&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 云端配置文件添加rabbitmq地址rabbitmq: host: 192.168.184. document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"SpringCloudConfig","slug":"SpringCloudConfig","permalink":"https://xulilei.github.io/tags/SpringCloudConfig/"}]},{"title":"微服务网关Zuul","date":"2020-06-26T07:40:35.000Z","path":"2020/06/26/微服务网关Zuul/","text":"微服务网关Zuul相关概念为什么使用网关不同的微服务一般有不同的网络地址，而外部的客户端可能需要调用多个服务的接口才 能完成一个业务需求。 如果客户端直接和微服务进行通信，会存在一下问题： 1、客户端会多次请求不同微服务，增加客户端的复杂性 2、存在跨域请求，在一定场景下处理相对复杂 3、认证复杂，每一个服务都需要独立认证 上述问题，都可以借助微服务网关解决。微服务网关是介于客户端和服务器端之间的中间层，所有的外部请求都会先经过微服务网关。 什么是zuulZuul是Netflix开源的微服务网关，他可以和Eureka,Ribbon,Hystrix等组件配合使用。 Zuul组件的核心是一系列的过滤器，这些过滤器可以完成以下功能： 1、身份认证和安全: 识别每一个资源的验证要求，并拒绝那些不符的请求 2、动态路由：动态将请求路由到不同后端集群 Zuul使用网关模块导入相关依赖zuul是依赖eureka实现的，通过微服务的name在eureka的服务器上寻找到对应的路径 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt; 配置application,ymlserver: port: 9011spring: application: name: tensquare-managereureka: client: service-url: defaultZone: http://127.0.0.1:6868/eureka/ instance: prefer‐ip‐address: truezuul: routes: tensquare-base: path: /base/** serviceId: tensquare-base tensquare-user: path: /user/** serviceId: tensquare-user tensquare-qa: path: /qa/** serviceId: tensquare-qa 修改启动类@SpringBootApplication@EnableEurekaClient@EnableZuulProxypublic class ManagerApplication { public static void main(String[] args) { SpringApplication.run(ManagerApplication.class); } @Bean public JwtUtil jwtUtil(){ return new JwtUtil(); }} 实例：通过ZuulFilter实现身份验证功能创建Filter类继承ZuulFilter，并实现其中的方法，具体细节请看注释 @Componentpublic class ManagerFilter extends ZuulFilter { @Autowired private JwtUtil jwtUtil; //过滤器类型 //“pre”执行之前，“post”执行时 @Override public String filterType() { return \"pre\"; } //排序，0表示优先执行 @Override public int filterOrder() { return 0; } //表示当前过滤器是否开启，true为开启 @Override public boolean shouldFilter() { return true; } //过滤器内执行的操作，return任何object表示继续执行， //setSendZullResponse(false)表示不再继续执行 @Override public Object run() throws ZuulException { //通过com.netflix.zuul得到request上下文 RequestContext currentContext =RequestContext.getCurrentContext(); //得到request域 HttpServletRequest request = currentContext.getRequest(); // 第一次转发始终放行，因为是根据配置文件中的路径去找其他服务 if(request.getMethod().equals(\"OPTIONS\")){ return null; } //登陆放行 if(request.getRequestURI().indexOf(\"login\")&gt;0){ return null; } //得到头信息 String header = request.getHeader(\"Authorization\"); if(header!=null&amp;&amp;!\"\".equals(header)){ if(header.startsWith(\"Bearer \")){ String token=header.substring(7); try { Claims claims = jwtUtil.parseJWT(token); String role= (String) claims.get(\"roles\"); if(role.equals(\"admin\")){ //把头信息继续往下传 currentContext.addZuulRequestHeader(\"Authorization\",header); return null; } }catch (Exception e){ //终止运行 currentContext.setSendZuulResponse(false); } } } //header为空返回错误信息 currentContext.setSendZuulResponse(false); currentContext.setResponseStatusCode(403); return null; }} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"zuul","slug":"zuul","permalink":"https://xulilei.github.io/tags/zuul/"}]},{"title":"Hystrix入门","date":"2020-06-25T13:58:25.000Z","path":"2020/06/25/Hystrix“入门/","text":"Hystrix熔断器相关概念为什么要使用熔断器在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障， 进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。而熔断器的产生，则有效规避了雪崩效应 熔断器工作机制当服务的某个API接口的失败次数在一定时间内小于设定的阈值时，熔断器处于关闭状态，该API接口正常提供服务。当该API接口处理请求的失败次数大于设定的阈值时，Hystrix判定该API接口出现了故障，打开熔断器，这时该API接口会执行快速失败的逻辑，不执行业务逻辑，请求的线程不会处于阻塞状态。处于打开状态的熔断器在一定时间后会处于半打开状态，并将一定数量的请求执行正常逻辑，剩余的请求会执行快速失败。若执行正常逻辑的请求失败了，则熔断器继续打开，若成功了，则熔断器关闭。这样熔断器就具有了自我修复的功能。 使用配置文件开启hystrix支持Feign本身支持Hystrix，因此不需要导入额外依赖 feign: hystrix: enabled: true 创建实现feign接口的实现类在声明式接口中的@FeignClient注解上添加fallback属性来配置快速失败的处理类。该处理类作为Feign熔断器的逻辑处理类，必须实现被@FeignClient修饰的接口 @FeignClient(value = \"tensquare-base\",fallback = BaseClientImpl.class)public interface BaseClient { @RequestMapping(value = \"/label/{labelId}\",method = RequestMethod.GET) public Result findById(@PathVariable(\"labelId\") String labelId);}@Componentpublic class BaseClientImpl implements BaseClient { @Override public Result findById(String labelId) { return new Result(false, StatusCode.ERROR,\"失败\"); }} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"Hystrix","slug":"Hystrix","permalink":"https://xulilei.github.io/tags/Hystrix/"}]},{"title":"SpringCloud架构模型","date":"2020-06-25T13:54:19.000Z","path":"2020/06/25/cloud常见模块/","text":"Spring Cloud架构模型 服务发现组件EurekaEureka是Netflix开发的服务发现框架，SpringCloud将它集成在自己的子项目spring-cloud-netflix中，实现SpringCloud的服务发现功能。Eureka包含两个组件：Eureka Server和Eureka Client。 Eureka Server提供服务注册服务，各个节点启动后，会在Eureka Server中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到。 详见：https://xulilei.github.io/2020/06/21/eureka%E5%85%A5%E9%97%A8/ 服务间调用Feignfeign是声明式的web service客户端，它让微服务之间的调用变得更简单了，类似controller调用service。Spring Cloud集成了Ribbon和Eureka，可在使用Feign时提供负载均衡的http客户端 详见：https://xulilei.github.io/2020/06/21/eureka%E5%85%A5%E9%97%A8/ 熔断器Hystrix在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障， 进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。而熔断器的产生，则有效规避了雪崩效应 当服务的某个API接口的失败次数在一定时间内小于设定的阈值时，熔断器处于关闭状态，该API接口正常提供服务。当该API接口处理请求的失败次数大于设定的阈值时，Hystrix判定该API接口出现了故障，打开熔断器，这时该API接口会执行快速失败的逻辑，不执行业务逻辑，请求的线程不会处于阻塞状态。处于打开状态的熔断器在一定时间后会处于半打开状态，并将一定数量的请求执行正常逻辑，剩余的请求会执行快速失败。若执行正常逻辑的请求失败了，则熔断器继续打开，若成功了，则熔断器关闭。这样熔断器就具有了自我修复的功能。 详见：","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://xulilei.github.io/tags/SpringCloud/"}]},{"title":"daySeven-eureka","date":"2020-06-21T15:04:08.000Z","path":"2020/06/21/十次方daySeven/","text":"交友服务搭建主要业务添加喜欢业务逻辑有两张表分别为tb_friend和tb_nofriend，当A添加喜欢B，先在tb_friend表中查询有无数据，如果有则代表已经添加喜欢了，回复不可重复添加，然后在tb_nofriend中查询是否之前A不喜欢B，如果有记录，则删除该记录。并在tb_friend中添加一条从A-B的记录，且状态为0，代表单向喜欢。如果在添加记录时，恰哈发现B-A已经有数据了，那么则将二者的状态都改为1，代表双向喜欢 业务实现，service层public int addFriend(String userid, String friendid) { //先判断userid到friendid是否有数据，有就是重复添加好友，返回0 Friend friend=friendDao.findByUseridAndFriendid(userid,friendid); if(friend!=null){ return 0; } //再判断以前是否不喜欢 if(noFriendDao.findByUseridAndFriendid(userid, friendid)!=null){ noFriendDao.deleteByUseridAndFriendid(userid,friendid); } //直接添加好友，让好友表中的userid到friendid方向的type为0 friend=new Friend(); friend.setUserid(userid); friend.setFriendid(friendid); friend.setIslike(\"0\"); friendDao.save(friend); //再判断friendid到userid是否有数据，如果有则把双方的状态都改为1 if(friendDao.findByUseridAndFriendid(friendid,userid)!=null){ //把双方islike都改为1 friendDao.updateIslike(\"1\",userid,friendid); friendDao.updateIslike(\"1\",friendid,userid); }; return 1;} 添加不喜欢业务逻辑当A添加B为不喜欢，首先查询tb_nofriend中是否已经有数据，如果有则提示不可重复拉黑。然后再去tb_friend中查询是否有A-B的喜欢，如果有则删除该记录，同时查询B-A是否也有记录，有则代表之前是双向喜欢，此时应将B-A的状态改为0，最后在tb_nofriend中添加一行A-B数据。 业务实现，service层public int addNoFriend(String userid,String friendid) { //先判断是否已经是非好友 NoFriend noFriend=noFriendDao.findByUseridAndFriendid(userid, friendid); if(noFriend!=null){ return 0; } //如果之前是好友，现在单方面删除 if(friendDao.findByUseridAndFriendid(userid,friendid)!=null){ friendDao.deleteByUseridAndFriendid(userid,friendid); //如果之前双向喜欢，则改为单向喜欢 if(friendDao.findByUseridAndFriendid(friendid,userid)!=null) friendDao.updateIslike(\"0\",friendid,userid); } //删完再添加到noFriend表 noFriend=new NoFriend(); noFriend.setUserid(userid); noFriend.setFriendid(friendid); noFriendDao.save(noFriend); return 1;} 上述功能用到的Dao层FriendDaopublic interface FriendDao extends JpaRepository&lt;Friend,String&gt; { public Friend findByUseridAndFriendid(String userid,String friendid); @Modifying @Query(value =\"update tb_friend SET islike=? where userid=? and friendid=?\",nativeQuery = true) public void updateIslike(String islike,String userid,String friendid); public void deleteByUseridAndFriendid(String userid,String friendid);} NoFriendDaopublic interface NoFriendDao extends JpaRepository&lt;NoFriend,String&gt; { public NoFriend findByUseridAndFriendid(String userid, String friendid); public void deleteByUseridAndFriendid(String userid,String friendid);} feign调用user模块业务业务逻辑当A添加B为喜欢时，在tb_user表中，userA的关注数+1，B的粉丝数+1。当A添加B为不喜欢时，userA的关注数-1，B的粉丝数-1。 User模块中粉丝关注业务实现Dao层public interface UserDao extends JpaRepository&lt;User,String&gt;,JpaSpecificationExecutor&lt;User&gt;{ @Modifying @Query(value =\"update tb_user set fanscout=fanscount+? where id=?\" ,nativeQuery = true) public void updateFans(int x, String friendid); @Modifying @Query(value =\"update tb_user set followcount=followcount+? where id=?\" ,nativeQuery = true) public void updateFollows(int x, String userid);} Service层@Transactionalpublic void updateFansAndFollowCounts(int x, String userid, String friendid) { //friendB粉丝数+1，userA的关注数+1 userDao.updateFans(x,friendid); userDao.updateFollows(x,userid);} Controller层//不返回result是因为这个业务是服务之间的调用，不涉及前台@RequestMapping(value = \"/{userid}/{friendid}/x\",method = RequestMethod.PUT)public void updateFansAndFollowCounts(@PathVariable int x,@PathVariable String userid,@PathVariable String friendid){ userService.updateFansAndFollowCounts(x,userid,friendid);} 交友模块中调用上述业务启动类添加相应注解@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@EnableFeignClientspublic class FriendApplication { public static void main(String[] args) { SpringApplication.run(FriendApplication.class); }} 创建client@FeignClient(\"tensquare-user\")public interface UserClient { @RequestMapping(value = \"/user/{userid}/{friendid}/x\",method = RequestMethod.PUT) public void updateFansAndFollowCounts (@PathVariable(\"x\") int x, @PathVariable(\"userid\") String userid, @PathVariable(\"friendid\") String friendid);} controller层调用//添加喜欢if(flag==1){ userClient.updateFansAndFollowCounts(1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\");}//添加不喜欢if(flag==1){ userClient.updateFansAndFollowCounts(-1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\");} 交友服务controller层整合@RequestMapping(value = \"/like/{friendid}/{type}\",method = RequestMethod.PUT )public Result addFriend(@PathVariable String friendid,@PathVariable String type){ //验证是否登陆，并拿到ID Claims claims = (Claims) request.getAttribute(\"user_claims\"); if(claims==null){ return new Result(false, StatusCode.LOGINERROR,\"权限不足\"); } String userid = claims.getId(); System.out.println(userid); //判断是添加好友还是非好友，直接传进来一个类型type，当type为1时，表示添加，2时表示拉黑 if(type!=null){ if(type.equals(\"1\")){ int flag=friendService.addFriend(userid,friendid); if(flag==0){ return new Result(false, StatusCode.ERROR,\"不能重复添加好友\"); } if(flag==1){ //后文介绍的添加粉丝与关注 userClient.updateFansAndFollowCounts(1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\"); } //添加好友 }else if(type.equals(\"2\")) { //添加黑名单 int flag= friendService.addNoFriend(userid,friendid); if(flag==0){ return new Result(false, StatusCode.ERROR,\"不能重复拉黑好友\"); } if(flag==1){ //后文介绍的减少粉丝与关注 userClient.updateFansAndFollowCounts(-1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\"); } } } return new Result(false, StatusCode.ERROR,\"参数异常\");} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"Eureka","slug":"Eureka","permalink":"https://xulilei.github.io/tags/Eureka/"},{"name":"交友业务","slug":"交友业务","permalink":"https://xulilei.github.io/tags/%E4%BA%A4%E5%8F%8B%E4%B8%9A%E5%8A%A1/"}]},{"title":"eureka入门","date":"2020-06-21T07:50:02.000Z","path":"2020/06/21/eureka入门/","text":"服务发现组件Eureka相关概念Eureka简介Eureka是Netflix开发的服务发现框架，SpringCloud将它集成在自己的子项目spring-cloud-netflix中，实现SpringCloud的服务发现功能。Eureka包含两个组件：Eureka Server和Eureka Client。 Eureka ServerEureka Server提供服务注册服务，各个节点启动后，会在Eureka Server中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到。 服务端开发第一步，在父工程中锁定版本，每一个版本的springboot都对应一个版本的springcloud &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.M9&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 第二步，Eureka子模块添加eureka-server &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 第三步，添加application.yml server: port: 6868eureka: client: register-with-eureka: false #是否将自己注册到Eureka服务中，本身就是所有无需注册 fetch-registry: false service-url: #Eureka客户端与Eureka服务端进行交互的地址 defaultZone: http://127.0.0.1:${server.port}/eureka/ 第四步，启动类 @SpringBootApplication@EnableEurekaServerpublic class EurekaServer { public static void main(String[] args) { SpringApplication.run(EurekaServer.class); }} Eureka ClientEureka Client是一个java客户端，用于简化与Eureka Server的交互，客户端同时也 就别一个内置的、使用轮询(round-robin)负载算法的负载均衡器。 客户端开发第一步，客户端模块添加eureka-client &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 第二步，修改每个微服务的application.yml，添加注册eureka服务的配置 eureka: client: service-url: defaultZone: http://127.0.0.1:6868/eureka/ instance: prefer‐ip‐address: true #跨域 第三步，启动类 @SpringBootApplication@EnableEurekaClient public class UserApplication { public static void main(String[] args) { SpringApplication.run(UserApplication.class, args); }} Feign实现服务间的调用谁调用别人就在谁的模块中搭建环境第一步，添加openfeign依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 第二步，启动类@SpringBootApplication@EnableEurekaClient//Eureka客户端@EnableDiscoveryClient//可以发现服务@EnableFeignClients//通过feign调用其他服务的业务public class QaApplication { public static void main(String[] args) { SpringApplication.run(QaApplication.class, args); }} 第三步，创建client包，创建要调用目标的接口默认采用的是ribbon的轮询负载均衡算法 //调用目标的名字，注意这里不能使用下划线，这也是其他模块的application.yml中名字不加下划线的原因@FeignClient(\"tensquare-base\")//调用目标controller层的方法public interface BaseClient { @RequestMapping(value = \"/label/{labelId}\",method = RequestMethod.GET) //这里的 @PathVariable 后面要加上具体的参数名称(\"labelId\")不然会找不到 public Result findById(@PathVariable(\"labelId\") String labelId);} 相关实践详见：https://xulilei.github.io/2020/06/21/%E5%8D%81%E6%AC%A1%E6%96%B9daySeven/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"eureka","slug":"eureka","permalink":"https://xulilei.github.io/tags/eureka/"}]},{"title":"daySix-JWT-BCryptPasswordEncoder","date":"2020-06-18T02:27:02.000Z","path":"2020/06/18/十次方daySix/","text":"管理员登陆验证与删除鉴权 利用Spring Security的BCryptPasswordEncoder与JWT实现 登陆验证签发tokenservice层public Admin login(Admin admin) { //想根据用户名查询对象 Admin adminLogin=adminDao.findByLoginname(admin.getLoginname()); //然后拿数据库中的密码和用户输入的密码匹配是否相同 if(adminLogin!=null&amp;&amp;encoder.matches(admin.getPassword(),adminLogin.getPassword())){ return adminLogin; } //登陆失败 return null;} controller层@RequestMapping(value = \"/login\",method = RequestMethod.POST)public Result login(@RequestBody Admin admin){ Admin adminLoginResult=adminService.login(admin); if(adminLoginResult==null){ return new Result(false,StatusCode.LOGINERROR,\"登陆失败\"); } //做一系列前后端通话的工作，用JWT来实现 //生成token并返回给客户端 String token=jwtUtil.createJWT(adminLoginResult.getId(),adminLoginResult.getLoginname(),\"admin\"); Map&lt;String,Object&gt;map=new HashMap&lt;&gt;(); map.put(\"token\",token); map.put(\"role\",\"admin\"); return new Result(true,StatusCode.OK,\"登陆成功\",map);} 返回给前端的token 利用拦截器解析token拦截器只是为了将请求头中的token解析成user和admin解析后将气保存在域对象中，等需要鉴权时，直接通过获取这个域对象的值来分别是user还是admin @Componentpublic class JwtInterceptor implements HandlerInterceptor { @Autowired private JwtUtil jwtUtil; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //无论如何都放行，具体能不能操作要在具体的操作中去判断 //拦截器只是负责把请求头中包含的token令牌解析成user和admin String header=request.getHeader(\"Authorization\"); if(header!=null&amp;&amp;header.startsWith(\"Bearer \")){ String token=header.substring(7); try { Claims claims = jwtUtil.parseJWT(token); if(claims!=null){ if(\"admin\".equals(claims.get(\"roles\"))){ request.setAttribute(\"admin_claims\",token); } if(\"user\".equals(claims.get(\"roles\"))){ request.setAttribute(\"user_claims\",token); } } }catch (Exception e){ //过期 throw new RuntimeException(\"token错误\"); } } return true; }} 注册拦截器当然不用拦截登陆请求了 @Configurationpublic class InterceptorConfig extends WebMvcConfigurationSupport { @Autowired private JwtInterceptor jwtInterceptor; @Override protected void addInterceptors(InterceptorRegistry registry) { //注册拦截器要声明的拦截器对象和要拦截的请求 registry.addInterceptor(jwtInterceptor) .addPathPatterns(\"/**\") .excludePathPatterns(\"/**/login\"); }} 管理员删除用户直接从域对象中获取admin_claims，如果有则说明该登陆用户为管理员，则可以删除用户，否则提示权限不足 @Autowired private HttpServletRequest request;public void deleteById(String id) { String token = (String) request.getAttribute(\"admin_claims\"); if(token==null||\"\".equals(token)){ throw new RuntimeException(\"权限不足\"); } userDao.deleteById(id);} 当header中的token无法解析时 当header中的token正确时 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"Spring Security","slug":"Spring-Security","permalink":"https://xulilei.github.io/tags/Spring-Security/"},{"name":"BCryptPasswordEncoder","slug":"BCryptPasswordEncoder","permalink":"https://xulilei.github.io/tags/BCryptPasswordEncoder/"},{"name":"JWT","slug":"JWT","permalink":"https://xulilei.github.io/tags/JWT/"},{"name":"鉴权","slug":"鉴权","permalink":"https://xulilei.github.io/tags/%E9%89%B4%E6%9D%83/"},{"name":"密码加密","slug":"密码加密","permalink":"https://xulilei.github.io/tags/%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86/"}]},{"title":"Spring Security加密与JWT鉴权","date":"2020-06-18T02:26:39.000Z","path":"2020/06/18/SpringSecurity加密与JWT鉴权/","text":"SpringSecurity加密与JWT鉴权Spring Security的BCryptPasswordEncoder使用过程引入依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置类如果只是使用BCryptPasswordEncoder，这个配置可以直接拿来用 @Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter{ @Override protected void configure(HttpSecurity http) throws Exception { //authorizeRequests是所有security全注解配置实现的开端 //需要的权限分两部分，第一部分是拦截的路径，第二部分是访问该路径需要的权限 //antMatchers，表示拦截的路径，permitAll表示任何权限都可以访问，直接放行所有 //这里主要是用security的加密功能，拦截功能用的是jwt //anyRequest()任何的请求，authenticated()认证后访问 //and().csrf().disable()表示使csrf攻击失效 http .authorizeRequests() .antMatchers(\"/**\").permitAll() .anyRequest().authenticated() .and().csrf().disable(); }} 配置BCryptPasswordEncoder交给容器@Beanpublic BCryptPasswordEncoder bCryptPasswordEncoder(){ return new BCryptPasswordEncoder();} 密码加密service层 public void add(User user) { user.setId( idWorker.nextId()+\"\" ); //密码加密 user.setPassword(encoder.encode(user.getPassword())); userDao.save(user);} 密码验证service层 public User login(String mobile,String password) { //先通过前台传过来的电话查询出user User user=userDao.findByMobile(mobile); //再比对user的密码，用encoder.match(原密码,加密后的密码) if(user!=null&amp;&amp;encoder.matches(password,user.getPassword())){ return user; } return null;} JWT鉴权常见的鉴权方式Cookie认证Cookie认证机制就是为一次请求认证在服务端创建一个Session对象，同时在客户端 的浏览器端创建了一个Cookie对象；通过客户端带上来Cookie对象来与服务器端的 session对象匹配来实现状态管理的。 Token认证使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是 这样的： 客户端使用用户名跟密码请求登录 服务端收到请求，去验证用户名与密码 验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端 客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里 客户端每次向服务端请求资源的时候需要带着服务端签发的 Token 服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向 客户端返回请求的数据 两者对比Token的优势 支持跨域访问: Cookie是不允许垮域访问的，这一点对Token机制是不存在的，前提 是传输的用户认证信息通过HTTP头传输. 无状态:Token机制在服务端不需要存储session信息，因为 Token 自身包含了所有登录用户的信息，只需要在客户端的cookie或本地介质存储状态信息. 去耦: 不需要绑定到一个特定的身份验证方案。Token可以在任何地方生成，只要在 你的API被调用的时候，你可以进行Token生成调用即可. 一次网络往返时间（通过数据库查询session信息）总比做一次HMACSHA256计算的Token验证和解析要费时得多. 基于标准化:你的API可以采用标准化的 JSON Web Token (JWT) JWT介绍一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名，且生成后都会采用base64进行编码。 头部（Header）头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。这也可以 被表示成一个JSON对象，如下指明了采用了JWT的算法为HS256 {\"typ\":\"JWT\",\"alg\":\"HS256\"} base64编码后：eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 载荷（playload）一般包含ID，用户SUB，身份roles，比如 {\"id\":\"1234567890\",\"sub\":\"John Doe\",\"roles\":\"admin\"} 会再次进行base64编码 签证（signature）包含头部，载荷，以及定义的salt，同样进行base编码 最终JWT会将三部分连接成一个字符串，以.连接 eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6I kpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ JJWT：Java JWT添加依赖&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.6.0&lt;/version&gt;&lt;/dependency&gt; 在common包下的util包中创建JWT工具类这个工具类，需要提供ID,SUB,ROLE作为claims @ConfigurationProperties(\"jwt.config\")public class JwtUtil { private String key ; private long ttl ;//一个小时 public String getKey() { return key; } public void setKey(String key) { this.key = key; } public long getTtl() { return ttl; } public void setTtl(long ttl) { this.ttl = ttl; } /** * 生成JWT * @param id * @param subject * @return */ public String createJWT(String id, String subject, String roles) { long nowMillis = System.currentTimeMillis(); Date now = new Date(nowMillis); JwtBuilder builder = Jwts.builder().setId(id) .setSubject(subject) .setIssuedAt(now) .signWith(SignatureAlgorithm.HS256, key).claim(\"roles\", roles); if (ttl &gt; 0) { builder.setExpiration( new Date( nowMillis + ttl)); } return builder.compact(); } /** * 解析JWT * @param jwtStr * @return */ public Claims parseJWT(String jwtStr){ return Jwts.parser() .setSigningKey(key) .parseClaimsJws(jwtStr) .getBody(); }} jwt.config哪里用到了这个工具类，哪里的application.yml添加jwt定义，哪里传入jwtUtil @Bean public JwtUtil jwtUtil(){ return new util.JwtUtil(); } jwt: config: key: itcast ttl: 360000 以admin的登陆与删除鉴权为例详见：https://xulilei.github.io/2020/06/18/%E5%8D%81%E6%AC%A1%E6%96%B9daySix/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"https://xulilei.github.io/tags/Spring-Security/"},{"name":"BCryptPasswordEncoder","slug":"BCryptPasswordEncoder","permalink":"https://xulilei.github.io/tags/BCryptPasswordEncoder/"},{"name":"JWT","slug":"JWT","permalink":"https://xulilei.github.io/tags/JWT/"},{"name":"鉴权","slug":"鉴权","permalink":"https://xulilei.github.io/tags/%E9%89%B4%E6%9D%83/"},{"name":"密码加密","slug":"密码加密","permalink":"https://xulilei.github.io/tags/%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86/"}]},{"title":"dayFive-rabbitmq","date":"2020-06-15T10:53:31.000Z","path":"2020/06/15/十次方dayFive/","text":"用户注册模块搭建在user模块添加发送短信业务service层public void sendMsg(String mobile) { //生成六位随机数 String checkCode = RandomStringUtils.randomNumeric(6); //向缓存中放一份 redisTemplate.opsForValue().set(\"checkCode\"+mobile,checkCode,6, TimeUnit.HOURS); //给用户发一份，先存放至rabbitmq中 Map&lt;String,String&gt;map=new HashMap&lt;&gt;(); map.put(\"mobile\",mobile); map.put(\"checkCode\",checkCode); rabbitTemplate.convertAndSend(\"sms\",map);} controller层@RequestMapping(value =\"/sendsms/{mobile}\",method = RequestMethod.POST)public Result sendMsg(@PathVariable String mobile){ userService.sendMsg(mobile); return new Result(true,StatusCode.OK,\"发送成功\");} 在rabbitmq短信监听模块通过阿里云实施发送短信导入阿里云依赖&lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;4.5.0&lt;/version&gt;&lt;/dependency&gt; 根据阿里云官网API创建工具类@Componentpublic class SmsUtil { private static final String accessKeyId=\"LTAI4GCjWSbTHQzGTaavF**\"; private static final String accessKeySecret=\"sDiW0PSXaAKXfNfwCI8vaG4spE4**\"; private static final String signName=\"******\"; private static final String templateCode=\"SMS_1932477**\"; public void sendSms(String mobile,String checkCode) { DefaultProfile profile = DefaultProfile.getProfile(\"default\", accessKeyId, accessKeySecret); IAcsClient client = new DefaultAcsClient(profile); CommonRequest request = new CommonRequest(); request.setSysMethod(MethodType.POST); request.setSysDomain(\"dysmsapi.aliyuncs.com\"); request.setSysVersion(\"2017-05-25\"); request.setSysAction(\"SendSms\"); request.putQueryParameter(\"PhoneNumbers\", mobile); request.putQueryParameter(\"SignName\", signName); request.putQueryParameter(\"TemplateCode\", templateCode); //这里使用通配符，code要与在阿里云注册的模版相同 request.putQueryParameter(\"TemplateParam\", \"{\\\"code\\\":\"+checkCode+\"}\"); try { CommonResponse response = client.getCommonResponse(request); System.out.println(response.getData()); } catch (ServerException e) { e.printStackTrace(); } catch (ClientException e) { e.printStackTrace(); } }} 创建rabbitmq监听器类@Component@RabbitListener(queues = \"sms\")public class SmsListener { @Autowired private SmsUtil smsUtil; @RabbitHandler public void executeSms(Map&lt;String,String&gt; map){ String mobile = map.get(\"mobile\"); String checkCode = map.get(\"checkCode\"); smsUtil.sendSms(mobile,checkCode); }} 自此短信功能部署成功 用户注册业务@RequestMapping(value =\"/register/{code}\",method = RequestMethod.POST)public Result register(@PathVariable String code,@RequestBody User user){ //先从缓存中拿到先前发送短信时存放的数据 String checkCodeRedis= (String) redisTemplate.opsForValue().get(\"checkCode\"+user.getMobile()); //比对数据 if(checkCodeRedis.isEmpty()){ return new Result(false,StatusCode.ERROR,\"未发送验证码\"); } if(!checkCodeRedis.equals(code)){ return new Result(false,StatusCode.ERROR,\"验证码错误\"); } //比对成功，注册用户 userService.add(user); return new Result(true,StatusCode.OK,\"注册成功\");} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://xulilei.github.io/tags/rabbitmq/"},{"name":"短信验证","slug":"短信验证","permalink":"https://xulilei.github.io/tags/%E7%9F%AD%E4%BF%A1%E9%AA%8C%E8%AF%81/"},{"name":"用户注册","slug":"用户注册","permalink":"https://xulilei.github.io/tags/%E7%94%A8%E6%88%B7%E6%B3%A8%E5%86%8C/"}]},{"title":"RabbitMQ入门","date":"2020-06-15T10:53:09.000Z","path":"2020/06/15/RabbitMQ/","text":"消息中间件RabbitMQRabbitMQ简介消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋和消息通讯等问题，实现高性能，高可用，可伸缩和最终一致性的架构 架构图通过交换机再进入到队列中 主要概念RabbitMQ Server也叫broker server，它是一种传输服务。 他的角色就是维护一条 从Producer到Consumer的路线，保证数据能够按照指定的方式进行传输。 Producer消息生产者，如图A、B、C，数据的发送方。消息生产者连接RabbitMQ服 务器然后将消息投递到Exchange。 Consumer消息消费者，如图1、2、3，数据的接收方。消息消费者订阅队列， RabbitMQ将Queue中的消息发送到消息消费者。 Exchange生产者将消息发送到Exchange（交换器），由Exchange将消息路由到一个 或多个Queue中（或者丢弃）。Exchange并不存储消息。RabbitMQ中的Exchange有 direct、fanout、topic、headers四种类型，每种类型对应不同的路由规则。 Queue队列是RabbitMQ的内部对象，用于存储消息。消息消费者就是通过订阅 队列来获取消息的，RabbitMQ中的消息都只能存储在Queue中，生产者生产消息并最终 投递到Queue中，消费者可以从Queue中获取消息并消费。多个消费者可以订阅同一个 Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者 都收到所有的消息并处理。 RoutingKey生产者在将消息发送给Exchange的时候，一般会指定一个routing key， 来指定这个消息的路由规则，而这个routing key需要与Exchange Type及binding key联 合使用才能最终生效。在Exchange Type与binding key固定的情况下（在正常使用时一 般这些内容都是固定配置好的），我们的生产者就可以在发送消息给Exchange时，通过 指定routing key来决定消息流向哪里。 Docker安装需要注意的是要配置多个接口 docker run ‐di ‐‐name=tensquare_rabbitmq ‐p 5671:5617 ‐p 5672:5672 ‐p 4369:4369 ‐p 15671:15671 ‐p 15672:15672 ‐p 25672:25672 rabbitmq:management 主要知识点Exchange类型direct模式 1、将消息发给唯一一个节点时使用这种模式，这是最简单的一种形式 2、这种模式下不需要将Exchange进行任何绑定(binding)操作 3、消息传递时需要一个“RouteKey”，可以简单的理解为要发送到的队列名字 首先创建一个test队列 以direct模式发送 @RunWith(SpringRunner.class)@SpringBootTest(classes = RabApplication.class)public class ProductTest { @Autowired private RabbitTemplate rabbitTemplate; @Test public void sendMsg(){ //这里的test就是queue的名字 rabbitTemplate.convertAndSend(\"test\",\"测试直接模式\"); }} 创建消费者接受 @Component@RabbitListener(queues = \"test\")public class Customer { @RabbitHandler public void getMsg(String msg){ System.out.println(\"直接模式消费消息\"+msg); }} 运行结果 该模式下，默认采用了负载均衡，即消费者从队列获取消息是均衡的 分列模式 任何发送到Fanout Exchange的消息都会被转发到与该Exchange绑定(Binding)的所有 Queue上。 1、这种模式不需要RouteKey 2、这种模式需要提前将Exchange与Queue进行绑定，一个Exchange可以绑定多个 Queue，一个Queue可以同多个Exchange进行绑定。 3、如果接受到消息的Exchange没有与任何Queue绑定，则消息会被抛弃。+ 主题模式 任何发送到Topic Exchange的消息都会被转发到所有关心RouteKey中指定话题的 Queue上 1、这种模式较为复杂，简单来说，就是每个队列都有其关心的主题，所有的消息都带有一 个“标题”(RouteKey)，Exchange会将消息转发到所有关注主题能与RouteKey模糊匹配的 队列。 2、这种模式需要RouteKey，也许要提前绑定Exchange与Queue。 3、在进行绑定时，要提供一个该队列关心的主题，如“#.log.#”表示该队列关心所有涉及 log的消息(一个RouteKey为”MQ.log.error”的消息会被转发到该队列)。 4、“#”表示0个或若干个关键字，“”表示一个关键字。如“log.”能与“log.warn”匹配，无法 与“log.warn.timeout”匹配；但是“log.#”能与上述两者匹配。 5、同样，如果Exchange没有发现能够与RouteKey匹配的Queue，则会抛弃此消息 配合阿里云实现发送短信功能详见 https://xulilei.github.io/2020/06/15/%E5%8D%81%E6%AC%A1%E6%96%B9dayFive/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://xulilei.github.io/tags/rabbitmq/"},{"name":"短信验证","slug":"短信验证","permalink":"https://xulilei.github.io/tags/%E7%9F%AD%E4%BF%A1%E9%AA%8C%E8%AF%81/"}]},{"title":"DayFour-elasticsearch","date":"2020-06-14T10:34:44.000Z","path":"2020/06/14/十次方DayFour/","text":"搜索微服务搭建使用spring-data-elasticsearch操作导入依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-elasticsearch&lt;/artifactId&gt;&lt;/dependency&gt; Pojo实体类@Document(indexName = \"articleindex\",type = \"article\")public class Article implements Serializable { @Id private String id; //是否能被搜索到 //是否分词，整体匹配还是分词匹配 //是否在页面上显示，即数据库中在该实体类中的字段，就是要显示的,比如该例中的id title content state //analyzer,分词 //searchAnalyzer，搜索 @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String title; @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String content; private String state;} Dao层public interface ArticleDao extends ElasticsearchRepository&lt;Article,String&gt; { public Page&lt;Article&gt; findByTitleOrContentLike(String title, String content, Pageable pageable);} Service层@Servicepublic class ArticleService { @Autowired private ArticleDao articleDao; @Autowired private IdWorker idWorker; public void save(Article article){ articleDao.save(article); } //springdata系列分页的写法都是这个 public Page&lt;Article&gt; findByKey(String key, int page, int size) { Pageable pageable= PageRequest.of(page-1,size); return articleDao.findByTitleOrContentLike(key,key,pageable); }} controller层@RestController@RequestMapping(\"/article\")@CrossOriginpublic class ArticleController { @Autowired private ArticleService articleService; @RequestMapping(method = RequestMethod.POST) public Result save(@RequestBody Article article){ articleService.save(article); return new Result(true, StatusCode.OK,\"存储成功\"); } @RequestMapping(value = \"/{key}/{page}/{size}\",method = RequestMethod.GET) public Result findByKey(@PathVariable String key,@PathVariable int page,@PathVariable int size){ Page&lt;Article&gt;pageData=articleService.findByKey(key,page,size); return new Result(true,StatusCode.OK,\"搜索成功\",new PageResult&lt;Article&gt;(pageData.getTotalElements(),pageData.getContent())); }} docker部署elasticsearchhttps://xulilei.github.io/2020/06/12/elasticSearch%E5%85%A5%E9%97%A8/ 连接服务器，并测试存储到服务器的索引库application.yml配置server: port: 9007spring: application: name: tensquare-search data: elasticsearch: cluster-nodes: 192.168.152.128:9300 postMan测试成功 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://xulilei.github.io/tags/elasticsearch/"},{"name":"搜索功能","slug":"搜索功能","permalink":"https://xulilei.github.io/tags/%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD/"}]},{"title":"ElasticSearch从认识到发布","date":"2020-06-12T07:54:05.000Z","path":"2020/06/12/elasticSearch入门/","text":"分布式搜索引擎ElasticSearch概念与mysql数据库对比 Elasticsearch 关系型数据库Mysql 索引(index) 数据库(databases) 类型(type) 表(table) 文档(document) 行(row) restful风格操作ElasticSearch新建索引如果需要创建一个叫articleindex的索引 ,就以put方式提交 http://127.0.0.1:9200/articleindex/ 新建文档新建类型，在索引后追加类型： 以post方式提交 http://127.0.0.1:9200/articleindex/article 查询文档查询全部_search，以get方式请求 http://127.0.0.1:9200/articleindex/article/_search 按ID查询以GET方式请求 http://127.0.0.1:9200/articleindex/article/1 匹配查询根据title=aa进行查询，get方式提交下列地址： http://127.0.0.1:9200/articleindex/article/_search?q=title:aa 模糊查询以*用代表任意字符： http://192.168.184.134:9200/articleindex/article/_search?q=title:*s* 修改以put形式提交以下地址,如果ID存在则修改，否则添加 http://127.0.0.1:9200/articleindex/article/1 删除文档根据ID删除文档,删除ID为1的文档 DELETE方式提交 http://192.168.184.134:9200/articleindex/article/1 head插件操作ElasticSearch安装步骤步骤1： 下载head插件：https://github.com/mobz/elasticsearch-head 步骤2： 将grunt安装为全局命令npm install ‐g grunt‐cli 步骤3：解决跨域问题修改elasticsearch配置文件：elasticsearch.yml，增加以下两句命令： http.cors.enabled: true http.cors.allow‐origin: \"*\" 步骤4： 安装依赖并启动cnpm installgrunt server 图形化界面 Logstash概念Logstash是一款轻量级的日志搜集处理框架，可以方便的把分散的、多样化的日志搜集 起来，并进行自定义的处理，然后传输到指定的位置，比如某个服务器或者文件。 基本用法命令行参数: -e ：执行（很少用） -f：路径，后跟参数类型可以是一个字符串的配置或全路径文件名或全路径 如：/etc/logstash.d/，logstash会自动读取/etc/logstash.d/目录下所有*.conf 的文 本文件，然后在自己内存里拼接成一个完整的大配置文件再去执行 使用Logstash将数据库的内容同步到索引库模版，用到时直接填写input { jdbc { # mysql jdbc connection string to our backup databse jdbc_connection_string =&gt; \"jdbc:mysql://192.168.xx.xx:3306/aaaaa?characterEncoding=UTF8\" # the user we wish to excute our statement as jdbc_user =&gt; \"root\" jdbc_password =&gt; \"root\" # the path to our downloaded jdbc driver jdbc_driver_library =&gt; \"C:\\Users\\xu\\Desktop\\tensquare\\logstash-5.6.8\\mysqletc\\mysql-connector-java-5.1.46.jar\" # the name of the driver class for mysql jdbc_driver_class =&gt; \"com.mysql.jdbc.Driver\" jdbc_paging_enabled =&gt; \"true\" jdbc_page_size =&gt; \"50\" #以下对应着要执行的sql的绝对路径。 #statement_filepath =&gt; \"\" #这个是要直接执行的sql语句 statement =&gt; \"\"select id,title,content,state from tb_article\" #定时字段 各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新（测试结果，不同的话请留言指出） schedule =&gt; \"* * * * *\" }}output { elasticsearch { #ESIP地址与端口 hosts =&gt; \"127.0.0.1:9200\" #ES索引名称（自己定义的） index =&gt; \"articleindex\" #自增ID编号 document_id =&gt; \"%{id}\" document_type =&gt; \"article\" } stdout { #以JSON格式输出 codec =&gt; json_lines }} 再通过一下命令执行该文件logstash ‐f ../mysqletc/mysql.conf 结果返回{\"@version\":\"1\",\"id\":\"1\",\"state\":\"1\",\"@timestamp\":\"2020-06-15T03:35:00.106Z\",\"title\":\"xu测试\",\"content\":\"测试\"}{\"@version\":\"1\",\"id\":\"1\",\"state\":\"1\",\"@timestamp\":\"2020-06-15T03:34:01.671Z\",\"title\":\"xu测试\",\"content\":\"测试\"} 注意事项删除数据库中的文件并不会导致索引库中的数据删除，可以约定一个state，当需要删除的时候更改state的值，在索引库中，查询约定state的值即可实现 docker安装ES安装ES容器第一步，安装容器docker run ‐di ‐‐name=tensquare_elasticsearch ‐p 9200:9200 ‐p 9300:9300 elasticsearch:5.6.8 第二步，允许其他ip地址访问#进入elasticsearch容器的目录docker exec ‐it tensquare_elasticsearch /bin/bash#拷贝容器中的配置文件到宿主机docker cp tensquare_elasticsearch:/usr/share/elasticsearch/config/elasticsearch.yml /usr/share/elasticsearch.yml#停止删除原来的容器docker stop tensquare_elasticsearch docker rm tensquare_elasticsearch#重新安装容器，并挂载配置文件为/usr/share/elasticsearch.ymldocker run ‐di ‐‐name=tensquare_elasticsearch ‐p 9200:9200 ‐p 9300:9300 ‐v /usr/share/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch .yml elasticsearch:5.6.8#修改/usr/share/elasticsearch.yml 将#transport.host:0.0.0.0前的#去掉后保存文件退出。其作用是允许任何ip地址访问elasticsearch，并指定可以跨域transport.host:0.0.0.0http.cors.enabled: true http.cors.allow‐origin: \"*\"#重启容器docker restart tensquare_elasticsearch 第三部，如果遇到容器启动自动关闭，则需要优化配置(每个机器不同优化也不同)可以参考 https://blog.csdn.net/qq_34756221/article/details/105550037 https://www.cnblogs.com/jasonzeng/p/11584754.html 安装ik分词器先通过xftp将ik分词文件传送至服务器，再拷贝至es容器目录的plugins中 docker cp ik tensquare_elasticsearch:/usr/share/elasticsearch/plugins/ 安装headerdocker run ‐di ‐‐name=myhead ‐p 9100:9100 docker pull mobz/elasticsearch‐ head:5 成功页面展示head插件展示 ik分词器展示 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://xulilei.github.io/tags/ElasticSearch/"},{"name":"Logstash","slug":"Logstash","permalink":"https://xulilei.github.io/tags/Logstash/"},{"name":"ik分词器","slug":"ik分词器","permalink":"https://xulilei.github.io/tags/ik%E5%88%86%E8%AF%8D%E5%99%A8/"},{"name":"docker","slug":"docker","permalink":"https://xulilei.github.io/tags/docker/"}]},{"title":"DayThree-mongoDB","date":"2020-06-09T08:25:22.000Z","path":"2020/06/09/十次方项目第三天/","text":"Day03什么是MongoDB​ MongoDB 是一个跨平台的，面向文档的数据库，是当前 NoSQL 数据库产品中最热 门 的一种。它介于关系数据库和非关系数据库之间，是非关系数据库当中功能最丰富，最像关系数据库的产品。它支持的数据结构非常松散，是类似 JSON 的 BSON 格式，因此可以存储比较复杂的数据类型。 MongoDB适用场景​ 适用于场景数据量大，数据价值相对低的情况 MongoDB体系结构（1）MongoDB 的文档（document），相当于关系数据库中的一行记录。 （2）多个文档组成一个集合（collection），相当于关系数据库的表。 （3）多个集合（collection），逻辑上组织在一起，就是数据库（database）。 服务器创建Docker MongoDB容器[root@pinyoyougou-docker ~]# docker run -di --name=tensquare_mongo -p 27017:27017 mongo MongoDB语法创建表use 数据库名称//如果不存在则自动创建 插入数据db.集合名称.insert(数据);//插入文档的语法格式比如db.spit.insert({content:\"听说十次方课程很给力呀\",userid:\"1011\",nickname:\"小雅\",visits:NumberInt(902)}) 查询数据db.集合名称.find()//查询所有db.spit.find().limit(3)//限定返回3条db.spit.find({userid:'1013'})//查询userid=1013的文档 修改与删除数据db.集合名称.update(条件,修改后的数据)//如果我们想修改_id为1的记录，浏览量为1000，输入以下语句：db.spit.update({_id:\"1\"},{visits:NumberInt(1000)})执行后，我们会发现，这条文档除了visits字段其它字段都不见了，为了解决这个问题，我们需要使用修改器$set来实现，命令如下：db.spit.update({_id:\"2\"},{$set:{visits:NumberInt(2000)}})//删除指定文档db.集合名称.remove(条件) 模糊查询MongoDB的模糊查询是通过正则表达式的方式实现的格式为：db.集合名称.find({content:/aaa/})例如，我要查询吐槽内容包含“流量”的所有文档，代码如下：db.spit.find({content:/流量/})如果要查询吐槽内容中以“加班”开头的，代码如下：db.spit.find({content:/^加班/}) 大于 小于 不等于db.集合名称.find({ \"field\" : { $gt: value }}) // 大于: field &gt; valuedb.集合名称.find({ \"field\" : { $lt: value }}) // 小于: field &lt; valuedb.集合名称.find({ \"field\" : { $gte: value }}) // 大于等于: field &gt;= valuedb.集合名称.find({ \"field\" : { $lte: value }}) // 小于等于: field &lt;= valuedb.集合名称.find({ \"field\" : { $ne: value }}) // 不等于: field != value 包含与不包含包含使用$in操作符。示例：查询吐槽集合中userid字段包含1013和1014的文档db.spit.find({userid:{$in:[\"1013\",\"1014\"]}})不包含使用$nin操作符。示例：查询吐槽集合中userid字段不包含1013和1014的文档db.spit.find({userid:{$nin:[\"1013\",\"1014\"]}}) 条件连接我们如果需要查询同时满足两个以上条件，需要使用$and操作符将条件进行关联。（相当于SQL的and）格式为：$and:[{ },{ },{ }]示例：查询吐槽集合中visits大于等于1000 并且小于2000的文档db.spit.find({$and:[ {visits:{$gte:1000}} ,{visits:{$lt:2000}}]})如果两个以上条件之间是或者的关系，我们使用 操作符进行关联，与前面and的使用方式相同格式为：$or:[{ },{ },{ }]示例：查询吐槽集合中userid为1013，或者浏览量小于2000的文档记录db.spit.find({$or:[ {userid:\"1013\"} ,{visits:{$lt:2000} }]}) 列值增长如果我们想实现对某列值在原有值的基础上进行增加或减少，可以使用$inc运算符来实现db.spit.update({_id:\"2\"},{$inc:{visits:NumberInt(1)}}) JAVA操作MongoDBpublic class MongoDemo { public static void main(String[] args) { MongoClient client=new MongoClient(\"192.168.184.134\");//创建连接 MongoDatabase spitdb = client.getDatabase(\"spitdb\");//打开数据库 MongoCollection&lt;Document&gt; spit = spitdb.getCollection(\"spit\");//获取集合 //条件查询 //BasicDBObject bson=new BasicDBObject(\"userid\",\"1013\");// 构建查询条件 //BasicDBObject bson=new BasicDBObject(\"visits\",newBasicDBObject(\"$gt\",1000) ); //FindIterable&lt;Document&gt; documents = spit.find(bson);//查询记录获取结果集合 FindIterable&lt;Document&gt; documents = spit.find();//查询记录获取文档集合 for(Document document:documents){ // System.out.println(\"内容：\"+ document.getString(\"content\")); System.out.println(\"用户ID:\"+document.getString(\"userid\")); System.out.println(\"浏览量：\"+document.getInteger(\"visits\")); } //插入数据 Map&lt;String,Object&gt; map=new HashMap(); map.put(\"content\",\"我要吐槽\"); map.put(\"userid\",\"9999\"); map.put(\"visits\",123); map.put(\"publishtime\",new Date()); Document document=new Document(map); spit.insertOne(document); client.close();//关闭连接 }} SpringDataMongoDB增删改查与SpringDataJPA几乎一样，详细用法参考https://xulilei.github.io/2020/06/08/%E5%8D%81%E6%AC%A1%E6%96%B9%E9%A1%B9%E7%9B%AEDay2/ 通过MongoTemplate原生方式实现数据自增public void thumbUp(String id){ //方式一,与数据库多次交互性能较低 Spit spit=spitDao.findById(id).get(); spit.setThumbup((spit.getThumbup()==null?0:spit.getThumbup())+1); spitDao.save(spit); //相当于使用原生mongo命令实现自增：db.spit.update({\"_id\":\"1\"},{$inc:{thumbup:NumberInt(1)}}) Query query=new Query(); query.addCriteria(Criteria.where(\"_id\").is(\"id\")); Update update=new Update(); update.inc(\"thumbup\",1); mongoTemplate.updateFirst(query,update,\"spit\"); } document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://xulilei.github.io/tags/MongoDB/"},{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"DayTwo-SpringDataJpa","date":"2020-06-08T07:23:13.000Z","path":"2020/06/08/十次方项目Day2/","text":"SpringDataJpa通过new Specification实现条件查询//service层public List&lt;Label&gt; findSearch(Label label) { return labelDao.findAll(new Specification&lt;Label&gt;() { /** * 采用内部类，方式实现 * @param root 根对象，也就是说要把条件封装到哪个对象中去 * @param query 查询关键字，比如groupBy，orderBy等 * @param cb 用来封装条件对象的 * @return 如果返回null，则代表不需要任何条件 */ @Override public Predicate toPredicate(Root&lt;Label&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; list=new ArrayList&lt;&gt;(); //相当于 where labelname like \"%小明%\" if(label.getLabelname()!=null&amp;&amp;!\"\".equals(label.getLabelname())){ Predicate predicate = cb.like(root.get(\"labelname\").as(String.class), \"%\" + label.getLabelname() + \"%\"); list.add(predicate); } if(label.getState()!=null&amp;&amp;!\"\".equals(label.getState())){ Predicate predicate = cb.equal(root.get(\"state\").as(String.class), label.getState()); list.add(predicate); } Predicate[] parr=new Predicate[list.size()]; list.toArray(parr); //相当于查询where condition A and condition B return cb.and(parr); } }); }//controller层 @RequestMapping(value = \"/search\",method = RequestMethod.POST) public Result findSearch(@RequestBody Label label){ List&lt;Label&gt;list=labelService.findSearch(label); return new Result(true,StatusCode.OK,\"查询成功\",list); } 分页与条件查询//service层public Page&lt;Label&gt; findSearchAndPageQuery(Label label, int page, int size) { //封装一个分页对象 Pageable pageable=PageRequest.of(page-1,size); return labelDao.findAll(new Specification&lt;Label&gt;() { /** * * @param root 根对象，也就是说要把条件封装到哪个对象中去 * @param query 查询关键字，比如groupBy，orderBy等 * @param cb 用来封装条件对象的 * @return 如果返回null，则代表不需要任何条件 */ @Override public Predicate toPredicate(Root&lt;Label&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; list=new ArrayList&lt;&gt;(); //相当于 where labelname like \"%小明%\" if(label.getLabelname()!=null&amp;&amp;!\"\".equals(label.getLabelname())){ Predicate predicate = cb.like(root.get(\"labelname\").as(String.class), \"%\" + label.getLabelname() + \"%\"); list.add(predicate); } if(label.getState()!=null&amp;&amp;!\"\".equals(label.getState())){ Predicate predicate = cb.equal(root.get(\"state\").as(String.class), label.getState()); list.add(predicate); } Predicate[] parr=new Predicate[list.size()]; list.toArray(parr); return cb.and(parr); } },pageable); }//controller层 @RequestMapping(value = \"/search/{page}/{size}\",method = RequestMethod.POST) public Result findSearchAndPageQuery(@RequestBody Label label,@PathVariable int page,@PathVariable int size){ Page&lt;Label&gt; pageData=labelService.findSearchAndPageQuery(label,page,size); return new Result(true,StatusCode.OK,\"查询成功\",new PageResult&lt;Label&gt;(pageData.getTotalElements(),pageData.getContent())); }//用来封装pageResult的类public class PageResult&lt;T&gt; { private long total; private List&lt;T&gt; rows; public long getTotal() { return total; } public void setTotal(long total) { this.total = total; } public List&lt;T&gt; getRows() { return rows; } public void setRows(List&lt;T&gt; rows) { this.rows = rows; } public PageResult() { } public PageResult(long total, List&lt;T&gt; rows) { this.total = total; this.rows = rows; }} 在Dao层通过方法命名方式生成sql语句public interface EnterpriseDao extends JpaRepository&lt;Enterprise,String&gt;,JpaSpecificationExecutor&lt;Enterprise&gt;{ //相当于where ishot=? public List&lt;Enterprise&gt; findByIshot(String ishot); }public interface RecruitDao extends JpaRepository&lt;Recruit,String&gt;,JpaSpecificationExecutor&lt;Recruit&gt;{ //相当于where state=？ order by Createtime，并且取前6个 public List&lt;Recruit&gt; findTop6ByStateOrderByCreatetimeDesc(String state); //相当于where state！=？order by createtime。并且取前6个 public List&lt;Recruit&gt; findTop6ByStateNotOrderByCreatetimeDesc(String state);} 具体命名规则参考https://www.cnblogs.com/oxygenG/p/10057525.html。 处理多对多关系在数据库端处理多对多的关系，必须需要借助中间表。而在java端，只需要在一个对象中放入另一个对象的list集合即可。如果不创建实体类，则需要通过原生的sql语句执行 //通过这个查询语句，才能够实现pageable的分页功能@Query(value=\"SELECT * FROM tb_problem,tb_pl WHERE id=problemid AND labelid=:labelid ORDER BY ?#{#pageable}\", countQuery = \"select count(*) from tb_problem ,tb_pl where id=problemid AND labelid=:labelid\",nativeQuery = true)public Page&lt;Problem&gt; newList(@Param(\"labelid\") String labelid, Pageable pageable); 参考：https://blog.csdn.net/tt____tt/article/details/81027269?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase 事务支持1、Dao层，在可能产生线程问题的语句上添加@Modifying @Modifying@Query(value = \"update tb_article set state='1' where id=?1\",nativeQuery = true)public void updateState(String id); 2、Service层开启注解支持@Transactional @Service@Transactionalpublic class ArticleService {} 缓存的应用Redis–有过期时间限制1、添加SpringDataRedis依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2、服务端Docker开启Redis镜像，生成redis容器 [root@pinyoyougou-docker ~]# docker run -di --name=tensquare_redis -p 6379:6379 redis 3、application.ymal配置host redis: host: 192.168.*.* 4、业务逻辑调用 public class ArticleService { @Autowired private ArticleDao articleDao; @Autowired private RedisTemplate redisTemplate; public Article findById(String id) { //先从缓存中查询当前对象 Article article= (Article) redisTemplate.opsForValue().get(\"article_\"+id); //如果没有渠道 if(article==null){ article = articleDao.findById(id).get(); //存入缓存 redisTemplate.opsForValue().set(\"article_\"+id,article); } return article; } public void deleteById(String id) { //删除缓存 redisTemplate.delete(\"article_\"+id); articleDao.deleteById(id); }} redisTemplate用法 stringRedisTemplate.opsForValue().set(\"test\", \"100\",60*10,TimeUnit.SECONDS);//向redis里存入数据和设置缓存时间stringRedisTemplate.opsForValue().get(\"test\")//根据key获取缓存中的valstringRedisTemplate.delete(\"test\");//根据key删除缓存stringRedisTemplate.hasKey(\"546545\");//检查key是否存在，返回boolean值 SpringCache–无过期时间限制1、SpringApplication开启SpringCache @SpringBootApplication@EnableCachingpublic class GatApplication {} 2、业务层调用，@Cacheable为存，@CacheEvict为删 @Cacheable(value = \"gathering\",key = \"#id\")public Gathering findById(String id) { return gatheringDao.findById(id).get();}@CacheEvict(value = \"gathering\",key = \"#gathering.id\")public void update(Gathering gathering) { gatheringDao.save(gathering);} 第二天总结掌握了条件与分页查询，Dao层方法命名规则，事务支持，缓存 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"SpringDataJPA","slug":"SpringDataJPA","permalink":"https://xulilei.github.io/tags/SpringDataJPA/"},{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"Docker入门篇","date":"2020-06-05T07:57:43.000Z","path":"2020/06/05/Docker入门/","text":"Docker入门Dokcer为什么会出现？一款产品从开发到上线，一般都需要两套环境。而环境的配置十分麻烦，Docker给出了解决方案 步骤：java–jar（环境）–打包项目带上环境（即Docker镜像）–Docker仓库–下载我们发布的镜像–直接运行即可。 虚拟机技术特点1、资源占用十分多 2、冗余步骤多 3、启动很慢 如下图所示，多个APP共享一个lib环境，可能会造成端口冲突等环境冲突的问题 容器化技术如下图所示，每个模块拥有独属于自己运行的环境，各个模块之间相互隔离 Docker的相关概念Docker架构图 相关术语镜像：images​ 通过这个模版来创建容器服务，比如Mysql镜像–通过Docker运行后，便成为了一个提供服务的容器,一个镜像可以创建多个容器 容器：container​ 提供服务，可以启动、停止、删除等，可类比为一个简单的linux系统 仓库：repository​ 存放镜像的地方，分为共有仓库和私有仓库 Docker安装Nginx1、search：可在命令行和dockerHub上搜索对应版本 2、pull：拉去下载该镜像 3、docker images：查看本机上的镜像 3、运行该镜像 docker run -d --name nginx01 -p 3344:80 nginx #新建一个名字为nginx01的nginx镜像，公网访问地址为3344，内部地址为80，并运行该镜像#-d 后台运行、--name 命名、-p 端口号 4、内部测试 ​ curl localhost:3344 容器数据卷结构示意图如下 防止容器删除后数据丢失，通过实现容器间数据共享，并将产生的数据备份到linux的文件系统上 总结一句话就是：容器的持久化和容器间的同步操作。 使用数据卷​ -v 主机目录:容器内目录 —&gt;映射容器内的目录到主机上 ​ 参考https://xulilei.github.io/2020/06/12/elasticSearch%E5%85%A5%E9%97%A8/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"Docker","slug":"Docker","permalink":"https://xulilei.github.io/tags/Docker/"}]},{"title":"DayOne-架构","date":"2020-06-02T11:02:13.000Z","path":"2020/06/02/十次方社交平台项目/","text":"DayOne系统架构SpringBoot+SpringCloud+SpringMVC+SpringData，也称这种架构模式为spring全家桶 系统模块不再采取按dao，service层划分模块，而是基于每个微服务，再将每个模块封装成一个镜像，再通过springCloud连接起来。因此在每个微服务中便不需要再写接口，因为每个微服务就是最小模块 开发API通过swagger封装，Nginx代理，形成的API开发文档 Restful开发风格我们在项目中经常用到增删改查：get/post/put/delete四种方法，安全：操作不会出现脏读、幻读等操作。幂等：查询成功后不会对数据库造成影响 Get查询是安全且幂等的 Post是不安全且不幂等的 Put改是不安全且幂等的 Delete删是不安全且幂等的 主要工作Mysql环境搭建创建虚拟机，安装docker，下载Mysql镜像，在服务器(192.168.152.128)运行并从本地连接完成建表 创建父工程主要是一些子模块都需要的依赖配置在这里 &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; &lt;!--SpringCloud全家桶父工程推荐默认配置--&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; 模块搭建公共模块搭建，根据swagger约定，封装数据传输到前端。其中utils包下的idWoker根据雪花算法，可以生成不同的ID，吞吐量为20W+。 基础模块搭建，数据的CRUD操作 import com.tensquare.base.pojo.Label;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.data.jpa.repository.JpaSpecificationExecutor;//SpringDataJpa封装了CRUD操作，以及一些复杂的条件查询public interface LabelDao extends JpaRepository&lt;Label,String&gt;, JpaSpecificationExecutor&lt;Label&gt; {} Day01总结在服务器端，通过Docker创建了Mysql镜像 通过本地IDEA的DataSource连接上去。 通过PostMan检查当天的CRUD操作 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]}]