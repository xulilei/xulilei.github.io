[{"title":"秋招复习之java基础","date":"2020-07-12T08:15:47.000Z","path":"2020/07/12/秋招复习之java基础/","text":"秋招复习之java基础1、面对对象的理解面向对象易维护，易复用，易扩展。因为面向对象有封装、继承、多态三大特性，所以基于面对对象思想构建的程序具有低耦合、更灵活、易维护等特点 封装、继承、多态封装：也就是把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。 继承：是指可以让某个类型的对象获得另一个类型的对象的属性的方法。 所态：就是指一个类实例的相同方法在不同情形有不同表现形式 2、JVM、JRE、JDKJVM：被称为java虚拟机，是运行java字节码的虚拟机 JRE：java运行时环境，包括JVM，Java类库，Java命令和其他一些基础组件 JDK：拥有JRE所拥有的一切，还有java编译器javac和工具 3、基本数据类型 4、重载、重写与重构的区别重载：发生在同一个类中，方法名必须相同，参数类型，个数，顺序，返回值类型，访问修饰符等都可以不同 重写：是子类对父类允许访问的方法的实现过程进行重新编写，发生在子类中，方法名、参数列表必须相同，返回值范围小于等于父类，访问修饰符范围大于等于父类，如果父类是private修饰的就不能重写该方法。也就是说方法提供的行为改变，而方法的外貌并没有改变 重构：是重写的一种特殊方式，子类与父类的成员方法的返回值、方法名称、参数类型及个数完全相同，唯一不同的是方法实现内容，这种特殊重写方式被称为重构。 5、StringBuffer、StringBuilder、StringString：由final关键字修饰，即String对象是不可变的，线程安全 StringBuffer：对象可变，线程安全 StringBuilder：对象可变，线程不安全 6、自动装箱与拆箱装箱：将基本数据类型用他们对应的引用类型包装起来 拆箱：将包装类型转换为基本数据类型 一种机制，使得这些基本类型在一般的编程中被当作非对象的简单类型处理，在另一些场合，又允许它们被视作是一个对象 7、静态方法和非静态方法的区别一、静态方法是使用static关键字修饰的方法，又叫类方法。属于类的，不属于对象，在实例化对象之前就可以通过类名.方法名调用静态方法。A.在静态方法中，可以调用静态方法。B.在静态方法中，不能调用非静态方法。C.在静态方法中，可以引用类变量（即，static修饰的变量）。D.在静态方法中，不能引用成员变量（即，没有static修饰的变量）。E.在静态方法中，不能使用super和this关键字 二、非静态方法是不含有static关键字修饰的普通方法，又称为实例方法，成员方法。属于对象的，不属于类的。成员方法是属于对象的，必须通过new关键字创建对象后，再通过对象调用A.在普通方法中，可以调用普通方法。B.在普通方法中，可以调用静态方法C.在普通方法中，可以引用类变量和成员变量D.在普通方法中，可以使用super和this关键字 静态方法和非静态方法的区别（生命周期不同）静态方法的生命周期跟相应的类一样长，静态方法和静态变量会随着类的定义而被分配和装载入内存中。一直到线程结束，静态属性和方法才会被销毁。（也就是静态方法属于类）非静态方法的生命周期和类的实例化对象一样长，只有当类实例化了一个对象，非静态方法才会被创建，而当这个对象被销毁时，非静态方法也马上被销毁。（也就是非静态方法属于对象） 8、空构造函数的作用构造函数的作用：当new一个对象的时候，调用构造函数完成对象的初始化 在类中如果没有参构造函数，系统会默认一个无参构造函数，此时写不写空构造没有影响。但如果父类只定义了有参构造，在子类的构造函数中，又没有通过super()来调用父类特定有参构造函数的情况下，将会发生编译错误。 9、接口和抽象类抽象类：抽象类不能实例化，即不能使用new关键字来实例化对象；抽象类可以含有抽象方法，也可以不包含抽象方法，抽象类中可以有具体的方法；抽象类中的抽象方法只有方法体，没有具体实现； 接口：接口不能被实例化；一个类只能继承一个类，但是可以实现多个接口；接口中方法可以为抽象方法，java8后接口也可以定义静态方法，可以直接通过接口名.方法调用 10、静态变量、成员变量和局部变量的区别一、静态变量和成员变量的区别：(1)所属不同： 静态变量：属于类，也称为类变量。 成员变量：属于对象，也称为对象变量或实例变量。(2)在内存中的位置不同： 静态变量：存储于方法区/元空间。 成员变量：存储于堆内存。(3)生命周期不同： 静态变量：静态变量是随着类的加载而加载，随着类的消失而消失。 成员变量：成员变量是随着对象的创建而存在，随着对象的消失而消失。(4)调用不同： 静态变量：可以通过对象名调用，也可以通过类名调用。 成员变量：只能通过对象名调用。 二、成员变量和局部变量的区别：(1)在类中的位置不同： 成员变量：在类中方法外。 局部变量：在方法定义中或者方法声明上(即形参)。(2)在内存中的位置不同： 成员变量：在堆中。 局部变量：在栈中。(3)生命周期不同： 成员变量：随着对象的创建而存在，随着对象的消失而消失。 局部变量：随着方法的调用而存在，随着方法的调用完毕而消失。(4)初始化值不同： 成员变量：有默认值。 局部变量：没有默认值，必须定义，赋值，然后才能使用。 12、直接引用与符号引用符号引用：在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。 直接引用：直接引用可以是直接指向目标的指针 11、==与equals方法==：判断两个对象的地址是不是相等，即判断两个对象是不是同一个对象，基本数据类型比较的是值，引用数据类型比较的是内存地址 equals：若没有重写equals方法，则比较对象时，等价于“==”，若重写了equals，则等价于重写的相等的逻辑 public class Main{ public static void main(String[] args) { String a = new String(\"ab\"); // a 为⼀个引⽤ String b = new String(\"ab\"); // b为另⼀个引⽤,对象的内容⼀样 String aa = \"ab\"; // 放在常量池中 String bb = \"ab\"; // 从常量池中查找 //true，同一对象 System.out.println(aa==bb); //false，非同一对象 System.out.println(a == b); //String对equals方法进行了重写，a的值与b的值相等 System.out.println(a.equals(b))； }} 12、重写equals方法为什么要重写hashcode()equals方法在没有被重写前，比较的是对象的内存地址，而重写后，可能不是同一对象的equals方法也相等 hashcode的作用是为了获取hash码，定位哈希表中索引的位置，是一个基于内存地址的int整数，而当重写了equals方法后，即使equals方法相等，hashcode也极大概率不等，这时如果我们用重写了equals方法的object作为hash表的key，那么会造成一个从hash表中取值为null的现象，因此需要重写equals方法，使得两者保持一致性 13、java复制为什么说java只有值传递值传递：是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。 引用传递：是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。 而在java中，方法中对参数的修改是不会影响到实际参数的，因此属于值传递 浅拷贝对基本数据类型进行值传递；如果该字段是引用类型的话，则复制引用但不复制引用的对象 ，因此原始对象及其副本引用同一个对象 深拷贝对基本数据类型进行值传递；如果该字段是引用类型的话，则创建一个新的对象，并复制其内容，返回这个新的对象 14、final关键字修饰变量：如果是基本数据类型，则其数值一旦在初始化后就不能更改；如果是引用类型的变量，则对齐初始化后边不能再指向另一个对象 修饰类：表明这个类不能被继承 修饰方法：防止该方法被继承，private方法都隐式都指定为final 15、java异常体系 如果某个方法不能按照正常的途径完成任务，就可以通过另一种路径退出方法。在这种情况下会抛出一个封装了错误信息的对象。此时，这个方法会立刻退出同时不返回任何值。另外，调用这个方法的其他代码也无法继续执行，异常处理机制会将代码执行交给异常处理器 异常分类Error：类是指 java 运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果出现了这样的错误，除了告知用户，剩下的就是尽力使程序安全的终止。Exception（RuntimeException、 CheckedException）：RuntimeException 如 ： NullPointerException、ClassCastException； 一个是检查异常CheckedException，如 I/O 错误导致的 IOException、 SQLException。 处理方式抛出异常有三种形式，一是 throw,一个 throws，还有一种系统自动抛异常 ： throws 用在函数上，后面跟的是异常类，可以跟多个； 而 throw 用在函数内，后面跟的是异常对象 try-catchtry块：用于捕获异常，其后可跟0或多个catch块，如果没有catch块，则必须跟一个finally块 catch块：用于处理try捕获到的异常 finally块：无论是否捕获到或者处理了异常，finally块里的语句都会被执行,弱try或者catch语句有return语句时，finally中的语句会被执行，若有返回值会覆盖原始的返回值，如下例子，最终返回0 public static int f(int value) { try { return value * value; } finally { if (value == 2) { return 0; } }} 16、java语言的反射机制指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法；并且对于任意一个对象，都能够调用它的任意一个方法；这种动态获取信息以及动态调用对象方法的功能称为 Java 语言的反射机制 获取calss对象的三种方法//1、调用某个对象的getClass()方法： Person p=new Person(); Class clazz=p.getClass();//2、调用某个类的 class 属性来获取该类对应的 Class 对象：如 Class clazz=Person.class;//3、使用 Class 类中的 forName()静态方法(最安全/性能最好/最常用) ：如 Class clazz=Class.forName(\"类的全路径\"); 获取类方法属性信息//Field 类：Java.lang.reflec 包中的类，表示类的成员变量，可以用来获取和设置类之中的属性值Field[] field=clazz.getDeclaredFields(); for(Field f:field){ System.out.println(f.toString());}//Method 类：Java.lang.reflec 包中的类，表示类的方法，它可以用来获取类中的方法信息或者执行方法Method[] method=clazz.getDeclaredMethods();for(Method m:method){ System.out.println(m.toString()); }//Constructor 类：Java.lang.reflec 包中的类，表示类的构造方法Constructor[] constructor=clazz.getDeclaredConstructors(); for(Constructor c:constructor){ System.out.println(c.toString()); } 通过反射创建对象的方法//1、使用 Class 对象的 newInstance()方法来创建该 Class 对象对应类的实例，但是这种方法要求 该 Class 对象对应的类有默认的空构造器Person p=(Person) clazz.newInstance();//2、先使用 Class 对象获取指定的 Constructor 对象，再调用 Constructor 对象的 newInstance() 方法来创建 Class 对象对应类的实例Constructor c=clazz.getDeclaredConstructor(String.class,String.class,int.class);Person p1=(Person) c.newInstance(\"李四\",\"男\",20); 17、对象的序列化和反序列化序列化：把对象转换为字节序列的过程称为对象的序列化。保存(持久化)指定的对象，并在将来重新读取被保存的对象。 反序列化：把字节序列恢复为对象的过程称为对象的反序列化 对于不想序列化的变量，使用transient关键词修饰 18、java泛型泛型，即“参数化类型”。就是将类型由原来的具体的类型参数化 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"java基础","slug":"java基础","permalink":"https://xulilei.github.io/tags/java%E5%9F%BA%E7%A1%80/"}]},{"title":"秋招基础复习之多线程（二）","date":"2020-07-11T07:32:32.000Z","path":"2020/07/11/秋招复习之多线程2/","text":"秋招基础复习之多线程（二）AQSAQS（AbstractQueuedSynchronizer 类）是一个用来构建锁和同步器的框架，各种 Lock 包中的锁（常用的有 ReentrantLock、 ReadWriteLock，countdownlatch、cyclicbarrier）都是基于 AQS 来构建 AQS 工作原理AQS的核心思想是，如果被请求的资源空闲，则将当前请求的线程设置为工作线程，并将该资源设置为锁定状态。如果被请求的资源已经被占用，那么就需要一套线程阻塞等待以及唤醒时锁分配的机制，而这个机制是通过CLH队列锁实现的，即将分配不到锁的线程加入到队列中 CLH锁CLH队列是一个虚拟的双向队列，即不存在队列的实例，仅存在节点之间的关联关系，AQS将请求线程封装成CLH队列的一个Node节点，是一个FIFO的过程 AQS工作步骤AQS 在内部定义了一个 volatile int state 变量，表示同步状态：当线程调用 lock 方法时，会通过tryAcquire()独占该锁 ，如果 state=0，说明没有任何线程占有共享资源的锁，可以获得锁并将 state=1；如果 state不为0，先判断是否属于重入的情况，不是的话，则说明有线程目前正在使用共享变量，则该线程必须加入同步队列（CLH）的队尾进行等待，直到占有资源的线程通过tryRelease()对state进行减一操作释放锁到state=0，其他线程才能够去获取该锁。 AQS公平锁非公平锁 公平锁：在获取锁时，增加了一个当前线程是否为head结点的判断，当且仅当等待队列为空或者当前线程是等待队列的head结点时才会获取该锁 非公平锁：那些尝试获取锁且尚未进入等待队列的线程会和等待队列的head节点的线程发生竞争 AQS组件ReentrantLock与Synchronized 相比，可重入锁ReentrantLock其实现原理有什么不同？实现方式角度：synchronized操作Mark Word，lock调用AQS的state和FIFO队列来控制加锁 Synchronized 通过在对象头中设置标记实现了这一目的，是一种 JVM 原生的锁实现方式 而 ReentrantLock 以及所有的基于 Lock 接口的实现类，都是通过用一个 volitile 修饰的 int 型变量，并保证每个线程都能拥有对该 int 的可见性和原子修改， 其本质是基于 AQS 框架。 从锁释放角度 Synchronized 在 JVM 层面上实现的，不但可以通过一些监控工具监控 Synchronized 的锁定，而且在代码执行出现异常时，JVM 会自动释放锁定； Lock 是通过代码实现的，需要通过 unLock() 来释放锁 从功能角度，ReentrantLock 比 Synchronized 的同步操作更精细 如等待可中断：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，对处理执行时间非常长的同步块很有用。 带超时的获取锁尝试：在指定的时间范围内获取锁，如果时间到了仍然无法获取则返回。 可以判断是否有线程在排队等待获取锁，以及是否获取成功。 可以实现公平锁。 ReadWriteLock虽然 ReentrantLock 和 Synchronized 简单实用，但是行为上有一定局限性，要么不占，要么独占。实际应用场景中， 有时候不需要大量竞争的写操作，而是以并发读取为主，为了进一步优化并发操作的粒度，Java 提供了读写锁。 读写锁基于的原理是多个读操作不需要互斥，如果读锁试图锁定时，写锁是被某个线程持有，读锁将无法获得，而只好等待对方操作结束， 这样就可以自动保证不会读取到有争议的数据 CountDownLatch CyclicBarrierCyclicBarrier 叫循环栅栏，它实现让一组线程等待至某个状态之后再全部同时执行，而且当所有等待线程被释放后，CyclicBarrier 可以被重复使用。 线程池1：降低线程切换所带来的资源消耗 2：解耦作用：线程的创建于执行分开，方便维护 3：便于其他线程的复用 实现原理 在 Java 中，所谓的线程池中的“线程”，其实是被抽象为了一个静态内部类 Worker，它基于 AQS 实现，存放在线程池 的HashSet workers 成员变量中； 需要执行的任务则存放在BlockingQueue workQueue中。 这样，整个线程池实现的基本思想就是：从workQueue 中不断取出需要执行的任务，放在 Workers 中进行处理。 创建线程池阿里的开发手册不允许使用Executors去创建线程池，而是通过ThreadPoolExecutor ？通过Executors创建的线程池，通过内部构造方法生成的线程池的初始参数会导致OOM FixedThreadPool 和SingleThreadExecutor：初始化请求队列的长度为Integer.MAX_VALUE，可能会堆积大量请求，导致OOM CachedThreadPool和ScheduledThreadPool：允许创建线程池的数量为Integer.MAX_VALUE，可能会创建大量线程导致OOM ThreadPoolExecutor类分析常见参数corePoolSize：线程池的核心线程数。 在刚创建线程池时线程不会立即启动，到有任务提交时才开始创建线程并逐步线程数目达到corePoolSize maximumPoolSize：线程池允许的最大线程数。 当核心线程满，且阻塞队列也满时，才会判断当前线程数是否小于最大线程数，才决定是否创建新线程 keepAliveTime：超过核心线程数时闲置线程的存活时间。workQueue：任务执行前保存任务的队列，保存由 execute 方法提交的 Runnable 任务。handler：线程池允许的最大线程数。 线程池中的线程已经用完了，无法继续为新任务服务，等待队列也已经排满了，再也塞不下新任务了，这时候我们就需要拒绝策略机制合理的处理这个问题。 线程池种类SingleThreadExecutor 线程池 这个线程池只有一个核心线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束， 那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 FixedThreadPool 线程池 固定大小的线程池，只有核心线程。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。 线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 CachedThreadPool 线程池 无界线程池，如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60 秒不执行任务）线程， 当任务数增加时，此线程池又可以智能的添加新线程来处理任务。 ScheduledThreadPool 线程池 核心线程池固定，大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 ThreadPoolExecutor handler拒绝策略AbortPolicy ： 直接抛出异常，阻止系统正常运行 CallerRunsPolicy ： 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。 DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。 DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。 执行execute()⽅法和submit()方法的区别是什么呢？execute()：用于提交不需要返回值的任务，所以通常传入Runnable对象 submit()： 用于提交需要返回值的任务，线程池会返回一个Futrue类型的对象，通过get获取返回值，因此通常传入Callable对象 创建线程池过程 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务； 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列； 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务； 如果等待队列满了的同时，正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会执行拒绝策略。 当一个线程完成任务时，它会从队列中取下一个任务来执行。 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断。 如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。 ThreadLocalThreadLocal，线程本地存储， ThreadLocal 的作用是提供线程内的局部变量， 这种变量只在本线程的生命周期内起作用 实现原理ThreadLocal类中有一个静态内部类ThreadLocalMap，相当于一个哈希表，用private Entry[ ] table来存储数据，其中Entry是一个实现了弱引用（下次GC会被回收）的内部类，它的key为弱引用，目的是为了在GC时防止内存泄漏。而value是强引用，GC是会产生key为null，值为value无法回收的内存，造成内存泄露，ThreadLocalMap会在key回收时，自动清理掉key为null的记录 原子类以AtomicInteger为例 public final int get() //获取当前的值public final int getAndSet(int newValue)//获取当前的值，并设置新的值public final int getAndIncrement()//获取当前的值，并⾃增public final int getAndDecrement() //获取当前的值，并⾃减public final int getAndAdd(int delta) //获取当前的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输⼊的数值等于预期值，则以原⼦⽅式将该值设置为输⼊值（update） AtomicInteger原理AtomicInteger主要利用CAS+Volatile+Native方法来保证原子操作，通过本地方法objectFieldO!set()拿到原来值的内存地址，再拿到Volatile修饰的value，最后再通过CAS来进行最终更新值的操作，足以保证在任何时刻任何线程拿到的都是该变量的最新值 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"多线程","slug":"多线程","permalink":"https://xulilei.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"秋招基础复习之多线程（一）","date":"2020-07-10T07:16:32.000Z","path":"2020/07/10/秋招复习之多线程/","text":"秋招基础复习之多线程（一）线程线程和进程的区别？进程是系统资源分配的最小单位，线程是CPU调度的基本单位 线程不能看成独立应用，而进程可以 进程有独立的地址空间，相互不影响，而线程没有独立的地址空间，只是进程的不同执行路径 进程的切换开销比线程大 Java进程和线程的关系运行一个程序会产生一个进程，一个进程至少一个线程 每个进程对应一个JVM实例，多个线程共享JVM的堆 线程的状态(6种)初始(NEW)：新创建了一个线程对象，但还没有调用start()方法。 运行(RUNNABLE)：Java线程中将就绪（ready）和运行中（running）两种状态笼统的称为“运行”。 阻塞(BLOCKED)：表示线程阻塞于锁。 等待(WAITING)：进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断)不会被分配CPU执行时间，由Object.wait()和Thread.join()导致 超时等待(TIMED_WAITING)：该状态不同于WAITING，它可以在指定的时间后自行返回。 终止(TERMINATED)：表示该线程已经执行完毕 start和run方法的区别run()方法只是Thread的一个普通方法的调用，会继续使用当前线程执行该方法 start()方法会创建一个新的子线程并启动,start()方法会调用JVM的StartThread方法创建一个子线程，并且通过thread_entry方法取调用子线程中的run方法 Thread类和Runnable接口是什么关系?Thread是实现了Runnable接口的类，使得run支持多线程 因为类的单一继承性，推荐多使用Runnable接口 Runnable需要通过构造:Thread t = new Thread(new Runnable())启动 如何实现处理线程的返回值1：主线程等待法(缺点是需要自己实现循环的等待方法，变量多的话代码臃肿) 2：使用Thread类的join()阻塞当前线程以等待子线程处理完毕，缺点是不能更精细的处理，只能等待join()线程全部执行完毕 3：通过Callable接口实现：FutureTask和线程池获取 利用FutureTask获取: FutureTask&lt;&gt; task = new FutureTask&lt;&gt;(new MyCallable())，这里的MyCallable必须实现Callable接口,然后new Thread(task).start()开启新线程，调用task.get();可以或者返回值 利用线程池获取: ExecutorService newCachedThreadPool = Executors.newCachedThreadPool(); 然后调用线程池的提交方法Future future = newCachedThreadPool.submit(new MyCallable()); 返回一个Future，调用future.get()获取返回值 sleep()和wait()的区别sleep是Thread类的方法，wait是Object类中定义的方法，也是native中的方法 sleep()方法可以在任何地方使用，而wait()方法只能在synchionized方法或synchronized块中使用 最本质区别： Thread.sleep只会让出CPU，不会导致锁行为的改变 Object.wait()不仅让出CPU，还会释放已经占有的同步资源锁，并进入等待池中，不会再竞争锁，需要通过notify或者notifyAll()唤醒 锁池和等待池的区别锁池：假设某个线程想进入一个对象的synchronized方法，而这个对象锁却被其他线程所占有，该线程就会进入一个地方取等待锁的释放，这个地方就是锁池 等待池：假设线程A调用了某个对象的wait方法，线程A就会释放该对象的锁，同时进入该对象的等待池中，进入到等待池中的线程不会取竞争该对象的锁，除非被 notify唤醒 notify()和notifyAll()的区别 notify只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会 notifyAll会让所有处于等待池的线程全部进入锁池去竞争获取锁的机会 interrupt()调用interrupt()，通知线程应该中断了 1：如果线程处于被阻塞状态，那么线程将立即退出被阻塞状态，并且抛出一个InterruptedException异常。 2：如果线程处于正常活动状态，那么会将线程的中断标志设置为true，设置中断标志的线程将继续正常运行，不受影响,在运行任务时，我们已经经常检查本线程的中断标志位，如果被设置了中断标志，就自行停止线程 调用stop()，是让线程强制执行，已经不再推荐使用 死锁线程死锁和进程死锁线程死锁：线程A想要持有线程B持有的资源1，线程B想要持有线程A持有的资源2，互相等待，造成死锁 进程死锁的四大条件 互斥条件：即任意时刻，一个资源只能有一个线程持有 请求与保持：在一个线程请求资源而阻塞的时候，不会释放自己已经持有的资源 不可剥夺：线程已经获得的资源不能被其他线程强行剥夺，只能等待自己释放 循环等待：若干进程之间形成一种头尾相接的循环等待的关系 如何避免死锁破坏进程死锁的四大条件 互斥条件：这个做不到 请求与保持：一次性申请所有用到的资源，申请不到线程不工作 不可剥夺：申请其他资源时，如果一段时间申请不到则主动释放已持有的资源 循环等待：破坏循环等待 synchronized线程安全的主要诱因 1：存在共享数据（也成临界资源） 2：存在多条线程共同操作这些共享数据 解决线程安全问题的根本方法 同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再对共享数据进行操作 互斥锁的特性 互斥性：在同一时间只允许一个线程持有某个对象锁 可见性：必须确保在锁被释放之前，对共享变量所做的修改，对于随后获得该锁的另一线程是可见的 什么是可重入性 ，为什么说 Synchronized是可重入锁？ 从互斥性的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁时，将会处于阻塞状态，但当一个线程再次请求自己持有对象的锁时，这种情况属于重入。可重入性是锁的一个基本要求，如果不能够重入，会发生自己锁死自己的情况。 获取对象锁的两种用法 同步代码块，synchronized(this)，锁的是括号中的实例对象，代码块的外面，方法的里面还是异步的。 同步非静态方法（synchronized method），锁的是当前对象的实例对象，方法整个都是同步的，需要获得当前对象的锁 获取类锁的两种用法 同步代码块 synchronized(类.class) 锁的是小括号()中的类对象(Class对象) 同步静态方法 synchronized static method 锁的是当前对象的类对象(Class对象) 底层实现 Java对象在内存中由三部分组成，对象头，实例数据，对齐填充，其中对象头的是synchronized的核心，其中的Mark Word部分存储着锁信息，包括锁的类型，状态标志，通过在对象头设置标记，从而达到了获取锁和释放锁的目的 monitor:每个java对象天生自带了一把看不见的锁,就是monitor锁，在java虚拟机中，monitor是由ObjectMonitor(在JVM中由C++)实现的，查看JVM中ObjectMonitor源码，里面有一个count_计数器 sychronized方法：生成的字节码文件中会多一个ACC_SYNCHRONIZED标志位，当一个线程访问方法时，会先取检查是否存在ACC_SYNCHRONIZED标志，如果存在，执行线程将先获取monitor，获取成功后才能执行方法体，方法执行完后再释放monitor。方法执行期间，其他任何线程都无法再获得同一个monitor对象 synchronized代码块：加了synchronized关键字的代码段，生成的字节码文件中会多出monitorenter和monitorexit两条指令，每个monitor维护着一个记录着次数的计数器_count，未被拥有的monitor的该计数器为0，当一个线程执行monitorenter指令，当前线程试图获取对象锁，如果此时的monitor的count计数器为0，线程成功获得monitor，计算器加1，当同一个线程执行了monitorexit指令，计算器减1，当计算器为0时，monitor便被释放. JDK6以后对于synchronized的优化自旋锁和自适应自旋锁 许多情况下，共享数据的锁定状态持续时间较短，切换线程不值得，通过让线程执行忙循环等待锁的释放，不让出CPU、 缺点：若锁被其他线程长时间占用，会带来许多性能上的开销 自适应自旋锁：自旋的次数不再固定，由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定 锁消除 如果某个锁不可能被其他线程引用，比如局部变量，由于栈私有，JVM会自动消除内部对象的锁 锁粗化 如果检测到一连串的操作都是对同一个对象加锁，JVM会将锁的范围粗化到这一连串操作的外部 synchronized锁的四种状态以及升级过程过程 无锁–偏向锁–轻量级锁–重量级锁 偏向锁: 如果一个线程获得了锁，那么锁就进入偏向模式，Mark Word结构也变为了偏向锁结构，当该线程再次请求锁时，只需要检查Mark Word的锁标记位为偏向锁以及当前线程的ID等于Mark Work 的ThreadID即可。 不适用于锁竞争比较激烈的多线程场合 轻量级锁 轻量级锁由偏向锁升级来的，当第二个线程加入锁的争用时，偏向锁会升级为轻量级锁 每个线程都有自己的栈针，会在栈针中生成一个LockRecord指针，通过CAS去争夺这个锁，LR修改成功的线程获得该锁，而另一个线程会自动进入循环CAS获取这个锁的过程，该过程被称为自旋，因此轻量级锁也被称为自旋锁 重量级锁 轻量级锁自旋锁由于一直处于循环CAS的过程，会占据一定量的系统资源，自JDK6后JVM会自适应控制自选次数，当自选次数超过该阈值，则会自动升级为重量级锁。 升级成重量级锁后，会形成一个队列，没有竞争到锁的线程会进入该队列，且不消耗系统资源 三种锁的优缺点以及使用场景 偏向锁的优缺点以及使用场景 优点：加锁和解锁不需要CAS操作，没有额外的性能消耗，和非同步方法相比性能差距较小 缺点：如果线程间存在锁竞争，会带来额外的锁撤销的消耗 使用场景：只有一个线程访问同步块或者同步方法 轻量级锁的优缺点以及使用场景 优点：竞争的线程不会阻塞，提高了响应速度 缺点：若线程长时间抢不到锁，自旋会消耗CPU性能 使用场景：线程交替执行同步块或者同步方法的场景 重量级锁的优缺点以及使用场景 优点：线程竞争不适用自旋，不会消耗CPU 缺点：线程阻塞，相应时间缓慢，在多线程下，频繁的获取释放锁，会带来巨大的性能消耗 使用场景：追求吞吐量，同步块或同步方法执行时间较长的场景 Volatile指令重排序指令重排序是编译器和处理器为了高效对程序进行优化的手段，它只能保证程序执行的结果时正确的，但是无法保证程序的操作顺序与代码顺序一致。这在单线程中不会构成问题，但是在多线程中就会出现问题。 指令重排序需要满足的条件 在单线程环境下不能改变程序运行的结果 不存在数据依赖关系的 不满足happens-before原则 Java内存模型JMM JMM中的主内存（main memory） 存储Java实例对象 包括成员变量，类信息，常量，静态变量 属于数据共享的区域，多线程并发操作会引发线程安全问题 JMM中的工作内存（L1,L2,L3） 存储当前方法的局部变量信息，局部变量对其他线程不可见 字节码行号指示器，Native方法信息 属于线程私有的数据区域，不存在线程安全问题 读写过程 将主存中的数据加载到工作内存中 CPU对工作内存中的数据进行修改 将每个线程工作内存中修改后的值刷新到主内存中 Volatile原理关键字 volatile 是 Java 虚拟机提供的最轻量级的同步机制。当一个变量被定义成 volatile 之后，具备两种特性： 1.保证此变量对所有线程的可见性。当一条线程修改了这个变量的值，新值对于其他线程是可以立即得知的。 2.禁止指令重排序。普通变量仅仅能保证在该方法执行过程中，得到正确结果，但是不保证程序代码的执行顺序。 如何实现上述两种特性？ 线程可见性：主要通过缓存一致性协议和总线锁两种方式实现 立即将线程中工作内存的数据写会到主内存中 其他处理器数据监测判断自己线程工作区内存中的值是不是过期了，如果过期了，就会将对应的数据置为无效。而当处理器对这个数据进行修改时，会重新从内存中把数据读取到缓存中进行处理。 禁止指令重排序： 代码级别：对变量加上volatile修饰 字节码级别：会生成ACC_volatile指令 JVM级别：通过JVM的内存屏障禁止内存屏障前后的指令执行重排序优化 DCL单例模式需不需要volatile指令？需要，因为在new一个对象的过程中对象并不是刚被创建就会将构造函数中的参数赋值给变量，而是会有一个半初始化的状态，此时如果发生指令重排序会使得别的线程拿到这个半初始化的对象，造成BUG，因此需要双重检测（对象创建的过程见https://xulilei.github.io/2020/07/06/%E7%A7%8B%E6%8B%9B%E5%A4%8D%E4%B9%A0%E4%B9%8BJVM/） //单例模式public class Singleton{ private Volatile static Singleton instance; private Singleton(){}; public static Singleton getInstance(){ //第一次检测 if(instance==null){ synchronized(Singleton.class){ //第二次检测 if(instance==null){ instance=new Singleton(); } } } return instance; }} Syncronized和volatile对比 volatile本质是告诉JVM当前变量在工作内存中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住直到该线程完成变量操作为止。 volatile仅能使用在变量上；synchronized则可以使用在变量，方法和类级别 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞 volatile仅能实现变量的修改的可见性，不能保持原子性；而synchronized则可以保证变量修改的可见性和原子性 CAS 实现过程 底层通过Unsafe类实现原子性操作，包括三个操作数——内存地址V，预期原值A和新值B 将内存地址的值与预期原值进行比较，如果匹配，那么处理器将该位置的值，自动更新为新值，否则会进行自旋，然后再重新以当前的值为原值再次比较，这也是自旋锁实现的基础 乐观锁悲观锁 悲观锁Syncronized：是典型的悲观锁，总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。 乐观锁CAS：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据 CAS缺点（乐观锁的缺点） 如果自旋时间长，则CPU资源开销很大 只能保证一个共享变量的原子操作 ABA问题 如果内存地址V初次读取的值为A，并且在准备赋值的时候检查到也为A，如果它曾经被改为了B，但是后来又被改成了A，那么CAS就会误认为它从来没被改变过 解决：给值加上一个版本号每当修改一次将值加1，或者使用AtomicStampedReference（ 版本戳） document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"多线程","slug":"多线程","permalink":"https://xulilei.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"秋招复习之集合","date":"2020-07-08T04:59:33.000Z","path":"2020/07/08/秋招复习之集合/","text":"秋招基础复习之集合 集合类存放于 Java.util 包中， 主要有 3 种： set(集）、 list(列表包含 Queue）和 map(映射)。Collection： Collection 是集合 List、 Set、 Queue 的最基本的接口。Iterator：迭代器，可以通过迭代器遍历集合中的数据。Map：是映射表的基础接口 。 Collection对比 ListArrayList（数组，线程不安全）ArrayList 是最常用的 List 实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数组的缺点是每个元素之间不能有间隔， 当数组大小不满足时需要增加存储能力，就要将已经有数组的数据复制到新的存储空间（1.5倍扩容）中。 当从 ArrayList 的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。 Vector（ 数组，线程安全）Vector 与 ArrayList 一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写 Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问 ArrayList 慢。 LinkList（链表，线程不安全）LinkedList 是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较慢。 SetHashSet（Hash表）哈希表边存放的是哈希值。 HashSet 存储元素的顺序并不是按照存入时的顺序（和 List 显然不同） 而是按照哈希值来存的所以取数据也是按照哈希值取得。元素的哈希值是通过元素的hashcode 方法来获取的, HashSet 首先判断两个元素的哈希值，如果哈希值一样，接着会比较equals 方法 如果 equls 结果为 true ， HashSet 就视为同一个元素。如果 equals 为 false 就不是同一个元素。HashSet 通过 hashCode 值来确定元素在内存中的位置。 一个 hashCode 位置上可以存放多个元素。 TreeSet（二叉树）TreeSet()是使用二叉树的原理对新添加的对象按照指定的顺序排序（升序、降序），每增加一个对象都会进行排序，将对象插入的二叉树指定的位置。Integer 和 String 对象都可以进行默认的 TreeSet 排序，而自定义类的对象是不可以的， 自己定义的类必须实现 Comparable 接口，才可以正常使用。 LinkHashSet（ HashSet+LinkedHashMap）对于 LinkedHashSet 而言，它继承与 HashSet、又基于 LinkedHashMap 来实现的。由于底层使用 LinkedHashMap 来保存所有元素 ，因此可以通过双向链表来记录插入的顺序 Map HashMap底层实现JDK1.7实现数组+链表 HashMap 的主干是一个数组，然后数组中每个元素是一个单向链表。上图中，每个绿色的实体是嵌套类 Entry 的实例， Entry 包含四个属性： key, value, hash 值和用于单向链表的 next。 //默认大小static final int DEFAULT_INITIAL_CAPACITY = 16;//最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//默认负载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;//存储元素的数组transient Entry[] table;//键值对数量transient int size;//阈值，size大于阈值触发扩容int threshold;//负载因子默认是0.75final float loadFactor;//修改次数transient volatile int modCount; Put的过程public V put(K key, V value) { //容器为空时，调用初始化方法，找到大于threshold的最小二次幂数 if (table == EMPTY_TABLE) { inflateTable(threshold); } //键为空则存放入数组第0个元素，如果之前有key为null的元素，则新元素将旧元素替换返回，否则创建新的元素并返回null，来看一下创建新元素的逻辑： if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); //弱key存在，则用新value覆盖oldvalue，并返回覆盖后的值 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(hash, key, value, i); return null;} 主要实现方法 //addEntry过程 void addEntry(int hash, K key, V value, int bucketIndex) { if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) { resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex); }//在数组下标为bucketIndex的位置创建节点，并将之前的头结点作为新结点的next结点，实现了链表头部插入元素，这样做的好处很明显，节省了插入的效率 void createEntry(int hash, K key, V value, int bucketIndex) { Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++; } //h（hash）与数组长度-1进行按位与操作，这个操作就保证了插入元素一定是在数组内部 static int indexFor(int h, int length) { // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return h &amp; (length-1); } resize过程 void resize(int newCapacity){ Entry[] oldTable = table; int oldCapacity = oldTable.length; ...... //创建一个新的Hash Table Entry[] newTable = new Entry[newCapacity]; //将Old Hash Table上的数据迁移到New Hash Table上 transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);}//resize()方法中的transfer()，采用头插法 void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) { while(null != e) { Entry&lt;K,V&gt; next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } } } 造成死循环的原因在扩容的过程中，将原来hashMap数组中的链表转移到新的hashmap中时，采用的是头插法进行指针操作，会将原hashmap的链表顺序反转，但如果此时再进来一个线程，会导致next指针指向一个环，形成死循环 JDK1.8实现数组+链表+红黑树，当链表中的元素超过了 8 个以后，会将链表转换为红黑树 put过程public V put(K key, V value) { return putVal(hash(key), key, value, false, true); }final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //初始化时，map中还没有key-value if ((tab = table) == null || (n = tab.length) == 0) //利用resize生成对应的tab[]数组 n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) //当前桶无元素 tab[i] = newNode(hash, key, value, null); else {//桶内有元素 Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //桶内第一个元素的key等于待放入的key，用 e = p; else if (p instanceof TreeNode) //如果此时桶内已经树化 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else {//桶内还是一个链表，则插入链尾（尾插） for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //变成红黑树 treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } //检查是否应该扩容 ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; } 示意图 resize过程采用尾插法，容量扩充为原来的两倍，再对每个节点重新计算hash值 HashMap面试问题总结1、为什么hashmap的长度是2的幂次方？首先不可能直接用散列化后的值直接作为数组下标，而是需要对长度进行取模运算，再得到下标。这个数组下标的计算方法为（n-1）&amp;hash。之所以使用与操作是因为与操作的性能优于取余。而当length是2的幂次方时，hash%length==hash&amp;（length-1），因此长度是2的幂次方。 2、hashmap1.7与1.8的区别(1)结构不同，1.7采用数组+链表，1.8采用数组+链表+红黑树 (2)插入位置不同，JDK1.7用的是头插法，而JDK1.8及之后使用的都是尾插法，因为JDK1.7是用单链表进行的纵向延伸，当采用头插法时可以避免遍历链表造成的性能损失，但是会容易出现逆序及多线程下环形链表死循环问题。但是在JDK1.8之后因为加入了红黑树使用尾插法，插入效率提升，且能够避免出现逆序和链表死循环的情况 (3)扩容数据存储位置的计算方式不一样，1.7通过扰动之后的hash&amp;（length-1）得到数组下标，1.8在扩容中只用判断原来的 hash 值与数组长度左移动的一位(扩大一倍)按位与操作是 0 或 1 就行，0 的话索引就不变，1 的话索引变成原索引加上扩容前数组 (4)扩容时数据的插入时机，1.7是先扩容后插入，1.8是先插入后扩容 3、为什么HashMap是线程不安全的，实际会如何体现第一，如果多个线程同时使用put方法添加元素:假设正好存在两个put的key发生了碰撞(hash值一样)，那么根据HashMap的实现，这两个key会添加到数组的同一个位置，这样最终就会发生其中一个线程的put的数据被覆盖 第二、hashmap1.7在扩容时，由于采取头插法会导致死循环 ConCurrentHashMap底层实现hashTable实现 JDK1.7实现首先将数据分为一段一段的存储，然后给每一段分配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据仍然能够被访问 JDK1.8实现1.8的ConcurrentHashMap取消了分段锁，采用CAS和syncronized来保证并发安全，syncronized只锁定一个node链表的首节点 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"集合","slug":"集合","permalink":"https://xulilei.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"秋招基础复习之JVM","date":"2020-07-06T07:07:16.000Z","path":"2020/07/06/秋招复习之JVM/","text":"秋招基础复习之JVMJVM内存模型 JVM-GC垃圾回收知识点概览 判断对象可回收引用计数法（JVM中不用）给对象添加一个计数器，每当有一个地方引用计数器+1，反之失效-1，当计数器为0的时候，则代表该对象不太可能会被继续用到，则判断该对象为可回收对象，但是会出现循环引用的问题 可达性分析算法为了解决引用计数法的循环引用问题， Java 使用了可达性分析的方法。通过一系列的“GC roots”对象作为起点搜索。如果在“GC roots”和一个对象之间没有可达路径，则称该对象是不可达的。 GC roots：类加载器，Thread，虚拟机栈的局部变量表，static成员，本地方法栈等 强软弱虚引用强引用在 Java 中最常见的就是强引用， 把一个对象赋给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它处于可达状态，它是不可能被垃圾回收机制回收的，即使该对象以后永远都不会被用到 JVM 也不会回收。因此强引用是造成 Java 内存泄漏的主要原因之一。 软引用软引用需要用 SoftReference 类来实现，对于只有软引用的对象来说，当系统内存足够时它不会被回收，当系统内存空间不足时它会被回收。软引用通常用在对内存敏感的程序中。 弱引用弱引用需要用 WeakReference 类来实现，它比软引用的生存期更短，对于只有弱引用的对象来说，只要垃圾回收机制一运行，不管 JVM 的内存空间是否足够，总会回收该对象占用的内存。 虚引用不能单独使用，必须和引用队列联合使用。 虚引用的主要作用是跟踪对象被垃圾回收的状态。 垃圾收集算法分代收集算法新生代的复制算法eden、survivorFrom SurvicorTo按照8比1比1划分新生代 1：eden、 survivorFrom 复制到 SurvivorTo，年龄+1首先，把 Eden 和 survivorFrom 区域中存活的对象复制到 SurvivorTo 区域（如果有对象的年龄以及达到了老年的标准15，则赋值到老年代区），同时把这些对象的年龄+1（如果 SurvivorTo 不够位置了就放到老年区）； 2：清空 eden、 survivorFrom然后，清空 Eden 和 survivorFrom 中的对象 3： SurvivorTo和 ServicorFrom 互换最后， SurvivorTo 和 survivorFrom互换，原 SurvivorTo 成为下一次 GC 时的 survivorFrom区。 老年代的标记-整理算法首先扫描一次所有老年代，标记出存活的对象，让所有存活对象都向一端移动，然后直接清理掉端边界以外的内存 分区收集算法分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的好处是可以控制一次回收多少个小区间 , 根据目标停顿时间, 每次合理地回收若干个小区间(而不是整个堆), 从而减少一次 GC 所产生的停顿。 垃圾收集器 新生代Serial：单线程收集器，采用复制算法它不但只会使用一个 CPU 或一条线程去完成垃圾收集工作，并且在进行垃圾收集的同时，必须暂停其他所有的工作线程，直到垃圾收集结束。它简单高效，对于限定单个 CPU 环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此 Serial垃圾收集器依然是 java 虚拟机运行在 Client 模式下默认的新生代垃圾收集器。 Parnew：serial收集器的多线程版本，采用复制算法除了使用多线程进行垃圾收集之外，其余的行为和 Serial 收集器完全一样， ParNew 垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程，ParNew垃圾收集器是很多 java虚拟机运行在 Server 模式下新生代的默认垃圾收集 Parallel Scavenge：复制算法，可控制吞吐量的收集器该收集器关注的重点在吞吐量，对用户等待的时间不那么关注，因而适用于在后台运算而不需要太多交互的任务 老年代Serial Old：serial收集器的老年代版本，使用标记-整理算法工作时会暂停用户线程 Parallel Old：Parallel Scavenge收集器的老年代版本，多线程，标记-整理算法工作时会暂停用户线程 CMS：采用标记-清除算法由于耗时最长的并发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作， 所以总体上来看CMS 收集器的内存回收和用户线程是一起并发地执行。 第一步-初始标记只是标记一下 GC Roots 能直接关联的对象，速度很快，仍然需要暂停所有的工作线程。 第二步-并发标记进行 GC Roots 跟踪的过程，和用户线程一起工作，不需要暂停工作线程 第三步-重新标记为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。 第四步-并发清除清除 GC Roots 不可达对象，和用户线程一起工作，不需要暂停工作线程。 Garbage first： 分区收集以及采用标记-整理算法基于标记-整理算法，不产生内存碎片。可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。 G1 收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间， 优先回收垃圾最多的区域。区域划分和优先级区域回收机制，确保 G1 收集器可以在有限时间获得最高的垃圾收集效率。 JVM类加载机制类加载过程 加载加载是类加载过程中的一个阶段， 这个阶段会在内存中生成一个代表这个类的 java.lang.Class 对象 验证这一阶段的主要目的是为了确保 Class 文件的字节流中包含的信息语法符合当前虚拟机的要求 准备准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。 解析解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。 符号引用符号引用就是 class 文件中的： CONSTANT_Class_info、 CONSTANT_Field_info、 CONSTANT_Method_info 等类型的常量，在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。 直接引用直接引用可以是指向目标的指针。如果有了直接引用，那引用的目标必定已经在内存中存在 初始化初始化阶段是类加载最后一个阶段，前面的类加载阶段由 JVM 主导。到了初始化阶段，才开始真正执行类中定义的 Java 程序代码 类加载器类加载器的种类 启动类加载器(Bootstrap ClassLoader)：负责加载核心库java.*，由C++编写。 扩展类加载器(Extension ClassLoader)：负责加载扩展库，由java编写。 应用程序类加载器(Application ClassLoader)：负责加载程序所在目录，java编写。 以及自定义加载器。 双亲委派机制与全盘委派机制1、双亲委派机制：先自下而上的委托父类加载目标类，只有当父类加载器反馈自己无法完成这个请求的时候，子类加载器会自上而下的会尝试自己去加载 2、全盘委派机制：该类所依赖的类都由该类的类加载器加载 类加载方式new 隐式加载，支持传参，loadclass与forname显式加载，不支持传参。springioc可以懒加载 对象创建的步骤区别于类加载的过程1、虚拟机遇到new命令时，首先检查这个对应的类能否在常量池定位到一个符号引用 2、判断这个类是否已经被加载解析（解析让符号引用变成直接引用）和初始化，如果没有则进行相应的类加载过程 3、为新生对象在java堆中分配内存空间，这一步是半初始化（单例的双重检测机制就是为了防止半初始化） 4、设置对象头相关数据（GC分代年龄、对象的哈希吗、锁等元数据信息）–java对象模型 5、执行init方法，赋值 对象分配流程1、首先尝试栈上分配，即如果该对象的作用域不会逃逸出该方法之外，则可以将其分配在栈上，随着方法的结束而销毁，不用通过GC收集 2、若失败则采用tlab分配，会先构造一种线程私有的堆空间，哪怕这块堆空间特别小，但是只要有，就可以每个线程在分配对象到堆空间时，先分配到自己所属的那一块堆空间中，避免同步带来的效率问题，从而提高分配效率 3、若还是失败，则正常的分配至eden区，若太大则直接进入老年代 JVM核心参数-Xms：最小堆 -Xmx：最大堆 -Xmn：新生代内存 -Xss：栈大小 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"JVM","slug":"JVM","permalink":"https://xulilei.github.io/tags/JVM/"}]},{"title":"秋招基础复习之计网","date":"2020-07-05T07:39:30.000Z","path":"2020/07/05/秋招复习之计网/","text":"秋招基础复习之计网7 层模型主要包括： 物理层：设备之间的比特流传输。 数据链路层：主要将从物理层接收的数据进行 MAC 地址（网卡的地址）的封装与解封装。在这一层工作的设备是交换机，数据通过交换机来传输。 主要协议为ARP协议，提供IP 地址到对应的硬件地址提供动态映射 网络层：主要将从下层接收到的数据进行 IP 地址（例 192.168.0.1)的封装与解封装。在这一层工作的设备是路由器，常把这一层的数据叫做数据包。 传输层：定义了一些传输数据的协议和端口号（WWW 端口 80 等），如：TCP，UDP协议。 主要是将从下层接收的数据进行分段进行传输，到达目的地址后在进行重组。 常常把这一层数据叫做段。 会话层：通过传输层（端口号：传输端口与接收端口）建立数据传输的通路。主要在你的系统之间发起会话或或者接受会话请求（设备之间需要互相认识可以是IP也可以是 MAC 或者是主机名） 表示层：主要是进行对接收的数据进行解释、加密与解密、压缩与解压缩等（也就是把计算机能够 识别的东西转换成人能够能识别的东西（如图片、声音等）） 应用层：主要是一些终端的应用，比如说FTP（各种文件下载），WEB（IE浏览），QQ之类的（你 就把它理解成我们在电脑屏幕上可以看到的东西．就 是终端应用）。 TCP/IP协议TCP三次握手四次挥手三次握手 过程第一次握手：主机 A 发送位码为 syn＝1,随机产生seq序列号的数据包到服务器，第二次握手：主机B收到请求后要确认联机信息，同样向A发送syn=1，以及确认请求ACK=1，B的seq序列号，以及A的序列号+1的确认号，第三次握手：主机A收到后检查返回的确认号是否正确以及确认请求ACK是否为1，若正确，主机A会再发送确认请求ACK=1以及服务器B的序列号+1的确认号，主机B收到后确认确认序列号值与确认请求 Ack=1 则连接建立成功。 为什么要三次握手？即为什么A还要发送一次确认请求给服务器B，这是为了防止已经失效的连接请求突然又传送到了B。存在这样的一种情况，当A发送连接请求给B，此时由于网络拥堵造成服务器B没有及时收到连接请求，因此A又重新发送了一个请求给B，正常建立连接后，拥堵的第一次请求又传送到了服务器B，如果不采用三次握手，那么B又会发送确认连接的请求给B，又会建立一个新的连接，会浪费许多资源 syn攻击在第一次握手后，服务器向客户端发送确认请求信息后需要等待客户端的再次确认信息，如果此时客户端掉线，服务器会一直尝试发送5次请求信息，会浪费大量资源，可能导致正常的syn请求无法完成。 那么如何防护呢？ 当syn队列满后，通过tcp_syncookies参数回发syn_cookie给客户端，如果正常连接，客户端会回发这个syn_cookie给服务器，此时即使syn队列满了，依然可以正常建立连接 建立连接后客户端出现问题怎么办？服务器会发送保持会话报文，若一直没有响应一定次数，服务器会中断此次会话 四次挥手 过程首先由客户端发送一个FIN=1，以及seq=a的请求码给服务器，此时客户端进入等待关闭状态1，服务器收到客户端的关闭请求后，会立即发送一个确认关闭的ACK=1，以及a+1的确认码，和seq=b的序列号给客户端，告诉客户端我收到你关闭的请求了，客户端收到请求后会进入等待关闭状态2，当服务器传送玩最后的数据给客户端后，会发送一个确认关闭FIN=1，确认请求ACK=1确认序列a+1的确认号给客户端，意思是我传送玩所有的数据了，你可以关闭了。客户端在收到服务器第二次关闭请求后回回发最终确认ACK=1，以及第二次的确认序列+1的确认号给服务器，服务器收到后关闭连接，客户端在2MSL时间后关闭连接。 为什么要四次挥手？因为TCP是全双工的，客户端给服务器发送信息的同时，服务器也可以给客户端发送，之所以需要四次挥手，是因为在客户端发送结束请求后，可能服务器的数据还没有传输完毕，因此需要2个等待关闭的状态确保所有数据传输完毕，因此需要四次挥手 为什么客户端还要等待2msl？因为服务器给客户端发送的第二次FIN请求后，客户端回发给服务器的最终确认可能丢失，如果服务器没有收到最终确认，则会再次发送FIN请求给客户端，那么在客户端等待关闭的这2MSL里再次收到请求后，会再次发送最终请求，使得服务器能够正常准确的关闭 如何理解IP协议的不可靠和无连接？不可靠：指的是不能保证数据报能成功地到达目的地。 发生错误时候，丢弃该数据包，发送 ICMP 消息给信源端，可靠性由上层提供。 无状态：IP 不维护关于后续数据报的状态信息。 体现在，IP 数据可以不按顺序发送和接收。A 发送连续的数据报，到达B不一定是连续的， 来回路由选择可能不一样，路线也不一样，到达先后顺序也不一样。 TCP如何保证可靠性？1） 确认机制，发送报文后，等待确认。 2） 重发机制，没有收到确认，将重发数据段。 3） 拥塞控制：慢启动（逐渐增大窗口）、快速重传（收到失序报文立刻重传）、快速恢复（收到重复确认可能没有拥堵，因此不执行慢启动而是快速恢复）、拥塞避免（门限设为一般后开始慢启动算法） 4） 排序，有专门的序列号字段 5） 流量控制，通过滑动窗口实现 TCP与UDP区别 tcp对应的协议有：FTP、HTTP udp对应的协议有：DNS HTTP协议http请求报文和响应报文http请求报文由请求行（get/post方法，url的path路径，http版本）、请求头（键值对）、请求体（body） get/post区别1、get请求是通过URL传参，而post请求被放在请求体中，因此决定了get不能代替post发送大量数据 2、get请求的安全性不如post，是由于get请求在url中会被看到 3、get请求是幂等的，post不幂等（幂等就是多次操作结果一样，get查询多次肯定一样，post是改肯定不一样） http响应报文由状态码（Status Code）、HTTP头部（编码格式，过期时间）、响应体（响应的内容） 状态码1XX：请求已接受一部分，正等待剩余部分 2XX：正常接收 3XX：重定向，进一步操作 4XX：客户端请求出错 5XX：服务端出错 http请求过程1、DNS域名解析器解析出IP地址 2、TCP连接（三次握手） 3、浏览器发送HTTP请求 4、服务器处理请求并返回HTTP响应 5、浏览器解析渲染页面 6、释放连接（四次挥手） http长连接，短连接，无状态，HTTP/1.0，HTTP/1.1，HTTP/2.0无状态无状态：HTTP 协议是无状态的，指的是协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。也就是说，打开一个服务器上的网页和上一次打开这个服务器上的网 页之间没有任何联系。HTTP 是一个无状态的面向连接的协议，无状态不代表 HTTP 不能保 持 TCP 连接，更不能代表 HTTP 使用的是 UDP 协议（无连接）。 长短连接HTTP/1.0 短连接：客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。适用于而像 WEB 网站的http服务 HTTP/1.1 默认使用长连接：在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据 的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。适用于于操作频繁，点对点的通讯，而且连接数不能太多情况。 HTTP/1.1和HTTP/2.0区别1.1管道传输与2.0的多路复用HTTP/1.1使用管道传输，即客户端与服务器建立连接后不用每次等待服务器响应就可发送新的请求，但是服务器仍然会顺序响应。如果某一请求出现问题，那么后面的请求都无法加载，这就会出现队头阻塞的问题。 在HTTP/2.0中通过多路复用解决了这个问题，即将一个TCP连接分为若干个流（Stream），每个流中可以传输若干消息（Message），这样即使一个请求被阻塞了，也不会影响其他请求 头部数据压缩在HTTP1.1中，消息主体都会经过gzip压缩，但状态行和头部却没有经过任何压缩，直接以纯文本传输。 HTTP2.0对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。 传输格式2.0采用二进制格式而非文本格式 HTTP和HTTPS的区别1、HTTP是超文本传输协议，是明文传输，而HTTPS则是具有安全协议SSL的加密传输 2、http是无状态的，而https是有可以进行加密传输，身份认证的 cookie和session的区别1、cookie 是一种发送到客户浏览器的文本串句柄，并保存在客户机硬盘上，可以用来在 某个 WEB 站点会话间持久的保持数据 2、session 其实指的就是访问者从到达某个特定主页到离开为止的那段时间。 Session 其 实是利用 Cookie 进行信息处理的，当用户首先进行了请求后，服务端就在用户浏览器 上创建了一个 Cookie，当这个 Session 结束时，其实就是意味着这个 Cookie 就过期 了 3、cookie 数据保存在客户端只能存储string类型的对象，session 数据保存在服务器端，可以存储任意类型的对象 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xulilei.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"十次方微服务复习","date":"2020-07-01T08:17:02.000Z","path":"2020/07/01/十次方微服务复习/","text":"利用SpringDataJPA完成问答、文章、招聘、交友、吐槽、用户、管理员的增删改以及模糊分页查询1、IdWorker：采用推特开源的雪花算法工具类，每秒能产生26W的id，而不产生id碰撞 SpringDataJpa用法：Dao层接口继承JpaRepository,JpaSpecifationExecutor（复杂查询使用）接口 模糊分页查询 实现条件查询： ​ 3种方式 ：一种是通过在dao层通过nativeQuery编写模糊查询语句，第二种是在dao层通过findBy**Like 另一种通过service层new Specification构造动态查询语句 public List&lt;Label&gt; findSearch(Label label) { return labelDao.findAll(new Specification&lt;Label&gt;() { @Override public Predicate toPredicate(Root&lt;Label&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; list=new ArrayList&lt;&gt;(); //相当于 ****** where labelname like \"%label.getLabelname()%\" if(label.getLabelname()!=null&amp;&amp;!\"\".equals(label.getLabelname())){ //通过root拿到字段名 Predicate predicate = cb.like(root.get(\"labelname\").as(String.class), \"%\" + label.getLabelname() + \"%\"); //一个条件，添加到cb中 list.add(predicate); } //将条件链表转化为数组 Predicate[] parr=new Predicate[list.size()]; list.toArray(parr); //合并所有条件，一起查询 return cb.and(parr); }); } 实现分页查询 dao层构建查询方法时传入pageable对象 service层调用JPA封装的方法时传入page和size，通过PageRequest生成Pgeable对象，service层返回Page对象 controller调用service方法，并通过之前定义好的分页类，返回给前端 //dao层public Page&lt;Label&gt; findAll(Pagealbe pageable){}//service层public Page&lt;Label&gt; findAll(int page,int size){ Pageable pageable=PageRequest.of(page-1,size); return labelDao.findAll(pageable);}//controller@RequestMapping(value = \"/{page}/{size}\",method = RequestMethod.GET) public Result findAll(@PathVariable int page,@PathVariable int size){ Page&lt;Label&gt; all = labelService.findAll(page,size); return new Result(true, StatusCode.OK,\"查询成功\",new PageResult&lt;&gt;(all.getTotalElements(),all.getContent())); }//pageResult类public class PageResult&lt;T&gt; { private long total; private List&lt;T&gt; rows; public long getTotal() { return total; } public void setTotal(long total) { this.total = total; } public List&lt;T&gt; getRows() { return rows; } public void setRows(List&lt;T&gt; rows) { this.rows = rows; } public PageResult() { } public PageResult(long total, List&lt;T&gt; rows) { this.total = total; this.rows = rows; }} 问答模块主要业务主要包含两个个表问题表，回答表 问题表包含：问题id，问题标题，内容，发布日期，最新回复时间、最新回复人，发布人id，点赞数，是否解决 回答表包含：回答id，问题id，回答内容，回答日期，回答人id等 完成的主要业务有 1、最新回答列表：最新回复的问题显示在上方， 按回复时间降序排序 2、热门回答列表：按回复数降序排序 3、等待回答列表： 回复数为0按时间升序排序 在问题展示，会将每个问题的回复通过分页查询的形式返回给前端 招聘模块主要业务招聘微服务主要有两块：企业信息和招聘信息 企业表包含：id，name，summary，address，ishot等字段 招聘信息表包含：jobid，jobname，salary，企业id，发布日期，截止日期，状态（0表关闭，1表开启，2表推荐），关注人数等字段 完成的主要业务有 1、展示热门企业列表（通过findByIshot查询） 2、推荐职业列表（通过findTop4ByStateOrderByCreatetimeDesc：查询状态为2并以创建日期降序排序，查询前4条记录） 3、最新职位列表（findTop12ByStateNotOrderByCreatetimeDesc：查询状态不为0并以创建日期降序排序，查询前12条记录） 文章模块主要业务文章表包含：文章id，类别，用户id，文章标题，内容，发布日期，审核状态（0，1），点赞数，是否热门等 完成的主要业务有 1、管理员审核文章：状态改为1 2、用户对文章进行评论 3、通过springdataredis对热门文章缓存,可设置缓存时间 public Article findById(String id) { //先从缓存中查询当前对象 Article article= (Article) redisTemplate.opsForValue().get(\"article_\"+id); //如果没有渠道 if(article==null){ article = articleDao.findById(id).get(); //如果热门存入缓存 if(article.getIshot()==1){ redisTemplate.opsForValue().set(\"article_\"+id,article); } } return article;} 4、利用Elasticsearch和ik分词器完成文章的搜索功能，利用logstash同步mysql至elasticsearch //创建新的实体类，这里只需要一些必须的字段@Document(indexName = \"articleindex\",type = \"article\")public class Article implements Serializable { @Id private String id; //@Field注解作用 //是否能被搜索到 //是否分词，整体匹配还是分词匹配 //是否在页面上显示，即数据库中在该实体类中的字段，就是要显示的 //analyzer,分词 //searchAnalyzer，搜索 @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String title; @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String content; public String getId() { return id; } public void setId(String id) { this.id = id; } public String getTitle() { return title; } public void setTitle(String title) { this.title = title; } public String getContent() { return content; } public void setContent(String content) { this.content = content; }}//dao层public interface ArticleDao extends ElasticsearchRepository&lt;Article,String&gt; { public Page&lt;Article&gt; findByTitleOrContentLike(String title, String content, Pageable pageable);}//service层 public Page&lt;Article&gt; findByKey(String key, int page, int size) { Pageable pageable= PageRequest.of(page-1,size); return articleDao.findByTitleOrContentLike(key,key,pageable); }//controller层@RequestMapping(value = \"/{key}/{page}/{size}\",method = RequestMethod.GET) public Result findByKey(@PathVariable String key,@PathVariable int page,@PathVariable int size){ Page&lt;Article&gt;pageData=articleService.findByKey(key,page,size); return new Result(true,StatusCode.OK,\"搜索成功\",new PageResult&lt;Article&gt;(pageData.getTotalElements(),pageData.getContent())); } 吐槽模块吐槽表：_id，内容content，发布时间，用户id，点赞数，上级吐槽id 使用springdataMongoDB完成的主要业务有 1、发布吐槽，如果是在别人下面吐槽需要将上级吐槽回复数加1 if(spit.getParentid()!=null&amp;&amp;!\"\".equals(spit.getParentid())){//表示是在别人下面回复 Query query=new Query(); query.addCriteria(Criteria.where(\"_id\").is(spit.getParentid())); Update update=new Update(); update.inc(\"thumbup\",1); mongoTemplate.updateFirst(query,update,\"spit\");} 2、根据上级id查询吐槽列表 3、吐槽点赞，并通过redis使其不能重复点赞 //使用mongoDB原生方式实现自增public void thumbUp(String id){ //方式一,与数据库多次交互性能较低 //Spit spit=spitDao.findById(id).get(); //spit.setThumbup((spit.getThumbup()==null?0:spit.getThumbup())+1); //spitDao.save(spit); //相当于使用原生mongo命令实现自增：db.spit.update({\"_id\":\"1\"},{$inc:{thumbup:NumberInt(1)}}) Query query=new Query(); query.addCriteria(Criteria.where(\"_id\").is(\"id\")); Update update=new Update(); update.inc(\"thumbup\",1); mongoTemplate.updateFirst(query,update,\"spit\"); }@RequestMapping(value = \"/thumbup/{spitId}\",method = RequestMethod.PUT)public Result thumbUp(@PathVariable String spitId){ //由于没有做登陆认证，因此暂时写死ID，实现一个用户只能点赞一次 String userid=\"111\"; if(redisTemplate.opsForValue().get(\"thumbup_\"+userid)!=null){ return new Result(false,StatusCode.REPERROR,\"不能重复点赞\"); }; spitService.thumbUp(spitId); redisTemplate.opsForValue().set(\"thumbup_\"+userid,1); return new Result(true,StatusCode.OK,\"点赞成功\");} 管理员模块管理员登陆，JWT鉴权，在完成鉴权后通过feign可以操作其他模块的业务 1、在招聘模块对关注人数超过一定值的招聘信息可以设置为推荐，删除超过截止日期的招聘信息 2、手动设置热门企业 3、对用户进行管理 4、审核为通过审核文章，删除违规的文章 用户中心模块用户登陆，JWT鉴权，在完成鉴权后通过feign可以操作其他模块的业务 完成的主要业务有 1、用户注册：本地生成6位验证码，redis缓存一份，向rabbitmq发送一份，在处理短信的模块中，监听mq的短信队列拿到想换验证码和手机号，通过阿里云的短信API实现发送短信的功能（处理短信的模块是自动完成的，只需向mq发送相关信息即可） 2、用户登录：通过spring security的BCryptPasswordEncoder实现密码的加密解密，完成用户登录，登录成功通过JWT向用户发送token，以后请求服务需要在头信息中添加token信息 交友模块分为好友表和非好友表 好友表包含：用户id，朋友id，islike（0表单向喜欢，1表双向喜欢） 非好友表包含：用户id，朋友id 完成的业务： 1、当A点击喜欢B，好友表增加记录，非好友表删除A不喜欢B，当B喜欢A，修改islike为1 2、当A点击拉黑B，非好友表增加记录，好友表删除A-B的记录，若B喜欢A，则修改为单向喜欢 3、于此同时，A喜欢B，A的关注数加1，B的粉丝数加1 public int addFriend(String userid, String friendid) { //先判断userid到friendid是否有数据，有就是重复添加好友，返回0 Friend friend=friendDao.findByUseridAndFriendid(userid,friendid); if(friend!=null){ return 0; } //再判断以前是否不喜欢 if(noFriendDao.findByUseridAndFriendid(userid, friendid)!=null){ noFriendDao.deleteByUseridAndFriendid(userid,friendid); } //直接添加好友，让好友表中的userid到friendid方向的type为0 friend=new Friend(); friend.setUserid(userid); friend.setFriendid(friendid); friend.setIslike(\"0\"); friendDao.save(friend); //再判断friendid到userid是否有数据，如果有则把双方的状态都改为1 if(friendDao.findByUseridAndFriendid(friendid,userid)!=null){ //把双方islike都改为1 friendDao.updateIslike(\"1\",userid,friendid); friendDao.updateIslike(\"1\",friendid,userid); }; return 1;}public int addNoFriend(String userid,String friendid) { //先判断是否已经是非好友 NoFriend noFriend=noFriendDao.findByUseridAndFriendid(userid, friendid); if(noFriend!=null){ return 0; } //如果之前是好友，现在单方面删除 if(friendDao.findByUseridAndFriendid(userid,friendid)!=null){ friendDao.deleteByUseridAndFriendid(userid,friendid); if(friendDao.findByUseridAndFriendid(friendid,userid)!=null) friendDao.updateIslike(\"0\",friendid,userid); } //删完再添加到noFriend表 noFriend=new NoFriend(); noFriend.setUserid(userid); noFriend.setFriendid(friendid); noFriendDao.save(noFriend); return 1; } 完成项目的微服务化 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[]},{"title":"使用jekins完成项目部署于Docker容器","date":"2020-06-30T07:52:28.000Z","path":"2020/06/30/使用jekins完成项目部署/","text":"使用jekins完成项目部署于Docker容器创建Docker私有仓库创建私有仓库容器拉去镜像，创建容器docker pull registrydocker run ‐di ‐‐name=registry ‐p 5000:5000 registry 打开浏览器 输入地址http://192.168.xxx.xxx:5000/v2/_catalog 看到 {“repositories”:[]} 表示私有仓库搭建成功并且内容为空 修改daemon.json让docker信任私有仓库 vi /etc/docker/daemon.json{\"insecure‐registries\":[\"192.168.xxx.xxx:5000\"]} maven插件自动部署修改宿主机docker配置使其可以远程访问vi /lib/systemd/system/docker.service其中ExecStart=后添加配置 ‐H tcp://0.0.0.0:2375 ‐H unix:///var/run/docker.sock 发布的项目pom文件引入插件&lt;build&gt; &lt;finalName&gt;tensquare_config&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!--docker的maven插件，官网： https://github.com/spotify/docker‐maven‐plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;!--上传私有仓库--&gt; &lt;imageName&gt;192.168.152.xx:5000/${project.artifactId}:${project.version}&lt;/imageName&gt; &lt;!--基础镜像，意味着docker容器中已经存在jdk8的镜像--&gt; &lt;baseImage&gt;jdk8&lt;/baseImage&gt; &lt;!--打包命令--&gt; &lt;entryPoint&gt;[\"java\", \"-jar\", \"/${project.build.finalName}.jar\"]&lt;/entryPoint&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory} &lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;dockerHost&gt;http://192.168.152.xx:2375&lt;/dockerHost&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 进入该工程所在目录执行命令mvn clean package docker:build -DpushImage 代码管理服务gogs安装gogsdocker pull gogs/gogsdocker run -d --name=gogs -p 10022:22 -p 3000:3000 -v /var/gogsdata:/data gogs/gogs 配置gogs在地址栏输入http://192.168.xxx.xxx:3000 会进入首次运行安装程序页面，我们可以选择一种数据库作为gogs数据的存储，最简单的是选择SQLite3。如果对于规模较大的公司，可以选择MySQL 页面展示idea上传至gogs仓库 jekins持续继承配置jekins下载安装完后需要配置用户和端口号JENKINS_USER=\"root\"JENKINS_PORT=\"8888\" 首次进入，安装插件主要的插件有两个一个是maven一个是git 全局工具配置服务器安装maven，JDK JDK配置git配置（一般服务器都已经安装）maven配置持续继承创建一个maven项目 源码管理选gitURL填写gogs仓库的地址 Buildpom要填写生成容器的子项目 执行任务 结果展示docker镜像 私有仓库 运行后可以成功展示！ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"jekins","slug":"jekins","permalink":"https://xulilei.github.io/tags/jekins/"},{"name":"gogs","slug":"gogs","permalink":"https://xulilei.github.io/tags/gogs/"}]},{"title":"集中配置组件SpringCloudConfig","date":"2020-06-26T07:58:27.000Z","path":"2020/06/26/集中配置组件SpringCloudConfig/","text":"集中配置组件SpringCloudConfigSpring Cloud Config简介在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所 以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库 中。在spring cloud config 组件中，分两个角色，一是config server，二是config client。 config server它用于集中管理应用程序各个 环境下的配置，默认使用Git存储配置文件内容 导入config-server依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 启动类添加@EnableConfigServer@SpringBootApplication@EnableConfigServerpublic class ConfigApplication { public static void main(String[] args) { SpringApplication.run(ConfigApplication.class); }} 修改配置文件这里如果uri使用的是http，则会出现不能clone仓库内容的错误，因此要换成ssh，并添加private-key，该配置文件不需要上传至云端 server: port: 12000spring: application: name: tensquare-config rabbitmq: host: 192.168.152.** cloud: config: server: git: uri: git@gitee.com:***/tensquare.git ignore-local-ssh-settings: true private-key: | -----BEGIN RSA PRIVATE KEY----- MIIEowIBAAKCAQEAxawgOKaig29oj/OqSVY9njJMnIYmedq4A7wvKEpg3Q/wYRl0 DO1QOl13ilyj20MyXUEUKON4dKWoBl+2/zhTtyI5cCDhcnISYAp9JSkYSzm8DTDp E+1Zwmq2yYE68mr5/UaRbhOHBPGr1GwrTNuraqnOtNDjUXm25E4HiCmHoc395RpA -----END RSA PRIVATE KEY----- config clientConfig Client是Config Server的客户端，用于操作存储在Config Server中的配置内容。 微服务在启动时会请求Config Server获取配置文件的内容，请求到后再启动容器。 导入config client依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 上传配置文件application.yml至gitee文件命名规则： {application}-{profile}.yml或{application}-{profile}.properties 其中application为应用名称，profile指的开发环境（用于区分开发环境，测试环境、生产环境等） 更换配置文件为bootstrap.ymlspring: cloud: config: #这个对应gitee配置文件的命名规则 name: base profile: dev label: master uri: http://127.0.0.1:12000 消息总线组件SpringCloudBusSpringCloudBus简介当云端修改配置文件后，本地不用修改和再次编译，只需向消息中间件发送一条修改提醒即可使得配置文件即时生效 配置服务端config-server导入SpringCloudBus和rabbitmq依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-bus&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 修改配置文件spring: rabbitmq: host: 192.168.152.128#暴露触发消息总线的地址，management: endpoints: web: exposure: include: bus-refresh 配置客户端功能子模块导入依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-bus&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 云端配置文件添加rabbitmq地址rabbitmq: host: 192.168.184. document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"SpringCloudConfig","slug":"SpringCloudConfig","permalink":"https://xulilei.github.io/tags/SpringCloudConfig/"}]},{"title":"微服务网关Zuul","date":"2020-06-26T07:40:35.000Z","path":"2020/06/26/微服务网关Zuul/","text":"微服务网关Zuul相关概念为什么使用网关不同的微服务一般有不同的网络地址，而外部的客户端可能需要调用多个服务的接口才 能完成一个业务需求。 如果客户端直接和微服务进行通信，会存在一下问题： 1、客户端会多次请求不同微服务，增加客户端的复杂性 2、存在跨域请求，在一定场景下处理相对复杂 3、认证复杂，每一个服务都需要独立认证 上述问题，都可以借助微服务网关解决。微服务网关是介于客户端和服务器端之间的中间层，所有的外部请求都会先经过微服务网关。 什么是zuulZuul是Netflix开源的微服务网关，他可以和Eureka,Ribbon,Hystrix等组件配合使用。 Zuul组件的核心是一系列的过滤器，这些过滤器可以完成以下功能： 1、身份认证和安全: 识别每一个资源的验证要求，并拒绝那些不符的请求 2、动态路由：动态将请求路由到不同后端集群 Zuul使用网关模块导入相关依赖zuul是依赖eureka实现的，通过微服务的name在eureka的服务器上寻找到对应的路径 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt; 配置application,ymlserver: port: 9011spring: application: name: tensquare-managereureka: client: service-url: defaultZone: http://127.0.0.1:6868/eureka/ instance: prefer‐ip‐address: truezuul: routes: tensquare-base: path: /base/** serviceId: tensquare-base tensquare-user: path: /user/** serviceId: tensquare-user tensquare-qa: path: /qa/** serviceId: tensquare-qa 修改启动类@SpringBootApplication@EnableEurekaClient@EnableZuulProxypublic class ManagerApplication { public static void main(String[] args) { SpringApplication.run(ManagerApplication.class); } @Bean public JwtUtil jwtUtil(){ return new JwtUtil(); }} 实例：通过ZuulFilter实现身份验证功能创建Filter类继承ZuulFilter，并实现其中的方法，具体细节请看注释 @Componentpublic class ManagerFilter extends ZuulFilter { @Autowired private JwtUtil jwtUtil; //过滤器类型 //“pre”执行之前，“post”执行时 @Override public String filterType() { return \"pre\"; } //排序，0表示优先执行 @Override public int filterOrder() { return 0; } //表示当前过滤器是否开启，true为开启 @Override public boolean shouldFilter() { return true; } //过滤器内执行的操作，return任何object表示继续执行， //setSendZullResponse(false)表示不再继续执行 @Override public Object run() throws ZuulException { //通过com.netflix.zuul得到request上下文 RequestContext currentContext =RequestContext.getCurrentContext(); //得到request域 HttpServletRequest request = currentContext.getRequest(); // 第一次转发始终放行，因为是根据配置文件中的路径去找其他服务 if(request.getMethod().equals(\"OPTIONS\")){ return null; } //登陆放行 if(request.getRequestURI().indexOf(\"login\")&gt;0){ return null; } //得到头信息 String header = request.getHeader(\"Authorization\"); if(header!=null&amp;&amp;!\"\".equals(header)){ if(header.startsWith(\"Bearer \")){ String token=header.substring(7); try { Claims claims = jwtUtil.parseJWT(token); String role= (String) claims.get(\"roles\"); if(role.equals(\"admin\")){ //把头信息继续往下传 currentContext.addZuulRequestHeader(\"Authorization\",header); return null; } }catch (Exception e){ //终止运行 currentContext.setSendZuulResponse(false); } } } //header为空返回错误信息 currentContext.setSendZuulResponse(false); currentContext.setResponseStatusCode(403); return null; }} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"zuul","slug":"zuul","permalink":"https://xulilei.github.io/tags/zuul/"}]},{"title":"Hystrix入门","date":"2020-06-25T13:58:25.000Z","path":"2020/06/25/Hystrix“入门/","text":"Hystrix熔断器相关概念为什么要使用熔断器在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障， 进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。而熔断器的产生，则有效规避了雪崩效应 熔断器工作机制当服务的某个API接口的失败次数在一定时间内小于设定的阈值时，熔断器处于关闭状态，该API接口正常提供服务。当该API接口处理请求的失败次数大于设定的阈值时，Hystrix判定该API接口出现了故障，打开熔断器，这时该API接口会执行快速失败的逻辑，不执行业务逻辑，请求的线程不会处于阻塞状态。处于打开状态的熔断器在一定时间后会处于半打开状态，并将一定数量的请求执行正常逻辑，剩余的请求会执行快速失败。若执行正常逻辑的请求失败了，则熔断器继续打开，若成功了，则熔断器关闭。这样熔断器就具有了自我修复的功能。 使用配置文件开启hystrix支持Feign本身支持Hystrix，因此不需要导入额外依赖 feign: hystrix: enabled: true 创建实现feign接口的实现类在声明式接口中的@FeignClient注解上添加fallback属性来配置快速失败的处理类。该处理类作为Feign熔断器的逻辑处理类，必须实现被@FeignClient修饰的接口 @FeignClient(value = \"tensquare-base\",fallback = BaseClientImpl.class)public interface BaseClient { @RequestMapping(value = \"/label/{labelId}\",method = RequestMethod.GET) public Result findById(@PathVariable(\"labelId\") String labelId);}@Componentpublic class BaseClientImpl implements BaseClient { @Override public Result findById(String labelId) { return new Result(false, StatusCode.ERROR,\"失败\"); }} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"Hystrix","slug":"Hystrix","permalink":"https://xulilei.github.io/tags/Hystrix/"}]},{"title":"SpringCloud架构模型","date":"2020-06-25T13:54:19.000Z","path":"2020/06/25/cloud常见模块/","text":"Spring Cloud架构模型 服务发现组件EurekaEureka是Netflix开发的服务发现框架，SpringCloud将它集成在自己的子项目spring-cloud-netflix中，实现SpringCloud的服务发现功能。Eureka包含两个组件：Eureka Server和Eureka Client。 Eureka Server提供服务注册服务，各个节点启动后，会在Eureka Server中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到。 详见：https://xulilei.github.io/2020/06/21/eureka%E5%85%A5%E9%97%A8/ 服务间调用Feignfeign是声明式的web service客户端，它让微服务之间的调用变得更简单了，类似controller调用service。Spring Cloud集成了Ribbon和Eureka，可在使用Feign时提供负载均衡的http客户端 详见：https://xulilei.github.io/2020/06/21/eureka%E5%85%A5%E9%97%A8/ 熔断器Hystrix在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障， 进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。而熔断器的产生，则有效规避了雪崩效应 当服务的某个API接口的失败次数在一定时间内小于设定的阈值时，熔断器处于关闭状态，该API接口正常提供服务。当该API接口处理请求的失败次数大于设定的阈值时，Hystrix判定该API接口出现了故障，打开熔断器，这时该API接口会执行快速失败的逻辑，不执行业务逻辑，请求的线程不会处于阻塞状态。处于打开状态的熔断器在一定时间后会处于半打开状态，并将一定数量的请求执行正常逻辑，剩余的请求会执行快速失败。若执行正常逻辑的请求失败了，则熔断器继续打开，若成功了，则熔断器关闭。这样熔断器就具有了自我修复的功能。 详见：","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://xulilei.github.io/tags/SpringCloud/"}]},{"title":"daySeven-eureka","date":"2020-06-21T15:04:08.000Z","path":"2020/06/21/十次方daySeven/","text":"交友服务搭建主要业务添加喜欢业务逻辑有两张表分别为tb_friend和tb_nofriend，当A添加喜欢B，先在tb_friend表中查询有无数据，如果有则代表已经添加喜欢了，回复不可重复添加，然后在tb_nofriend中查询是否之前A不喜欢B，如果有记录，则删除该记录。并在tb_friend中添加一条从A-B的记录，且状态为0，代表单向喜欢。如果在添加记录时，恰哈发现B-A已经有数据了，那么则将二者的状态都改为1，代表双向喜欢 业务实现，service层public int addFriend(String userid, String friendid) { //先判断userid到friendid是否有数据，有就是重复添加好友，返回0 Friend friend=friendDao.findByUseridAndFriendid(userid,friendid); if(friend!=null){ return 0; } //再判断以前是否不喜欢 if(noFriendDao.findByUseridAndFriendid(userid, friendid)!=null){ noFriendDao.deleteByUseridAndFriendid(userid,friendid); } //直接添加好友，让好友表中的userid到friendid方向的type为0 friend=new Friend(); friend.setUserid(userid); friend.setFriendid(friendid); friend.setIslike(\"0\"); friendDao.save(friend); //再判断friendid到userid是否有数据，如果有则把双方的状态都改为1 if(friendDao.findByUseridAndFriendid(friendid,userid)!=null){ //把双方islike都改为1 friendDao.updateIslike(\"1\",userid,friendid); friendDao.updateIslike(\"1\",friendid,userid); }; return 1;} 添加不喜欢业务逻辑当A添加B为不喜欢，首先查询tb_nofriend中是否已经有数据，如果有则提示不可重复拉黑。然后再去tb_friend中查询是否有A-B的喜欢，如果有则删除该记录，同时查询B-A是否也有记录，有则代表之前是双向喜欢，此时应将B-A的状态改为0，最后在tb_nofriend中添加一行A-B数据。 业务实现，service层public int addNoFriend(String userid,String friendid) { //先判断是否已经是非好友 NoFriend noFriend=noFriendDao.findByUseridAndFriendid(userid, friendid); if(noFriend!=null){ return 0; } //如果之前是好友，现在单方面删除 if(friendDao.findByUseridAndFriendid(userid,friendid)!=null){ friendDao.deleteByUseridAndFriendid(userid,friendid); //如果之前双向喜欢，则改为单向喜欢 if(friendDao.findByUseridAndFriendid(friendid,userid)!=null) friendDao.updateIslike(\"0\",friendid,userid); } //删完再添加到noFriend表 noFriend=new NoFriend(); noFriend.setUserid(userid); noFriend.setFriendid(friendid); noFriendDao.save(noFriend); return 1;} 上述功能用到的Dao层FriendDaopublic interface FriendDao extends JpaRepository&lt;Friend,String&gt; { public Friend findByUseridAndFriendid(String userid,String friendid); @Modifying @Query(value =\"update tb_friend SET islike=? where userid=? and friendid=?\",nativeQuery = true) public void updateIslike(String islike,String userid,String friendid); public void deleteByUseridAndFriendid(String userid,String friendid);} NoFriendDaopublic interface NoFriendDao extends JpaRepository&lt;NoFriend,String&gt; { public NoFriend findByUseridAndFriendid(String userid, String friendid); public void deleteByUseridAndFriendid(String userid,String friendid);} feign调用user模块业务业务逻辑当A添加B为喜欢时，在tb_user表中，userA的关注数+1，B的粉丝数+1。当A添加B为不喜欢时，userA的关注数-1，B的粉丝数-1。 User模块中粉丝关注业务实现Dao层public interface UserDao extends JpaRepository&lt;User,String&gt;,JpaSpecificationExecutor&lt;User&gt;{ @Modifying @Query(value =\"update tb_user set fanscout=fanscount+? where id=?\" ,nativeQuery = true) public void updateFans(int x, String friendid); @Modifying @Query(value =\"update tb_user set followcount=followcount+? where id=?\" ,nativeQuery = true) public void updateFollows(int x, String userid);} Service层@Transactionalpublic void updateFansAndFollowCounts(int x, String userid, String friendid) { //friendB粉丝数+1，userA的关注数+1 userDao.updateFans(x,friendid); userDao.updateFollows(x,userid);} Controller层//不返回result是因为这个业务是服务之间的调用，不涉及前台@RequestMapping(value = \"/{userid}/{friendid}/x\",method = RequestMethod.PUT)public void updateFansAndFollowCounts(@PathVariable int x,@PathVariable String userid,@PathVariable String friendid){ userService.updateFansAndFollowCounts(x,userid,friendid);} 交友模块中调用上述业务启动类添加相应注解@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@EnableFeignClientspublic class FriendApplication { public static void main(String[] args) { SpringApplication.run(FriendApplication.class); }} 创建client@FeignClient(\"tensquare-user\")public interface UserClient { @RequestMapping(value = \"/user/{userid}/{friendid}/x\",method = RequestMethod.PUT) public void updateFansAndFollowCounts (@PathVariable(\"x\") int x, @PathVariable(\"userid\") String userid, @PathVariable(\"friendid\") String friendid);} controller层调用//添加喜欢if(flag==1){ userClient.updateFansAndFollowCounts(1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\");}//添加不喜欢if(flag==1){ userClient.updateFansAndFollowCounts(-1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\");} 交友服务controller层整合@RequestMapping(value = \"/like/{friendid}/{type}\",method = RequestMethod.PUT )public Result addFriend(@PathVariable String friendid,@PathVariable String type){ //验证是否登陆，并拿到ID Claims claims = (Claims) request.getAttribute(\"user_claims\"); if(claims==null){ return new Result(false, StatusCode.LOGINERROR,\"权限不足\"); } String userid = claims.getId(); System.out.println(userid); //判断是添加好友还是非好友，直接传进来一个类型type，当type为1时，表示添加，2时表示拉黑 if(type!=null){ if(type.equals(\"1\")){ int flag=friendService.addFriend(userid,friendid); if(flag==0){ return new Result(false, StatusCode.ERROR,\"不能重复添加好友\"); } if(flag==1){ //后文介绍的添加粉丝与关注 userClient.updateFansAndFollowCounts(1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\"); } //添加好友 }else if(type.equals(\"2\")) { //添加黑名单 int flag= friendService.addNoFriend(userid,friendid); if(flag==0){ return new Result(false, StatusCode.ERROR,\"不能重复拉黑好友\"); } if(flag==1){ //后文介绍的减少粉丝与关注 userClient.updateFansAndFollowCounts(-1,userid,friendid); return new Result(true, StatusCode.OK,\"添加成功\"); } } } return new Result(false, StatusCode.ERROR,\"参数异常\");} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"Eureka","slug":"Eureka","permalink":"https://xulilei.github.io/tags/Eureka/"},{"name":"交友业务","slug":"交友业务","permalink":"https://xulilei.github.io/tags/%E4%BA%A4%E5%8F%8B%E4%B8%9A%E5%8A%A1/"}]},{"title":"eureka入门","date":"2020-06-21T07:50:02.000Z","path":"2020/06/21/eureka入门/","text":"服务发现组件Eureka相关概念Eureka简介Eureka是Netflix开发的服务发现框架，SpringCloud将它集成在自己的子项目spring-cloud-netflix中，实现SpringCloud的服务发现功能。Eureka包含两个组件：Eureka Server和Eureka Client。 Eureka ServerEureka Server提供服务注册服务，各个节点启动后，会在Eureka Server中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到。 服务端开发第一步，在父工程中锁定版本，每一个版本的springboot都对应一个版本的springcloud &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.M9&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 第二步，Eureka子模块添加eureka-server &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 第三步，添加application.yml server: port: 6868eureka: client: register-with-eureka: false #是否将自己注册到Eureka服务中，本身就是所有无需注册 fetch-registry: false service-url: #Eureka客户端与Eureka服务端进行交互的地址 defaultZone: http://127.0.0.1:${server.port}/eureka/ 第四步，启动类 @SpringBootApplication@EnableEurekaServerpublic class EurekaServer { public static void main(String[] args) { SpringApplication.run(EurekaServer.class); }} Eureka ClientEureka Client是一个java客户端，用于简化与Eureka Server的交互，客户端同时也 就别一个内置的、使用轮询(round-robin)负载算法的负载均衡器。 客户端开发第一步，客户端模块添加eureka-client &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 第二步，修改每个微服务的application.yml，添加注册eureka服务的配置 eureka: client: service-url: defaultZone: http://127.0.0.1:6868/eureka/ instance: prefer‐ip‐address: true #跨域 第三步，启动类 @SpringBootApplication@EnableEurekaClient public class UserApplication { public static void main(String[] args) { SpringApplication.run(UserApplication.class, args); }} Feign实现服务间的调用谁调用别人就在谁的模块中搭建环境第一步，添加openfeign依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 第二步，启动类@SpringBootApplication@EnableEurekaClient//Eureka客户端@EnableDiscoveryClient//可以发现服务@EnableFeignClients//通过feign调用其他服务的业务public class QaApplication { public static void main(String[] args) { SpringApplication.run(QaApplication.class, args); }} 第三步，创建client包，创建要调用目标的接口默认采用的是ribbon的轮询负载均衡算法 //调用目标的名字，注意这里不能使用下划线，这也是其他模块的application.yml中名字不加下划线的原因@FeignClient(\"tensquare-base\")//调用目标controller层的方法public interface BaseClient { @RequestMapping(value = \"/label/{labelId}\",method = RequestMethod.GET) //这里的 @PathVariable 后面要加上具体的参数名称(\"labelId\")不然会找不到 public Result findById(@PathVariable(\"labelId\") String labelId);} 相关实践详见：https://xulilei.github.io/2020/06/21/%E5%8D%81%E6%AC%A1%E6%96%B9daySeven/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"eureka","slug":"eureka","permalink":"https://xulilei.github.io/tags/eureka/"}]},{"title":"daySix-JWT-BCryptPasswordEncoder","date":"2020-06-18T02:27:02.000Z","path":"2020/06/18/十次方daySix/","text":"管理员登陆验证与删除鉴权 利用Spring Security的BCryptPasswordEncoder与JWT实现 登陆验证签发tokenservice层public Admin login(Admin admin) { //想根据用户名查询对象 Admin adminLogin=adminDao.findByLoginname(admin.getLoginname()); //然后拿数据库中的密码和用户输入的密码匹配是否相同 if(adminLogin!=null&amp;&amp;encoder.matches(admin.getPassword(),adminLogin.getPassword())){ return adminLogin; } //登陆失败 return null;} controller层@RequestMapping(value = \"/login\",method = RequestMethod.POST)public Result login(@RequestBody Admin admin){ Admin adminLoginResult=adminService.login(admin); if(adminLoginResult==null){ return new Result(false,StatusCode.LOGINERROR,\"登陆失败\"); } //做一系列前后端通话的工作，用JWT来实现 //生成token并返回给客户端 String token=jwtUtil.createJWT(adminLoginResult.getId(),adminLoginResult.getLoginname(),\"admin\"); Map&lt;String,Object&gt;map=new HashMap&lt;&gt;(); map.put(\"token\",token); map.put(\"role\",\"admin\"); return new Result(true,StatusCode.OK,\"登陆成功\",map);} 返回给前端的token 利用拦截器解析token拦截器只是为了将请求头中的token解析成user和admin解析后将气保存在域对象中，等需要鉴权时，直接通过获取这个域对象的值来分别是user还是admin @Componentpublic class JwtInterceptor implements HandlerInterceptor { @Autowired private JwtUtil jwtUtil; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //无论如何都放行，具体能不能操作要在具体的操作中去判断 //拦截器只是负责把请求头中包含的token令牌解析成user和admin String header=request.getHeader(\"Authorization\"); if(header!=null&amp;&amp;header.startsWith(\"Bearer \")){ String token=header.substring(7); try { Claims claims = jwtUtil.parseJWT(token); if(claims!=null){ if(\"admin\".equals(claims.get(\"roles\"))){ request.setAttribute(\"admin_claims\",token); } if(\"user\".equals(claims.get(\"roles\"))){ request.setAttribute(\"user_claims\",token); } } }catch (Exception e){ //过期 throw new RuntimeException(\"token错误\"); } } return true; }} 注册拦截器当然不用拦截登陆请求了 @Configurationpublic class InterceptorConfig extends WebMvcConfigurationSupport { @Autowired private JwtInterceptor jwtInterceptor; @Override protected void addInterceptors(InterceptorRegistry registry) { //注册拦截器要声明的拦截器对象和要拦截的请求 registry.addInterceptor(jwtInterceptor) .addPathPatterns(\"/**\") .excludePathPatterns(\"/**/login\"); }} 管理员删除用户直接从域对象中获取admin_claims，如果有则说明该登陆用户为管理员，则可以删除用户，否则提示权限不足 @Autowired private HttpServletRequest request;public void deleteById(String id) { String token = (String) request.getAttribute(\"admin_claims\"); if(token==null||\"\".equals(token)){ throw new RuntimeException(\"权限不足\"); } userDao.deleteById(id);} 当header中的token无法解析时 当header中的token正确时 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"Spring Security","slug":"Spring-Security","permalink":"https://xulilei.github.io/tags/Spring-Security/"},{"name":"BCryptPasswordEncoder","slug":"BCryptPasswordEncoder","permalink":"https://xulilei.github.io/tags/BCryptPasswordEncoder/"},{"name":"JWT","slug":"JWT","permalink":"https://xulilei.github.io/tags/JWT/"},{"name":"鉴权","slug":"鉴权","permalink":"https://xulilei.github.io/tags/%E9%89%B4%E6%9D%83/"},{"name":"密码加密","slug":"密码加密","permalink":"https://xulilei.github.io/tags/%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86/"}]},{"title":"Spring Security加密与JWT鉴权","date":"2020-06-18T02:26:39.000Z","path":"2020/06/18/SpringSecurity加密与JWT鉴权/","text":"SpringSecurity加密与JWT鉴权Spring Security的BCryptPasswordEncoder使用过程引入依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置类如果只是使用BCryptPasswordEncoder，这个配置可以直接拿来用 @Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter{ @Override protected void configure(HttpSecurity http) throws Exception { //authorizeRequests是所有security全注解配置实现的开端 //需要的权限分两部分，第一部分是拦截的路径，第二部分是访问该路径需要的权限 //antMatchers，表示拦截的路径，permitAll表示任何权限都可以访问，直接放行所有 //这里主要是用security的加密功能，拦截功能用的是jwt //anyRequest()任何的请求，authenticated()认证后访问 //and().csrf().disable()表示使csrf攻击失效 http .authorizeRequests() .antMatchers(\"/**\").permitAll() .anyRequest().authenticated() .and().csrf().disable(); }} 配置BCryptPasswordEncoder交给容器@Beanpublic BCryptPasswordEncoder bCryptPasswordEncoder(){ return new BCryptPasswordEncoder();} 密码加密service层 public void add(User user) { user.setId( idWorker.nextId()+\"\" ); //密码加密 user.setPassword(encoder.encode(user.getPassword())); userDao.save(user);} 密码验证service层 public User login(String mobile,String password) { //先通过前台传过来的电话查询出user User user=userDao.findByMobile(mobile); //再比对user的密码，用encoder.match(原密码,加密后的密码) if(user!=null&amp;&amp;encoder.matches(password,user.getPassword())){ return user; } return null;} JWT鉴权常见的鉴权方式Cookie认证Cookie认证机制就是为一次请求认证在服务端创建一个Session对象，同时在客户端 的浏览器端创建了一个Cookie对象；通过客户端带上来Cookie对象来与服务器端的 session对象匹配来实现状态管理的。 Token认证使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是 这样的： 客户端使用用户名跟密码请求登录 服务端收到请求，去验证用户名与密码 验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端 客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里 客户端每次向服务端请求资源的时候需要带着服务端签发的 Token 服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向 客户端返回请求的数据 两者对比Token的优势 支持跨域访问: Cookie是不允许垮域访问的，这一点对Token机制是不存在的，前提 是传输的用户认证信息通过HTTP头传输. 无状态:Token机制在服务端不需要存储session信息，因为 Token 自身包含了所有登录用户的信息，只需要在客户端的cookie或本地介质存储状态信息. 去耦: 不需要绑定到一个特定的身份验证方案。Token可以在任何地方生成，只要在 你的API被调用的时候，你可以进行Token生成调用即可. 一次网络往返时间（通过数据库查询session信息）总比做一次HMACSHA256计算的Token验证和解析要费时得多. 基于标准化:你的API可以采用标准化的 JSON Web Token (JWT) JWT介绍一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名，且生成后都会采用base64进行编码。 头部（Header）头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。这也可以 被表示成一个JSON对象，如下指明了采用了JWT的算法为HS256 {\"typ\":\"JWT\",\"alg\":\"HS256\"} base64编码后：eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 载荷（playload）一般包含ID，用户SUB，身份roles，比如 {\"id\":\"1234567890\",\"sub\":\"John Doe\",\"roles\":\"admin\"} 会再次进行base64编码 签证（signature）包含头部，载荷，以及定义的salt，同样进行base编码 最终JWT会将三部分连接成一个字符串，以.连接 eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6I kpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ JJWT：Java JWT添加依赖&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.6.0&lt;/version&gt;&lt;/dependency&gt; 在common包下的util包中创建JWT工具类这个工具类，需要提供ID,SUB,ROLE作为claims @ConfigurationProperties(\"jwt.config\")public class JwtUtil { private String key ; private long ttl ;//一个小时 public String getKey() { return key; } public void setKey(String key) { this.key = key; } public long getTtl() { return ttl; } public void setTtl(long ttl) { this.ttl = ttl; } /** * 生成JWT * @param id * @param subject * @return */ public String createJWT(String id, String subject, String roles) { long nowMillis = System.currentTimeMillis(); Date now = new Date(nowMillis); JwtBuilder builder = Jwts.builder().setId(id) .setSubject(subject) .setIssuedAt(now) .signWith(SignatureAlgorithm.HS256, key).claim(\"roles\", roles); if (ttl &gt; 0) { builder.setExpiration( new Date( nowMillis + ttl)); } return builder.compact(); } /** * 解析JWT * @param jwtStr * @return */ public Claims parseJWT(String jwtStr){ return Jwts.parser() .setSigningKey(key) .parseClaimsJws(jwtStr) .getBody(); }} jwt.config哪里用到了这个工具类，哪里的application.yml添加jwt定义，哪里传入jwtUtil @Bean public JwtUtil jwtUtil(){ return new util.JwtUtil(); } jwt: config: key: itcast ttl: 360000 以admin的登陆与删除鉴权为例详见：https://xulilei.github.io/2020/06/18/%E5%8D%81%E6%AC%A1%E6%96%B9daySix/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"https://xulilei.github.io/tags/Spring-Security/"},{"name":"BCryptPasswordEncoder","slug":"BCryptPasswordEncoder","permalink":"https://xulilei.github.io/tags/BCryptPasswordEncoder/"},{"name":"JWT","slug":"JWT","permalink":"https://xulilei.github.io/tags/JWT/"},{"name":"鉴权","slug":"鉴权","permalink":"https://xulilei.github.io/tags/%E9%89%B4%E6%9D%83/"},{"name":"密码加密","slug":"密码加密","permalink":"https://xulilei.github.io/tags/%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86/"}]},{"title":"dayFive-rabbitmq","date":"2020-06-15T10:53:31.000Z","path":"2020/06/15/十次方dayFive/","text":"用户注册模块搭建在user模块添加发送短信业务service层public void sendMsg(String mobile) { //生成六位随机数 String checkCode = RandomStringUtils.randomNumeric(6); //向缓存中放一份 redisTemplate.opsForValue().set(\"checkCode\"+mobile,checkCode,6, TimeUnit.HOURS); //给用户发一份，先存放至rabbitmq中 Map&lt;String,String&gt;map=new HashMap&lt;&gt;(); map.put(\"mobile\",mobile); map.put(\"checkCode\",checkCode); rabbitTemplate.convertAndSend(\"sms\",map);} controller层@RequestMapping(value =\"/sendsms/{mobile}\",method = RequestMethod.POST)public Result sendMsg(@PathVariable String mobile){ userService.sendMsg(mobile); return new Result(true,StatusCode.OK,\"发送成功\");} 在rabbitmq短信监听模块通过阿里云实施发送短信导入阿里云依赖&lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;4.5.0&lt;/version&gt;&lt;/dependency&gt; 根据阿里云官网API创建工具类@Componentpublic class SmsUtil { private static final String accessKeyId=\"LTAI4GCjWSbTHQzGTaavF**\"; private static final String accessKeySecret=\"sDiW0PSXaAKXfNfwCI8vaG4spE4**\"; private static final String signName=\"******\"; private static final String templateCode=\"SMS_1932477**\"; public void sendSms(String mobile,String checkCode) { DefaultProfile profile = DefaultProfile.getProfile(\"default\", accessKeyId, accessKeySecret); IAcsClient client = new DefaultAcsClient(profile); CommonRequest request = new CommonRequest(); request.setSysMethod(MethodType.POST); request.setSysDomain(\"dysmsapi.aliyuncs.com\"); request.setSysVersion(\"2017-05-25\"); request.setSysAction(\"SendSms\"); request.putQueryParameter(\"PhoneNumbers\", mobile); request.putQueryParameter(\"SignName\", signName); request.putQueryParameter(\"TemplateCode\", templateCode); //这里使用通配符，code要与在阿里云注册的模版相同 request.putQueryParameter(\"TemplateParam\", \"{\\\"code\\\":\"+checkCode+\"}\"); try { CommonResponse response = client.getCommonResponse(request); System.out.println(response.getData()); } catch (ServerException e) { e.printStackTrace(); } catch (ClientException e) { e.printStackTrace(); } }} 创建rabbitmq监听器类@Component@RabbitListener(queues = \"sms\")public class SmsListener { @Autowired private SmsUtil smsUtil; @RabbitHandler public void executeSms(Map&lt;String,String&gt; map){ String mobile = map.get(\"mobile\"); String checkCode = map.get(\"checkCode\"); smsUtil.sendSms(mobile,checkCode); }} 自此短信功能部署成功 用户注册业务@RequestMapping(value =\"/register/{code}\",method = RequestMethod.POST)public Result register(@PathVariable String code,@RequestBody User user){ //先从缓存中拿到先前发送短信时存放的数据 String checkCodeRedis= (String) redisTemplate.opsForValue().get(\"checkCode\"+user.getMobile()); //比对数据 if(checkCodeRedis.isEmpty()){ return new Result(false,StatusCode.ERROR,\"未发送验证码\"); } if(!checkCodeRedis.equals(code)){ return new Result(false,StatusCode.ERROR,\"验证码错误\"); } //比对成功，注册用户 userService.add(user); return new Result(true,StatusCode.OK,\"注册成功\");} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://xulilei.github.io/tags/rabbitmq/"},{"name":"短信验证","slug":"短信验证","permalink":"https://xulilei.github.io/tags/%E7%9F%AD%E4%BF%A1%E9%AA%8C%E8%AF%81/"},{"name":"用户注册","slug":"用户注册","permalink":"https://xulilei.github.io/tags/%E7%94%A8%E6%88%B7%E6%B3%A8%E5%86%8C/"}]},{"title":"RabbitMQ入门","date":"2020-06-15T10:53:09.000Z","path":"2020/06/15/RabbitMQ/","text":"消息中间件RabbitMQRabbitMQ简介消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋和消息通讯等问题，实现高性能，高可用，可伸缩和最终一致性的架构 架构图通过交换机再进入到队列中 主要概念RabbitMQ Server也叫broker server，它是一种传输服务。 他的角色就是维护一条 从Producer到Consumer的路线，保证数据能够按照指定的方式进行传输。 Producer消息生产者，如图A、B、C，数据的发送方。消息生产者连接RabbitMQ服 务器然后将消息投递到Exchange。 Consumer消息消费者，如图1、2、3，数据的接收方。消息消费者订阅队列， RabbitMQ将Queue中的消息发送到消息消费者。 Exchange生产者将消息发送到Exchange（交换器），由Exchange将消息路由到一个 或多个Queue中（或者丢弃）。Exchange并不存储消息。RabbitMQ中的Exchange有 direct、fanout、topic、headers四种类型，每种类型对应不同的路由规则。 Queue队列是RabbitMQ的内部对象，用于存储消息。消息消费者就是通过订阅 队列来获取消息的，RabbitMQ中的消息都只能存储在Queue中，生产者生产消息并最终 投递到Queue中，消费者可以从Queue中获取消息并消费。多个消费者可以订阅同一个 Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者 都收到所有的消息并处理。 RoutingKey生产者在将消息发送给Exchange的时候，一般会指定一个routing key， 来指定这个消息的路由规则，而这个routing key需要与Exchange Type及binding key联 合使用才能最终生效。在Exchange Type与binding key固定的情况下（在正常使用时一 般这些内容都是固定配置好的），我们的生产者就可以在发送消息给Exchange时，通过 指定routing key来决定消息流向哪里。 Docker安装需要注意的是要配置多个接口 docker run ‐di ‐‐name=tensquare_rabbitmq ‐p 5671:5617 ‐p 5672:5672 ‐p 4369:4369 ‐p 15671:15671 ‐p 15672:15672 ‐p 25672:25672 rabbitmq:management 主要知识点Exchange类型direct模式 1、将消息发给唯一一个节点时使用这种模式，这是最简单的一种形式 2、这种模式下不需要将Exchange进行任何绑定(binding)操作 3、消息传递时需要一个“RouteKey”，可以简单的理解为要发送到的队列名字 首先创建一个test队列 以direct模式发送 @RunWith(SpringRunner.class)@SpringBootTest(classes = RabApplication.class)public class ProductTest { @Autowired private RabbitTemplate rabbitTemplate; @Test public void sendMsg(){ //这里的test就是queue的名字 rabbitTemplate.convertAndSend(\"test\",\"测试直接模式\"); }} 创建消费者接受 @Component@RabbitListener(queues = \"test\")public class Customer { @RabbitHandler public void getMsg(String msg){ System.out.println(\"直接模式消费消息\"+msg); }} 运行结果 该模式下，默认采用了负载均衡，即消费者从队列获取消息是均衡的 分列模式 任何发送到Fanout Exchange的消息都会被转发到与该Exchange绑定(Binding)的所有 Queue上。 1、这种模式不需要RouteKey 2、这种模式需要提前将Exchange与Queue进行绑定，一个Exchange可以绑定多个 Queue，一个Queue可以同多个Exchange进行绑定。 3、如果接受到消息的Exchange没有与任何Queue绑定，则消息会被抛弃。+ 主题模式 任何发送到Topic Exchange的消息都会被转发到所有关心RouteKey中指定话题的 Queue上 1、这种模式较为复杂，简单来说，就是每个队列都有其关心的主题，所有的消息都带有一 个“标题”(RouteKey)，Exchange会将消息转发到所有关注主题能与RouteKey模糊匹配的 队列。 2、这种模式需要RouteKey，也许要提前绑定Exchange与Queue。 3、在进行绑定时，要提供一个该队列关心的主题，如“#.log.#”表示该队列关心所有涉及 log的消息(一个RouteKey为”MQ.log.error”的消息会被转发到该队列)。 4、“#”表示0个或若干个关键字，“”表示一个关键字。如“log.”能与“log.warn”匹配，无法 与“log.warn.timeout”匹配；但是“log.#”能与上述两者匹配。 5、同样，如果Exchange没有发现能够与RouteKey匹配的Queue，则会抛弃此消息 配合阿里云实现发送短信功能详见 https://xulilei.github.io/2020/06/15/%E5%8D%81%E6%AC%A1%E6%96%B9dayFive/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://xulilei.github.io/tags/rabbitmq/"},{"name":"短信验证","slug":"短信验证","permalink":"https://xulilei.github.io/tags/%E7%9F%AD%E4%BF%A1%E9%AA%8C%E8%AF%81/"}]},{"title":"DayFour-elasticsearch","date":"2020-06-14T10:34:44.000Z","path":"2020/06/14/十次方DayFour/","text":"搜索微服务搭建使用spring-data-elasticsearch操作导入依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-elasticsearch&lt;/artifactId&gt;&lt;/dependency&gt; Pojo实体类@Document(indexName = \"articleindex\",type = \"article\")public class Article implements Serializable { @Id private String id; //是否能被搜索到 //是否分词，整体匹配还是分词匹配 //是否在页面上显示，即数据库中在该实体类中的字段，就是要显示的,比如该例中的id title content state //analyzer,分词 //searchAnalyzer，搜索 @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String title; @Field(index = true,analyzer=\"ik_max_word\",searchAnalyzer=\"ik_max_word\") private String content; private String state;} Dao层public interface ArticleDao extends ElasticsearchRepository&lt;Article,String&gt; { public Page&lt;Article&gt; findByTitleOrContentLike(String title, String content, Pageable pageable);} Service层@Servicepublic class ArticleService { @Autowired private ArticleDao articleDao; @Autowired private IdWorker idWorker; public void save(Article article){ articleDao.save(article); } //springdata系列分页的写法都是这个 public Page&lt;Article&gt; findByKey(String key, int page, int size) { Pageable pageable= PageRequest.of(page-1,size); return articleDao.findByTitleOrContentLike(key,key,pageable); }} controller层@RestController@RequestMapping(\"/article\")@CrossOriginpublic class ArticleController { @Autowired private ArticleService articleService; @RequestMapping(method = RequestMethod.POST) public Result save(@RequestBody Article article){ articleService.save(article); return new Result(true, StatusCode.OK,\"存储成功\"); } @RequestMapping(value = \"/{key}/{page}/{size}\",method = RequestMethod.GET) public Result findByKey(@PathVariable String key,@PathVariable int page,@PathVariable int size){ Page&lt;Article&gt;pageData=articleService.findByKey(key,page,size); return new Result(true,StatusCode.OK,\"搜索成功\",new PageResult&lt;Article&gt;(pageData.getTotalElements(),pageData.getContent())); }} docker部署elasticsearchhttps://xulilei.github.io/2020/06/12/elasticSearch%E5%85%A5%E9%97%A8/ 连接服务器，并测试存储到服务器的索引库application.yml配置server: port: 9007spring: application: name: tensquare-search data: elasticsearch: cluster-nodes: 192.168.152.128:9300 postMan测试成功 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://xulilei.github.io/tags/elasticsearch/"},{"name":"搜索功能","slug":"搜索功能","permalink":"https://xulilei.github.io/tags/%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD/"}]},{"title":"ElasticSearch从认识到发布","date":"2020-06-12T07:54:05.000Z","path":"2020/06/12/elasticSearch入门/","text":"分布式搜索引擎ElasticSearch概念与mysql数据库对比 Elasticsearch 关系型数据库Mysql 索引(index) 数据库(databases) 类型(type) 表(table) 文档(document) 行(row) restful风格操作ElasticSearch新建索引如果需要创建一个叫articleindex的索引 ,就以put方式提交 http://127.0.0.1:9200/articleindex/ 新建文档新建类型，在索引后追加类型： 以post方式提交 http://127.0.0.1:9200/articleindex/article 查询文档查询全部_search，以get方式请求 http://127.0.0.1:9200/articleindex/article/_search 按ID查询以GET方式请求 http://127.0.0.1:9200/articleindex/article/1 匹配查询根据title=aa进行查询，get方式提交下列地址： http://127.0.0.1:9200/articleindex/article/_search?q=title:aa 模糊查询以*用代表任意字符： http://192.168.184.134:9200/articleindex/article/_search?q=title:*s* 修改以put形式提交以下地址,如果ID存在则修改，否则添加 http://127.0.0.1:9200/articleindex/article/1 删除文档根据ID删除文档,删除ID为1的文档 DELETE方式提交 http://192.168.184.134:9200/articleindex/article/1 head插件操作ElasticSearch安装步骤步骤1： 下载head插件：https://github.com/mobz/elasticsearch-head 步骤2： 将grunt安装为全局命令npm install ‐g grunt‐cli 步骤3：解决跨域问题修改elasticsearch配置文件：elasticsearch.yml，增加以下两句命令： http.cors.enabled: true http.cors.allow‐origin: \"*\" 步骤4： 安装依赖并启动cnpm installgrunt server 图形化界面 Logstash概念Logstash是一款轻量级的日志搜集处理框架，可以方便的把分散的、多样化的日志搜集 起来，并进行自定义的处理，然后传输到指定的位置，比如某个服务器或者文件。 基本用法命令行参数: -e ：执行（很少用） -f：路径，后跟参数类型可以是一个字符串的配置或全路径文件名或全路径 如：/etc/logstash.d/，logstash会自动读取/etc/logstash.d/目录下所有*.conf 的文 本文件，然后在自己内存里拼接成一个完整的大配置文件再去执行 使用Logstash将数据库的内容同步到索引库模版，用到时直接填写input { jdbc { # mysql jdbc connection string to our backup databse jdbc_connection_string =&gt; \"jdbc:mysql://192.168.xx.xx:3306/aaaaa?characterEncoding=UTF8\" # the user we wish to excute our statement as jdbc_user =&gt; \"root\" jdbc_password =&gt; \"root\" # the path to our downloaded jdbc driver jdbc_driver_library =&gt; \"C:\\Users\\xu\\Desktop\\tensquare\\logstash-5.6.8\\mysqletc\\mysql-connector-java-5.1.46.jar\" # the name of the driver class for mysql jdbc_driver_class =&gt; \"com.mysql.jdbc.Driver\" jdbc_paging_enabled =&gt; \"true\" jdbc_page_size =&gt; \"50\" #以下对应着要执行的sql的绝对路径。 #statement_filepath =&gt; \"\" #这个是要直接执行的sql语句 statement =&gt; \"\"select id,title,content,state from tb_article\" #定时字段 各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新（测试结果，不同的话请留言指出） schedule =&gt; \"* * * * *\" }}output { elasticsearch { #ESIP地址与端口 hosts =&gt; \"127.0.0.1:9200\" #ES索引名称（自己定义的） index =&gt; \"articleindex\" #自增ID编号 document_id =&gt; \"%{id}\" document_type =&gt; \"article\" } stdout { #以JSON格式输出 codec =&gt; json_lines }} 再通过一下命令执行该文件logstash ‐f ../mysqletc/mysql.conf 结果返回{\"@version\":\"1\",\"id\":\"1\",\"state\":\"1\",\"@timestamp\":\"2020-06-15T03:35:00.106Z\",\"title\":\"xu测试\",\"content\":\"测试\"}{\"@version\":\"1\",\"id\":\"1\",\"state\":\"1\",\"@timestamp\":\"2020-06-15T03:34:01.671Z\",\"title\":\"xu测试\",\"content\":\"测试\"} 注意事项删除数据库中的文件并不会导致索引库中的数据删除，可以约定一个state，当需要删除的时候更改state的值，在索引库中，查询约定state的值即可实现 docker安装ES安装ES容器第一步，安装容器docker run ‐di ‐‐name=tensquare_elasticsearch ‐p 9200:9200 ‐p 9300:9300 elasticsearch:5.6.8 第二步，允许其他ip地址访问#进入elasticsearch容器的目录docker exec ‐it tensquare_elasticsearch /bin/bash#拷贝容器中的配置文件到宿主机docker cp tensquare_elasticsearch:/usr/share/elasticsearch/config/elasticsearch.yml /usr/share/elasticsearch.yml#停止删除原来的容器docker stop tensquare_elasticsearch docker rm tensquare_elasticsearch#重新安装容器，并挂载配置文件为/usr/share/elasticsearch.ymldocker run ‐di ‐‐name=tensquare_elasticsearch ‐p 9200:9200 ‐p 9300:9300 ‐v /usr/share/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch .yml elasticsearch:5.6.8#修改/usr/share/elasticsearch.yml 将#transport.host:0.0.0.0前的#去掉后保存文件退出。其作用是允许任何ip地址访问elasticsearch，并指定可以跨域transport.host:0.0.0.0http.cors.enabled: true http.cors.allow‐origin: \"*\"#重启容器docker restart tensquare_elasticsearch 第三部，如果遇到容器启动自动关闭，则需要优化配置(每个机器不同优化也不同)可以参考 https://blog.csdn.net/qq_34756221/article/details/105550037 https://www.cnblogs.com/jasonzeng/p/11584754.html 安装ik分词器先通过xftp将ik分词文件传送至服务器，再拷贝至es容器目录的plugins中 docker cp ik tensquare_elasticsearch:/usr/share/elasticsearch/plugins/ 安装headerdocker run ‐di ‐‐name=myhead ‐p 9100:9100 docker pull mobz/elasticsearch‐ head:5 成功页面展示head插件展示 ik分词器展示 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://xulilei.github.io/tags/ElasticSearch/"},{"name":"Logstash","slug":"Logstash","permalink":"https://xulilei.github.io/tags/Logstash/"},{"name":"ik分词器","slug":"ik分词器","permalink":"https://xulilei.github.io/tags/ik%E5%88%86%E8%AF%8D%E5%99%A8/"},{"name":"docker","slug":"docker","permalink":"https://xulilei.github.io/tags/docker/"}]},{"title":"DayThree-mongoDB","date":"2020-06-09T08:25:22.000Z","path":"2020/06/09/十次方项目第三天/","text":"Day03什么是MongoDB​ MongoDB 是一个跨平台的，面向文档的数据库，是当前 NoSQL 数据库产品中最热 门 的一种。它介于关系数据库和非关系数据库之间，是非关系数据库当中功能最丰富，最像关系数据库的产品。它支持的数据结构非常松散，是类似 JSON 的 BSON 格式，因此可以存储比较复杂的数据类型。 MongoDB适用场景​ 适用于场景数据量大，数据价值相对低的情况 MongoDB体系结构（1）MongoDB 的文档（document），相当于关系数据库中的一行记录。 （2）多个文档组成一个集合（collection），相当于关系数据库的表。 （3）多个集合（collection），逻辑上组织在一起，就是数据库（database）。 服务器创建Docker MongoDB容器[root@pinyoyougou-docker ~]# docker run -di --name=tensquare_mongo -p 27017:27017 mongo MongoDB语法创建表use 数据库名称//如果不存在则自动创建 插入数据db.集合名称.insert(数据);//插入文档的语法格式比如db.spit.insert({content:\"听说十次方课程很给力呀\",userid:\"1011\",nickname:\"小雅\",visits:NumberInt(902)}) 查询数据db.集合名称.find()//查询所有db.spit.find().limit(3)//限定返回3条db.spit.find({userid:'1013'})//查询userid=1013的文档 修改与删除数据db.集合名称.update(条件,修改后的数据)//如果我们想修改_id为1的记录，浏览量为1000，输入以下语句：db.spit.update({_id:\"1\"},{visits:NumberInt(1000)})执行后，我们会发现，这条文档除了visits字段其它字段都不见了，为了解决这个问题，我们需要使用修改器$set来实现，命令如下：db.spit.update({_id:\"2\"},{$set:{visits:NumberInt(2000)}})//删除指定文档db.集合名称.remove(条件) 模糊查询MongoDB的模糊查询是通过正则表达式的方式实现的格式为：db.集合名称.find({content:/aaa/})例如，我要查询吐槽内容包含“流量”的所有文档，代码如下：db.spit.find({content:/流量/})如果要查询吐槽内容中以“加班”开头的，代码如下：db.spit.find({content:/^加班/}) 大于 小于 不等于db.集合名称.find({ \"field\" : { $gt: value }}) // 大于: field &gt; valuedb.集合名称.find({ \"field\" : { $lt: value }}) // 小于: field &lt; valuedb.集合名称.find({ \"field\" : { $gte: value }}) // 大于等于: field &gt;= valuedb.集合名称.find({ \"field\" : { $lte: value }}) // 小于等于: field &lt;= valuedb.集合名称.find({ \"field\" : { $ne: value }}) // 不等于: field != value 包含与不包含包含使用$in操作符。示例：查询吐槽集合中userid字段包含1013和1014的文档db.spit.find({userid:{$in:[\"1013\",\"1014\"]}})不包含使用$nin操作符。示例：查询吐槽集合中userid字段不包含1013和1014的文档db.spit.find({userid:{$nin:[\"1013\",\"1014\"]}}) 条件连接我们如果需要查询同时满足两个以上条件，需要使用$and操作符将条件进行关联。（相当于SQL的and）格式为：$and:[{ },{ },{ }]示例：查询吐槽集合中visits大于等于1000 并且小于2000的文档db.spit.find({$and:[ {visits:{$gte:1000}} ,{visits:{$lt:2000}}]})如果两个以上条件之间是或者的关系，我们使用 操作符进行关联，与前面and的使用方式相同格式为：$or:[{ },{ },{ }]示例：查询吐槽集合中userid为1013，或者浏览量小于2000的文档记录db.spit.find({$or:[ {userid:\"1013\"} ,{visits:{$lt:2000} }]}) 列值增长如果我们想实现对某列值在原有值的基础上进行增加或减少，可以使用$inc运算符来实现db.spit.update({_id:\"2\"},{$inc:{visits:NumberInt(1)}}) JAVA操作MongoDBpublic class MongoDemo { public static void main(String[] args) { MongoClient client=new MongoClient(\"192.168.184.134\");//创建连接 MongoDatabase spitdb = client.getDatabase(\"spitdb\");//打开数据库 MongoCollection&lt;Document&gt; spit = spitdb.getCollection(\"spit\");//获取集合 //条件查询 //BasicDBObject bson=new BasicDBObject(\"userid\",\"1013\");// 构建查询条件 //BasicDBObject bson=new BasicDBObject(\"visits\",newBasicDBObject(\"$gt\",1000) ); //FindIterable&lt;Document&gt; documents = spit.find(bson);//查询记录获取结果集合 FindIterable&lt;Document&gt; documents = spit.find();//查询记录获取文档集合 for(Document document:documents){ // System.out.println(\"内容：\"+ document.getString(\"content\")); System.out.println(\"用户ID:\"+document.getString(\"userid\")); System.out.println(\"浏览量：\"+document.getInteger(\"visits\")); } //插入数据 Map&lt;String,Object&gt; map=new HashMap(); map.put(\"content\",\"我要吐槽\"); map.put(\"userid\",\"9999\"); map.put(\"visits\",123); map.put(\"publishtime\",new Date()); Document document=new Document(map); spit.insertOne(document); client.close();//关闭连接 }} SpringDataMongoDB增删改查与SpringDataJPA几乎一样，详细用法参考https://xulilei.github.io/2020/06/08/%E5%8D%81%E6%AC%A1%E6%96%B9%E9%A1%B9%E7%9B%AEDay2/ 通过MongoTemplate原生方式实现数据自增public void thumbUp(String id){ //方式一,与数据库多次交互性能较低 Spit spit=spitDao.findById(id).get(); spit.setThumbup((spit.getThumbup()==null?0:spit.getThumbup())+1); spitDao.save(spit); //相当于使用原生mongo命令实现自增：db.spit.update({\"_id\":\"1\"},{$inc:{thumbup:NumberInt(1)}}) Query query=new Query(); query.addCriteria(Criteria.where(\"_id\").is(\"id\")); Update update=new Update(); update.inc(\"thumbup\",1); mongoTemplate.updateFirst(query,update,\"spit\"); } document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://xulilei.github.io/tags/MongoDB/"},{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"DayTwo-SpringDataJpa","date":"2020-06-08T07:23:13.000Z","path":"2020/06/08/十次方项目Day2/","text":"SpringDataJpa通过new Specification实现条件查询//service层public List&lt;Label&gt; findSearch(Label label) { return labelDao.findAll(new Specification&lt;Label&gt;() { /** * 采用内部类，方式实现 * @param root 根对象，也就是说要把条件封装到哪个对象中去 * @param query 查询关键字，比如groupBy，orderBy等 * @param cb 用来封装条件对象的 * @return 如果返回null，则代表不需要任何条件 */ @Override public Predicate toPredicate(Root&lt;Label&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; list=new ArrayList&lt;&gt;(); //相当于 where labelname like \"%小明%\" if(label.getLabelname()!=null&amp;&amp;!\"\".equals(label.getLabelname())){ Predicate predicate = cb.like(root.get(\"labelname\").as(String.class), \"%\" + label.getLabelname() + \"%\"); list.add(predicate); } if(label.getState()!=null&amp;&amp;!\"\".equals(label.getState())){ Predicate predicate = cb.equal(root.get(\"state\").as(String.class), label.getState()); list.add(predicate); } Predicate[] parr=new Predicate[list.size()]; list.toArray(parr); //相当于查询where condition A and condition B return cb.and(parr); } }); }//controller层 @RequestMapping(value = \"/search\",method = RequestMethod.POST) public Result findSearch(@RequestBody Label label){ List&lt;Label&gt;list=labelService.findSearch(label); return new Result(true,StatusCode.OK,\"查询成功\",list); } 分页与条件查询//service层public Page&lt;Label&gt; findSearchAndPageQuery(Label label, int page, int size) { //封装一个分页对象 Pageable pageable=PageRequest.of(page-1,size); return labelDao.findAll(new Specification&lt;Label&gt;() { /** * * @param root 根对象，也就是说要把条件封装到哪个对象中去 * @param query 查询关键字，比如groupBy，orderBy等 * @param cb 用来封装条件对象的 * @return 如果返回null，则代表不需要任何条件 */ @Override public Predicate toPredicate(Root&lt;Label&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) { List&lt;Predicate&gt; list=new ArrayList&lt;&gt;(); //相当于 where labelname like \"%小明%\" if(label.getLabelname()!=null&amp;&amp;!\"\".equals(label.getLabelname())){ Predicate predicate = cb.like(root.get(\"labelname\").as(String.class), \"%\" + label.getLabelname() + \"%\"); list.add(predicate); } if(label.getState()!=null&amp;&amp;!\"\".equals(label.getState())){ Predicate predicate = cb.equal(root.get(\"state\").as(String.class), label.getState()); list.add(predicate); } Predicate[] parr=new Predicate[list.size()]; list.toArray(parr); return cb.and(parr); } },pageable); }//controller层 @RequestMapping(value = \"/search/{page}/{size}\",method = RequestMethod.POST) public Result findSearchAndPageQuery(@RequestBody Label label,@PathVariable int page,@PathVariable int size){ Page&lt;Label&gt; pageData=labelService.findSearchAndPageQuery(label,page,size); return new Result(true,StatusCode.OK,\"查询成功\",new PageResult&lt;Label&gt;(pageData.getTotalElements(),pageData.getContent())); }//用来封装pageResult的类public class PageResult&lt;T&gt; { private long total; private List&lt;T&gt; rows; public long getTotal() { return total; } public void setTotal(long total) { this.total = total; } public List&lt;T&gt; getRows() { return rows; } public void setRows(List&lt;T&gt; rows) { this.rows = rows; } public PageResult() { } public PageResult(long total, List&lt;T&gt; rows) { this.total = total; this.rows = rows; }} 在Dao层通过方法命名方式生成sql语句public interface EnterpriseDao extends JpaRepository&lt;Enterprise,String&gt;,JpaSpecificationExecutor&lt;Enterprise&gt;{ //相当于where ishot=? public List&lt;Enterprise&gt; findByIshot(String ishot); }public interface RecruitDao extends JpaRepository&lt;Recruit,String&gt;,JpaSpecificationExecutor&lt;Recruit&gt;{ //相当于where state=？ order by Createtime，并且取前6个 public List&lt;Recruit&gt; findTop6ByStateOrderByCreatetimeDesc(String state); //相当于where state！=？order by createtime。并且取前6个 public List&lt;Recruit&gt; findTop6ByStateNotOrderByCreatetimeDesc(String state);} 具体命名规则参考https://www.cnblogs.com/oxygenG/p/10057525.html。 处理多对多关系在数据库端处理多对多的关系，必须需要借助中间表。而在java端，只需要在一个对象中放入另一个对象的list集合即可。如果不创建实体类，则需要通过原生的sql语句执行 //通过这个查询语句，才能够实现pageable的分页功能@Query(value=\"SELECT * FROM tb_problem,tb_pl WHERE id=problemid AND labelid=:labelid ORDER BY ?#{#pageable}\", countQuery = \"select count(*) from tb_problem ,tb_pl where id=problemid AND labelid=:labelid\",nativeQuery = true)public Page&lt;Problem&gt; newList(@Param(\"labelid\") String labelid, Pageable pageable); 参考：https://blog.csdn.net/tt____tt/article/details/81027269?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase 事务支持1、Dao层，在可能产生线程问题的语句上添加@Modifying @Modifying@Query(value = \"update tb_article set state='1' where id=?1\",nativeQuery = true)public void updateState(String id); 2、Service层开启注解支持@Transactional @Service@Transactionalpublic class ArticleService {} 缓存的应用Redis–有过期时间限制1、添加SpringDataRedis依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2、服务端Docker开启Redis镜像，生成redis容器 [root@pinyoyougou-docker ~]# docker run -di --name=tensquare_redis -p 6379:6379 redis 3、application.ymal配置host redis: host: 192.168.*.* 4、业务逻辑调用 public class ArticleService { @Autowired private ArticleDao articleDao; @Autowired private RedisTemplate redisTemplate; public Article findById(String id) { //先从缓存中查询当前对象 Article article= (Article) redisTemplate.opsForValue().get(\"article_\"+id); //如果没有渠道 if(article==null){ article = articleDao.findById(id).get(); //存入缓存 redisTemplate.opsForValue().set(\"article_\"+id,article); } return article; } public void deleteById(String id) { //删除缓存 redisTemplate.delete(\"article_\"+id); articleDao.deleteById(id); }} redisTemplate用法 stringRedisTemplate.opsForValue().set(\"test\", \"100\",60*10,TimeUnit.SECONDS);//向redis里存入数据和设置缓存时间stringRedisTemplate.opsForValue().get(\"test\")//根据key获取缓存中的valstringRedisTemplate.delete(\"test\");//根据key删除缓存stringRedisTemplate.hasKey(\"546545\");//检查key是否存在，返回boolean值 SpringCache–无过期时间限制1、SpringApplication开启SpringCache @SpringBootApplication@EnableCachingpublic class GatApplication {} 2、业务层调用，@Cacheable为存，@CacheEvict为删 @Cacheable(value = \"gathering\",key = \"#id\")public Gathering findById(String id) { return gatheringDao.findById(id).get();}@CacheEvict(value = \"gathering\",key = \"#gathering.id\")public void update(Gathering gathering) { gatheringDao.save(gathering);} 第二天总结掌握了条件与分页查询，Dao层方法命名规则，事务支持，缓存 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"SpringDataJPA","slug":"SpringDataJPA","permalink":"https://xulilei.github.io/tags/SpringDataJPA/"},{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"Docker入门篇","date":"2020-06-05T07:57:43.000Z","path":"2020/06/05/Docker入门/","text":"Docker入门Dokcer为什么会出现？一款产品从开发到上线，一般都需要两套环境。而环境的配置十分麻烦，Docker给出了解决方案 步骤：java–jar（环境）–打包项目带上环境（即Docker镜像）–Docker仓库–下载我们发布的镜像–直接运行即可。 虚拟机技术特点1、资源占用十分多 2、冗余步骤多 3、启动很慢 如下图所示，多个APP共享一个lib环境，可能会造成端口冲突等环境冲突的问题 容器化技术如下图所示，每个模块拥有独属于自己运行的环境，各个模块之间相互隔离 Docker的相关概念Docker架构图 相关术语镜像：images​ 通过这个模版来创建容器服务，比如Mysql镜像–通过Docker运行后，便成为了一个提供服务的容器,一个镜像可以创建多个容器 容器：container​ 提供服务，可以启动、停止、删除等，可类比为一个简单的linux系统 仓库：repository​ 存放镜像的地方，分为共有仓库和私有仓库 Docker安装Nginx1、search：可在命令行和dockerHub上搜索对应版本 2、pull：拉去下载该镜像 3、docker images：查看本机上的镜像 3、运行该镜像 docker run -d --name nginx01 -p 3344:80 nginx #新建一个名字为nginx01的nginx镜像，公网访问地址为3344，内部地址为80，并运行该镜像#-d 后台运行、--name 命名、-p 端口号 4、内部测试 ​ curl localhost:3344 容器数据卷结构示意图如下 防止容器删除后数据丢失，通过实现容器间数据共享，并将产生的数据备份到linux的文件系统上 总结一句话就是：容器的持久化和容器间的同步操作。 使用数据卷​ -v 主机目录:容器内目录 —&gt;映射容器内的目录到主机上 ​ 参考https://xulilei.github.io/2020/06/12/elasticSearch%E5%85%A5%E9%97%A8/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"Docker","slug":"Docker","permalink":"https://xulilei.github.io/tags/Docker/"}]},{"title":"DayOne-架构","date":"2020-06-02T11:02:13.000Z","path":"2020/06/02/十次方社交平台项目/","text":"DayOne系统架构SpringBoot+SpringCloud+SpringMVC+SpringData，也称这种架构模式为spring全家桶 系统模块不再采取按dao，service层划分模块，而是基于每个微服务，再将每个模块封装成一个镜像，再通过springCloud连接起来。因此在每个微服务中便不需要再写接口，因为每个微服务就是最小模块 开发API通过swagger封装，Nginx代理，形成的API开发文档 Restful开发风格我们在项目中经常用到增删改查：get/post/put/delete四种方法，安全：操作不会出现脏读、幻读等操作。幂等：查询成功后不会对数据库造成影响 Get查询是安全且幂等的 Post是不安全且不幂等的 Put改是不安全且幂等的 Delete删是不安全且幂等的 主要工作Mysql环境搭建创建虚拟机，安装docker，下载Mysql镜像，在服务器(192.168.152.128)运行并从本地连接完成建表 创建父工程主要是一些子模块都需要的依赖配置在这里 &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; &lt;!--SpringCloud全家桶父工程推荐默认配置--&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; 模块搭建公共模块搭建，根据swagger约定，封装数据传输到前端。其中utils包下的idWoker根据雪花算法，可以生成不同的ID，吞吐量为20W+。 基础模块搭建，数据的CRUD操作 import com.tensquare.base.pojo.Label;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.data.jpa.repository.JpaSpecificationExecutor;//SpringDataJpa封装了CRUD操作，以及一些复杂的条件查询public interface LabelDao extends JpaRepository&lt;Label,String&gt;, JpaSpecificationExecutor&lt;Label&gt; {} Day01总结在服务器端，通过Docker创建了Mysql镜像 通过本地IDEA的DataSource连接上去。 通过PostMan检查当天的CRUD操作 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","tags":[{"name":"项目","slug":"项目","permalink":"https://xulilei.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]}]